en101-code
英语学习过程中是用到的代码

目标: 微信小程序，写一个基于期刊文章数据库的例句词典。



========================================
使用colab下载经济学人目录和正文、图片
----------------------------------------
1.网址
https://colab.research.google.com



2.访问网站首页，或者当前打印版目录
import requests

#发出请求
respose=requests.get('https://www.economist.com/printedition')
#print(respose.status_code)# 响应的状态码 200
#print(respose.content)  #返回字节信息
print(respose.text)  #返回文本内容

#包装成函数
def getHtml(url):
  print(url)
  response=requests.get(url)
  print(response.status_code)# 响应的状态码 200
  #print(response.content)  #返回字节信息
  #print(response.text)  #返回文本内容
  return response.text;

url1="https://www.economist.com/printedition/2019-08-10"
#url1="https://www.bbc.com"
rs=getHtml(url1)

保存到本地，使用下节的css代码美化，即可浏览。



3.访问页面
提取链接：
file:///C:/china/2019/07/18/chinese-are-big-customers-for-schemes-selling-foreign-residency
替换成：
https://www.economist.com/china/2019/07/18/chinese-are-big-customers-for-schemes-selling-foreign-residency

import requests
respose=requests.get('https://www.economist.com/china/2019/07/18/chinese-are-big-customers-for-schemes-selling-foreign-residency')
print(respose.text)



4.从页面提取图片url

怎么下载呢？
import requests
url = 'https://www.economist.com/sites/default/files/images/print-edition/20190720_CND001_0.jpg'
html = requests.get(url)
# 将图片保存到本地
with open("./1.jpg","wb")as f:
    f.write(html.content)

然后查看图片
! ls -lth

加载到jupyter上
from IPython.display import Image
picPath = "./1.jpg"
Image(filename = picPath, width=500)



4.2 更简洁、智能的一体化现在图片的方案：
# download image
import requests
url = 'https://www.economist.com/sites/default/files/images/print-edition/20190720_BKD001_0.jpg'

# get img name
import re
arr=re.split("/",url)
imgName=arr[-1]

#get img
html = requests.get(url)
# save img
with open(imgName,"wb")as f:
    f.write(html.content)

#load image
from IPython.display import Image
Image(filename = imgName, width=500)






========================================
|-- 经济学人目录美化
----------------------------------------
梯子爬 https://www.economist.com/printedition
格式是混乱的，需要稍微美化一下。


<base href="https://www.economist.com/" />
<base target="_blank" />

<style>
*{font-family:Arial,Verdana;}
a {display:block; text-decoration: none;}
a:hover {text-decoration: underline;}

img{padding:100px;border:1px solid red;}
span{padding-left:10px;}
a{color: darkblue;  }

/*最有作用的2行*/
a.link-button.list__link {    display: block; }
span.print-edition__link-flytitle{    font-weight: bold;     margin-right: 10px;}
</style>

后面是梯子显示的其他内容

//todo


========================================
从微信下载文章目录信息(url/title/readNum等)
----------------------------------------
需要登录，配置好cookie信息。

import re,os
import requests
import time,random
import datetime


###############
#part 1 获取1页的目录信息
###############
#get method
def getURL(url):
    #设置 headers信息，模拟真实用户访问
    headers={}
    headers['Accept']='text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3'
    headers['Accept-Encoding']='gzip, deflate, br'
    headers['Accept-Language']='zh-CN,zh;q=0.9,en;q=0.8'
    headers['Cache-Control']='max-age=0'
    headers['Connection']='keep-alive'
    headers['Host']='mp.weixin.qq.com'
    headers['Upgrade-Insecure-Requests']='1'
    headers['User-Agent']='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36'
    # 有这一对cookie 才能正常访问
    cookies={'ua_id': 'Xm1KD4F6R7QsXiwDAAAAAIN4ElaGwHvY5I_a35JmCOM=',
        'mm_lang': 'zh_CN',
        'pgv_pvi': '4462950400',
        'pgv_pvid': '3691230498',
        'RK': 'dRSsGPjle2',
        'ptcz': '4d6674eaae060082e9dd23c4dcb5be5e35bfb68fb580ad9e4c3d646fca9919b3',
        'ts_uid': '1473981184',
        'tvfe_boss_uuid': '107c1a140bd510c1',
        'o_cookie': '469004330',
        'pac_uid': '1_469004330',
        'pgv_si': 's7429627904',
        'rewardsn': '',
        'wxtokenkey': '777',
        'cert': '7kPbM_JrsT532DIHCSRhLRk21eqqtT84',
        'noticeLoginFlag': '1',
        'remember_acct': 'post_master_v1%40163.com',
        'openid2ticket_oICWNxHPgv2OlFhNxaUfSXJMcbFA': '4BxmPBpgwMLyi9apNE/Gc3uSVlls7+qOPW/d9Jfu7/o=',
        'uuid': '96735d3444c8d6b89dbaf018ac760b81',
        'data_bizuin': '3297584416',
        'bizuin': '3244717792',
        'data_ticket': 'w9cc28H/fFiSH4BmmMXXXht+W8tzSBxe/WYEyIWmVoFGntaLwghqXJNJ+IN6se5H',
        'slave_sid': 'NmRKSXEydWxDaWRSYWdLS2xyTXpyYzFxdHFUM1A0blJCeTNKSXlHU0dNdU55VXFvR0l2bmk3UUFick9UM0VYY3F1QUYwZEExb0M5eWRxdlRCR0kzYXZwMlk4Q3ZRV20xSEcwYlBvQVUydjVpS1hSaFp0NDJ3Y29ET0dKWWdUUFZCaU91SWd3SEFET1IwMFlB',
        'slave_user': 'gh_7177736af7e2',
        'xid': 'b6ec883094bed132f8bc7251976aa4fe',
    }
    #发出请求
    #respose=requests.get(url,headers)
    respose=requests.get(url,headers=headers,cookies=cookies,verify=False)
    assert respose.status_code==200,'Error: requests.get'
    #获取编码方式
    codeType=respose.apparent_encoding #GB2312 编码方式
    html_content = respose.content#以二进制编码读出页面源码    
    html = html_content.decode(codeType)#指定编码
    return html
#2.获取当前日期和时间:
print("loading function getURL(), done at", datetime.datetime.now())


#test
#page=1
#url="https://mp.weixin.qq.com/cgi-bin/newmasssendpage?count=7&begin="+str(page*7)+"&token=1998518622&lang=zh_CN&token=1998518622&lang=zh_CN&f=json&ajax=1"
#json2=getURL(url)
#json2



###############
#part 2 #批量执行 获取每页的目录
###############
import json,random
psgs=[] #所有文章目录保存到这里
pages=83 #总页码
for page in range(pages): #[0-83)
    #构建目录
    url="https://mp.weixin.qq.com/cgi-bin/newmasssendpage?count=7&begin="+str(page*7)+"&token=1998518622&lang=zh_CN&token=1998518622&lang=zh_CN&f=json&ajax=1"
    json2=getURL( url )
    
    #休眠随机时间
    pause=0.5+3*random.random()
    time.sleep(pause) 
    #
    json3=json.loads(json2)
    l2=json3['sent_list']
    #
    for i in range(len(l2)):
        #新年祝词可以省略了
        numADay=len(l2[i]["appmsg_info"])
        if numADay==0:
            continue;
        for num in range(numADay): #如果一天有多篇文章
            msg=l2[i]["appmsg_info"][num]
            msg['time']=l2[i]['sent_info']['time']
            psgs.append(msg)
    
    print(page,"/",pages,'; passages=',len(psgs), '; sleep',pause,'s\n',)
#

len(psgs) # 没有考虑一天多篇幅的:578
#考虑一天多篇幅后 624 


# 保存这一批json文件
import json
with open("web/wechatContent20190626-.json","w") as f:
    json.dump(psgs,f)
    print("写入文件完成...")
# 读文件
with open("web/wechatContent20190626.json",'r') as load_f:
    load_jn = json.load(load_f)
    print(type(load_jn),len(load_jn), load_jn[0]) #<class 'list'> 578
#




###############
# part3 写成html 格式的目录
###############

fw=open('web/wcContent2.html','w',encoding="utf-8")
fw.write('<html>\n<head><meta http-equiv=Content-Type content="text/html;charset=utf-8"></head>'+"\n"+'<body><ul>'+"\n")

for psg in psgs:
    #psg=psgs[0]
    url2=re.sub("^http","https",psg['content_url'])
    rd=str(psg['read_num'])
    
    line="<li><span>"+time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(psg['time'])) + \
        "</span> <span title='阅读数'>["+rd+"]</span>"+ \
        " <a target='_blank' href='"+url2+"'>"+psg['title']+"</a></li>"
    #print(line)
    fw.write(line+"\n")
print("done==")

js="""
<script>
function sortByRead(){
	var oUl=document.getElementsByTagName('ul')[0];
	var aList = oUl.getElementsByTagName("li");
	var aSpan;
	
	var arr = [];
	var len = aList.length;

	for(var i=0;i<len;i++){
		aSpan =aList[i].getElementsByTagName("span");
		strs=aSpan[1].innerHTML
		//
		aList[i].id=strs.substr(1,strs.length-2)
		arr.push(aList[i]);
	};

	arr.sort(function(a,b){
		return b.id - a.id;
	});
	//console.log(arr);

	oUl.innerHTML=""
	for(i=0;i<len;i++){
		oUl.append(arr[i])
	}
};

sortByRead();
</script>
"""

fw.write("</ul>\n"+js+"</body></html>")
fw.close()


进一步修改js代码，变得更好用，最后效果见：
http://ielts.biomooc.com/en/contents.html






========================================
|-- 将微信(英文全文)结果保存到数据库
----------------------------------------
1.数据表设计

CREATE TABLE `msg_English` (
  `msg_id` int(4) not null primary key auto_increment,
  `msg_url` varchar(300), #url
	
  `msg_origin` char(100) NOT NULL DEFAULT '', #来源
  `msg_date` char(50) NOT NULL DEFAULT '', #日期
  `msg_size` int(10) NOT NULL DEFAULT 0, #字数

  `msg_title` char(100) NOT NULL DEFAULT '', 
  `msg_desc` char(200) NOT NULL DEFAULT '',
  `msg_content` text #PRIMARY KEY (`msg_origin`,`msg_date`)
) ENGINE=MyISAM DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='微信英文文章表';


清空数据表
> truncate table wang.msg_English;

查字段及其属性
> show full columns from msg_English;

有错别字，可能是 pymysql.escape_string() 实体变换太多导致的，要替换回’
> select msg_id, msg_desc from msg_English where msg_desc like "%\x26#39;%";


encodeURI('\x26#39;') //"&#39;" 这个在html中就是'，所以可以在js中转义。
'company\x26#39;s'.replace('\x26#39;', '’')  //"company’s"

'company\x26#39;scompany\x26#39;scompany\x26#39;s'.replace(/\x26#39;/g, '’')  //"company’scompany’scompany’s" 全局替换
这个貌似起作用了。不过正则中的\要转义\\







2.保存文章到db
脚本位置: IELTS/py/ jupyter文件。
警告： jupyter 会一直占用mysql连接，如果要执行只好重启jupyter，进入mysql的docker容器重启。
$ sudo docker exec -it e3f bash
# service mysql restart
$ docker start e3f



(0) 获取标题
import requests
from lxml import html

#1.请求数据
def getURLs(url):
    page=requests.Session().get(url)
    #print("==ok  http://y.biomooc.com/wangjl/urls.html")


    #2.解析数据：获取批量URL
    tree=html.fromstring(page.text)

    result=tree.xpath('//@href')#重复出现2次，所以只取奇数即可。
    arrURL=[]
    for i in range( len(result) ):
        if i==0: continue;
        arrURL.append(result[i])
    print(len(arrURL))
    print(arrURL[0:5])
    return arrURL
# test
url="http://ielts.dawneve.cc/en/contents.html"
arrURL=getURLs(url)
print("="*20, "预期会有n个url，请手工测试一个url能否打开。")






(1) 输入url，获取英文文本信息，写入文件，并返回
# 函数库
import re, requests, sys, pymysql

# v0.2 修改日期获取方式
# v0.3 修正条件:过滤掉日期中的html标签
# v0.4 过滤掉日期中的空格实体
# v0.5 fix url para

def getInfoByURL2(msg_url, fromSys=False):
    #####################################
    #1.爬虫获取信息
    #####################################
    # 发出请求
    response=requests.get(msg_url)
    assert response.status_code==200,'Error: requests.get'
    #print(respose.text)
    #解析数据
    page3=response.text.encode('utf-8').decode('utf-8')
    

    #1.msg_title
    title=re.findall(r"msg_title = '(.*?)'",page3,re.S)[0]
    #print('title=',title)

    #2.msg_desc
    msg_desc=re.findall(r'msg_desc = "(.*?)"',page3,re.S)[0]
    #print('msg_desc=',msg_desc)

    #3.js_content
    rs=re.findall(r'id="js_content" style="visibility: hidden;"\>(.*?)\<\/div\>',page3,re.S)[0]
    #print('rs=', rs)
    
    # data 
    msg_date=re.findall(r',s="(.*?)"',page3,re.S)[0]

    
    
    #4.获取日期
    
    ########### 方法1，从内容中获取日期
    #aid1 由第一行获取数组：日期字符串，单词数
    def getDateStrSize(strs):
        d1=strs   #rs[1:300];d1
        d2=re.split("words",d1)[0]
        d3=re.split(">",d2)[-1]
        d4=re.split("\|", d3)

        return [d4[0].strip(), int(d4[1].strip())] ##'Aug 30, 2018'日期; 859 单词数
    #aid2 由日期字符串'Aug 30, 2018'获得日期数字字符串 '20180830'
    def getDateFromStr(s):
        a = s; #d4[0].strip()
        month=a[0:3]; month
        year=a[-4:];year
        day=re.split("[\s,]",a)[1];day
        #
        m_dict={"Jan":"01", "Feb":"02", "Mar":"03", "Apr":"04", "May":"05", "Jun":"06", 
                "Jul":"07", "Aug":"08", "Sep":"09", "Oct":"10", "Nov":"11", "Dec":"12" }
        #
        def to2(day):
            if len(day)==1:
                day="0"+day
            return day;

        return year+m_dict[month]+to2(day)
    #
    
    # 根据情况判断使用哪种方法
    raw=re.sub('<[^>]+>','', rs[1:300])
    raw=re.sub('&nbsp;', '', raw)
    if fromSys==False and (len(re.split("\|",raw))>1) and (len(re.split("words",raw))>1)  :
        #print(raw)
        d_n=getDateStrSize(raw);
        #print(d_n)  ##['Aug 30, 2018', 859]
        dateN=getDateFromStr(d_n[0]) #'20180830'
        #5.获取字数
        size=d_n[1]
        #print(dateN, size)
    else:
        ########### 方法2，从系统中获取日期。没有字数信息。
        dateN=re.sub('-','',msg_date)
        size=0
    
    
    #写入文件
    with open('backup/'+dateN+'.html','w', encoding="utf8") as f:
        f.write('<meta http-equiv="Content-Type" content="text/html; charset=utf-8">')
        f.write(title+"<br>")
        f.write(msg_desc)
        f.write(rs)
    print("Title: ", title)
    print("write in to file: http://y.biomooc.com/wangjl/en"+dateN+".html")
    
    return [msg_url,dateN, size,title,msg_desc,rs]



(2) 保存到数据库
# v0.2 desc 最长150字符
# v0.3 desc 最长180字符; 添加第三个参数，默认检查日期是否重复
def insertInfo2DB2(info,source="英语读报", checkDate=True):
    # 打开数据库连接
    db = pymysql.connect(host='y.biomooc.com',port=7070,user='root', password='123456', \
                         database='wang', charset='utf8')

    # 使用cursor()方法获取操作游标 
    cursor = db.cursor()

    #如果没有，则保存到数据库中
    def DoInsertDB(info,source=source):
        # SQL 插入语句
        sql = "INSERT INTO msg_English(msg_url,msg_origin,msg_date, msg_size, msg_title, msg_desc,msg_content) \
               VALUES ('%s', '%s', '%s', '%d', '%s', '%s','%s' )" % \
              (info[0],source, info[1],info[2],
                   pymysql.escape_string(info[3]), #title
                   pymysql.escape_string(info[4])[0:180], #desc
                   pymysql.escape_string(info[5])) #content
                #[url,dateN, size,title,msg_desc,rs]
               #(msg_url, '英语读报', dateN, size, title, msg_desc, pymysql.escape_string(rs))
        try:
            cursor.execute(sql) # 执行sql语句
            db.commit() # 提交到数据库执行
            print("commit successfully")
        except:
            rsponse=db.rollback() # 发生错误时回滚
            print("rollback")
            print( sys.exc_info() )

    #如果日期已经存在，则不进行处理

    if checkDate:
        # SQL 查询语句
        dateN2=info[1]
        #dateN2="20170102"
        sql = 'select msg_date from msg_English where msg_date like "'+dateN2+'";'

        # 执行sql语句
        cursor.execute(sql)
        values = cursor.fetchall()
        if len(values)==0:
            print("Not exist the date")
            DoInsertDB(info,source)
        else:
            print("The date "+dateN2+" has already existed.")
    else:
        DoInsertDB(info,source);

    # 关闭数据库连接
    cursor.close()
    db.close()
#



(3) 二合一函数
# 批量URL获取文章，并插入数据库
# v0.2 添加参数: checkDate

def run(start, end=-1, fromSys=False, checkDate=True):
    if end==-1:
        end=len(arrURL)
    for i in range(start, end): #随机时间段后[2s,12s]执行
    #for i in range(4,6):    
        msg_url=arrURL[i]
        print(msg_url)
        #2.get Info  return [url,dateN, size,title,msg_desc,rs]
        info= getInfoByURL2(msg_url, fromSys)

        #3.插入数据库
        insertInfo2DB2(info, checkDate=checkDate)

        #等待随机时间
        pause=1+2*random.random()
        print(str(i)+" "+ str(info[1])+' '+str(pause) )
        time.sleep(pause)
        print('='*20)
### 
run(1)
run(44)
run(19, 20, checkDate=False)

# 共 624 个，但是有一些被删除了。
> select count(*) from msg_English;
616


忘写日期了
日期重复
* The date 20190608 has already existed.

rollback
* DataError(1406, "Data too long for column 'msg_desc' at row 1"
* DataError(1406, "Data too long for column 'msg_content' at row 1")

run(321, 322, True)



(4) 一个一个添加的函数
def addOneByURL(msg_url, source="英语读报", fromSys=True):
    info= getInfoByURL2(msg_url, fromSys)
    insertInfo2DB2(info, source)
    print(str(info[1]) )
    print('='*20)
# test
addOneByURL('https://mp.weixin.qq.com/s/cBaYW7V_t7ULIA7D5FKbjQ','新英文杂志')





3. 查询结果
(1) 查找一个单词在句子中的位置
mysql> select * from msg_English where msg_content like '%reside%'\G

(2) 制作一个网页最好。
http://ielts.dawneve.cc/dict/sentence2.html?page=1&word=good


(3) 有差错重做时，结果少了几条：
select msg_id, msg_date, msg_title from msg_English2 
where msg_title not in 
(select msg_title from msg_English);
结果：
| msg_id | msg_date | msg_title
|    579 | 20181007 | NCE3 | Lesson 1 A Puma at large 逃遁的美洲狮 
|    583 | 20180724 | 英语读报：我们在中学学习的英语距离国外英语环境的差距有多大？
|    582 | 20180913 | NW | We might be heading for a crash as bad as 1929 









========================================
|-- 爬虫下载英文书: BRAVE NEW WORLD by Aldous Huxley (1894-1963)
----------------------------------------
1. 简介
网址 https://www.huxley.net/bnw/



2. 下载代码
import time, re;
import requests
from bs4 import BeautifulSoup


####### 下载第一章
fw=open('a0011.html', 'w', encoding='utf-8')
fw.write(" <meta charset='utf-8'>")

url="https://www.huxley.net/bnw/"
#    https://www.huxley.net/bnw/two.html
#1. 发出请求
url2=url #% page
respose=requests.get(url2)
assert respose.status_code==200,'Error: requests.get'
# print(respose.text)

#2. get text
soup=BeautifulSoup(respose.text,"lxml")
patterns=soup.find("blockquote")
patterns2=patterns.find("blockquote")
#patterns2

page="one"

#3. save to file
fw.write("="*20 + '<br>Chapter: '+str(page)+'<br>'+'='*20+'<br>')
fw.write(str(patterns2) + "<br>"*2+url2)
fw.write('<br>'*3)

fw.close()



# for more pages
def appendHtml(url, page, fw):
    #1. 发出请求
    url2=url % page
    respose=requests.get(url2)
    assert respose.status_code==200,'Error: requests.get'
    #2. get text
    soup=BeautifulSoup(respose.text,"lxml")
    patterns=soup.find("blockquote")
    patterns2=patterns.find("blockquote")
    #patterns2
    #3. save to file
    fw.write("="*20 + '<br>Chapter: '+str(page)+'<br>'+'='*20+'<br>')
    fw.write(str(patterns2) + "<br>"*2+url2)
    fw.write('<br>'*3)

fw=open('a0011.html', 'a', encoding='utf-8')
# test
#url="https://www.huxley.net/bnw/%s.html"
#appendHtml(url, "two", fw)

pages=["two","three", "four", "five", "six", "seven", "eight", "nine", "ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen", "sixteen", "seventeen", "eighteen"]
for page in pages:
    print(page)
    appendHtml(url, page, fw)
print("==end==")

fw.close()




3. 下载后的文件
add title, desc

IELTS reading/novel/dustbin/BRAVE_NEW_WORLD.html
IELTS reading/novel/Brave_new_world.txt









========================================
测试词汇量的网站
----------------------------------------
http://testyourvocab.com/




========================================
如何记忆单词？做一个艾宾浩斯记忆曲线背单词工具 //todo
----------------------------------------
1.这个效果和配色挺好的：
http://dict.bioon.com/word/8000.asp?c=81&t=1

我做的版本：引用了百度翻译
http://ielts.biomooc.com/wordKing/




第一个复习周期：2天
第二个复习周期：4天
第三个复习周期：7天
第四个复习周期：20天

举个例子：假设今天新建的单词表为「List_20」,也就是说这份单词表要在建立日期后的第2天，第4天，第7天和第20天复习。




========================================
在线英语词典、英语翻译
----------------------------------------
词典:get
#英汉
https://fanyi.baidu.com/#en/zh/stalk
http://dict.youdao.com/w/eng/stalk/
https://dictionary.cambridge.org/dictionary/english-chinese-simplified/stalk
https://cn.bing.com/dict/SerpHoverTrans?q=stalk
http://dict.cn/stalk
http://www.iciba.com/stalk
https://dict.hjenglish.com/w/stalk
http://odict.net/stalk/

https://translate.google.cn/#view=home&op=translate&sl=en&tl=zh-CN&text=stalk


# 英英
#柯林斯
https://www.collinsdictionary.com/dictionary/english/stalk
#牛津
https://www.oed.com/search?searchType=dictionary&q=stalk&_searchBtn=Search
https://www.oxfordlearnersdictionaries.com/definition/english/stalk_1?q=stalk
#朗文
https://www.ldoceonline.com/dictionary/stalk
#韦氏
https://www.merriam-webster.com/dictionary/stalk
http://www.webster-dictionary.net/definition/stalk
http://www.learnersdictionary.com/definition/stalk
#
https://www.lexico.com/en/definition/stalk
https://www.vocabulary.com/dictionary/stalk
https://www.thefreedictionary.com/stalk
https://www.yourdictionary.com/stalk
https://www.macmillandictionary.com/dictionary/british/stalk_1




词典:post
https://cn.bing.com/translator/
https://translate.google.cn/
https://fanyi.qq.com/





========================================
|-- 必应词典：悬浮取词
----------------------------------------

1. 必应首页，悬浮取词，返回的dom可以直接插入页面，并悬浮显示。
https://cn.bing.com/dict/SerpHoverTrans?q=profound

<div>
	<span id="ht_logo"></span>
	<h4>profound</h4>
	<span class="ht_attr" lang="en">[prə'faʊnd] </span>
	<ul>
		<li><span class="ht_pos">adj.</span><span class="ht_trs">巨大的；深切的；深远的；知识渊博的</span></li>
	</ul>
	<ul>
		<li><span class="ht_pos">n.</span><span class="ht_trs">大洋；深渊；(灵魂)深处</span></li>
	</ul>
</div>


嵌套到原文div#ht_content中
<div id="ht_pop" class="hts_pop" style="display: block; left: 532px; top: 273px;">
	<div id="ht_content"><div><h4>profound</h4><span class="ht_attr" lang="en">[prə'faʊnd] </span><ul><li><span class="ht_pos">adj.</span><span class="ht_trs">巨大的；深切的；深远的；知识渊博的</span></li></ul><ul><li><span class="ht_pos">n.</span><span class="ht_trs">大洋；深渊；(灵魂)深处</span></li></ul></div></div>
	
	<div id="ht_footer">
		<span id="ht_logo"></span>
		<a href="/search?q=how+brazil+industry+retreat+&amp;qs=n&amp;sp=-1&amp;pq=how+brazil+industry+retreat+&amp;sc=0-28&amp;sk=&amp;cvid=0293D34B6E63450D868F88A59812D553&amp;sid=0C176A10B8AB62370CDE67D5B9856353&amp;format=snrjson&amp;jsoncbid=0&amp;hta=off&amp;form=D3RE" onclick="return HT.closeHoverBox();" class="ht_close">关闭取词</a>
		<a href="https://bingdict.chinacloudsites.cn/" target="_blank" class="ht_download">Download Client</a>
	</div>
</div>




(2)js 
https://cn.bing.com/s/as/8_1_2_6229282/MsnJVData/HoverTranslation.js

(3)样式表
https://cn.bing.com/s/ac/8_1_2_6229282/MsnJVData/HoverTranslationV2.css

/* Hover Translation CSS. Note: Only use single quote because this file will be crunched to HoverTranslation javascript file*/
#ht_pop {
    overflow: auto;
    position: absolute;
    display: none;
    background: white;
    z-index: 99999;
}

.hts_pop {
    width: 295px;
    font-size: 13px;
    border: 1px solid #e0e0e0;
    box-shadow: 0 2px 6px #E0E0E0;
}

    .hts_pop #ht_content {
        margin: 15px 15px 0px;
        padding-bottom: 10px;
        overflow: hidden;
        border-bottom: 1px solid #e0e0e0;
    }

    * html .hts_pop #ht_content {
        height: expression((this.childNodes.length && this.childNodes[0].offsetHeight > 272 ) ? '272px' : 'auto');
    }

        .hts_pop #ht_content div {
            width: 265px;
            max-height: 275px;
            overflow: hidden;
        }

    .hts_pop h4 {
        margin: 0 5px 6px 0;
        padding: 0;
        font-size: 20px;
        font-weight: bold;
        display: inline-block;
        line-height: 24px;
        word-break: break-all;
        color: #444444;
    }

    .hts_pop ul {
        font-size: 13px;
        margin: 0;
        padding: 0;
        color: #444444;
    }

        .hts_pop ul li {
            font-size: 13px;
            margin: 0;
            padding: 0;
            line-height: 21px;
            list-style-type: none;
        }

    .hts_pop .ht_attr {
        _font-family: Lucida Sans Unicode,sans-serif;
        line-height: 24px;
        color: #737373;
        vertical-align:top;
    }

#ht_logo {
    background: url('/fd/s/cn/dict_logo_ht.png') center no-repeat;
    display: inline-block;
    width: 18px;
    height: 18px;
    vertical-align: -3px;
}

#ht_footer {
    height: 30px;
    margin: 0 12px;
    line-height: 30px;
}

    #ht_footer a {
        display: inline-block;
        margin-left: 2px;
    }

i {
    font-style: normal;
}

.hts_pop .ht_trs {
    margin-left: 10px;
}

.hts_pop .ht_close {
    float: right;
    margin-right: 3px;
    vertical-align: top;
}

.hts_pop .ht_more {
    display: block;
}

.hover_target {
    background: #a7d8ff;
}

/* Hide download link*/
#ht_footer > #ht_logo, #ht_footer > .ht_download {
    display: none;
}



========================================
|-- 爬虫抓取必应词典条目，插入数据库
----------------------------------------
http://y.biomooc.com:7000/notebooks/web/getWords.ipynb


1.爬虫抓取单词数据(音标、意思)，到本地文件
import re
import requests
import random,time

################
# part1 给出单词，获取单词，并写下单词、音标、意思到文本文件
################
def scrawWord(word):
    response=requests.get('https://cn.bing.com/dict/SerpHoverTrans?q='+word)
    #print(response.status_code)# 响应的状态码 200
    #print(response.content)  #返回字节信息
    #response.text  #返回文本内容
    
    #正则解析内容
    #音标
    phoneticSymbol=re.findall(r'lang="en">(.*?)</span>',response.text,re.S)  #re.S 把文本信息转换成1行匹配
    if len(phoneticSymbol)<1:
        phoneticSymbol=''
    else:
        phoneticSymbol=phoneticSymbol[0]
    #print(phoneticSymbol[0])

    #意思
    meaningArr=re.findall(r'<ul>(.*?)</ul>',response.text,re.S)  #re.S 把文本信息转换成1行匹配
    meaning='<ul>'+'</ul><ul>'.join(meaningArr) +'</ul>';
    #print( meaning )
    
    #拼接起来
    arr=[word, phoneticSymbol.strip(), meaning]
    wordStr='\t\t'.join(arr)
    
    #写入文件; 单词、音标，意思
    fw=open('word_ms2.txt','a')
    fw.write(wordStr+'\n')
    fw.close()
#test
#word="profound"
#scrawWord(word)


################
# part2 读取单词列表(cet6大概5k多个单词)，逐个进行
################
def now():
    return time.strftime("%Y-%m-%d %H:%M:%S", time.localtime()) #'2018-09-27 21:15:01'
#

print('task begins:',now())
fr2=open('/home/wangjl/web/docs/docs/words.js')
lines=fr2.readlines();
i=0
for i in range(len(lines)):
    lineR=lines[i]
    if i>20:
        #break;
        pass
    word=lineR.strip().strip(',').strip("'")
    scrawWord(word)
    #休眠，等待随机时间后执行函数
    rt=0.5+3*random.random() #0-1之间
    time.sleep(rt)
    #进度条
    if i%100==0:
        print(i, '|'+word+"|", now(),rt)

fr2.close()
print('==end==')






2. 插入数据库
(1)创建数据库
drop table if exists word_ms; 
CREATE TABLE `word_ms` (
  `id` int(10) NOT NULL AUTO_INCREMENT,
  `word` varchar(50) DEFAULT NULL,
  `phoneticSymbol` varchar(100) DEFAULT NULL,
  `meaning` text,
  `modi_time` varchar(30) DEFAULT NULL,
  `add_time` varchar(30) DEFAULT NULL,
  PRIMARY KEY (`id`),
  #Unique KEY `word` (`word`)
  KEY `word` (`word`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;


mysql> desc word_ms;
+----------------+--------------+------+-----+---------+----------------+
| Field          | Type         | Null | Key | Default | Extra          |
+----------------+--------------+------+-----+---------+----------------+
| id             | int(10)      | NO   | PRI | NULL    | auto_increment |
| word           | varchar(50)  | YES  | UNI | NULL    |                |
| phoneticSymbol | varchar(100) | YES  |     | NULL    |                |
| meaning        | text         | YES  |     | NULL    |                |
| modi_time      | varchar(30)  | YES  |     | NULL    |                |
| add_time       | varchar(30)  | YES  |     | NULL    |                |
+----------------+--------------+------+-----+---------+----------------+
6 rows in set (0.00 sec)






(2)使用py插入数据
#local_time=time.localtime(add_time) #这种格式太长了，没啥用
##time.struct_time(tm_year=2019, tm_mon=10, tm_mday=26, tm_hour=18, tm_min=21, tm_sec=2, tm_wday=5, tm_yday=299, tm_isdst=0) 
#human_time=time.strftime("%Y-%m-%d %H:%M:%S", local_time) #2019-10-26 18:21:02 显示格式
#print(add_time, local_time, human_time)


################
# part3 插入数据库
################
import re

#创建数据库 略

#链接数据库
import pymysql
# 打开数据库连接
db = pymysql.connect(host='y.biomooc.com',port=7070,user='root', password='123456', database='wang')
# 使用cursor()方法获取操作游标 
cursor = db.cursor()

print('==begin==')
#读取数据，拼接sql语句
fr=open('word_ms2.txt','r')
lines=fr.readlines();
for i in range(len(lines)):
    line=lines[i].strip()
    if i>20:
        #break;
        pass
    arr=re.split('\t\t',line)
    
    # SQL 语句
    add_time=int(time.time()) #1572085262 数据库保存这种格式
    #mysql 转义 content = db.escape_string(content)
    sql="insert into word_ms(word,phoneticSymbol,meaning,add_time) values('%s','%s','%s',%d)" %  \
    (arr[0],db.escape_string(arr[1]),db.escape_string(arr[2]), add_time)
    #print(sql+'\n')
    # 执行sql语句
    rs=cursor.execute(sql)
    if i%1000==0:
        print(i,arr[0],rs)
        pass

#关闭文件
fr.close()

# 关闭数据库连接
db.commit();
cursor.close()
db.close()

print('==end==')



缺点：对于大小写，mysql没有区分，貌似需要调节编码方式。
May和may是不同的，但是目前无差别，甚至被认为是重复。
//todo





(3)web访问
<script type="text/javascript">
$(document).ready(function(){
  $("#btn1").click(function(){
      var word=$('#word').val()
      $.get('http://127.0.0.1:5000/api/dict/'+word, function(res){
        console.log(res)
        $('#show').html( res.word +'<br>'+ res.phoneticSymbol +'<br>'+res.meaning);
      })
  });
</script>

web后台接口
#字典查询后台接口
@app.route('/api/dict/<word>', methods=['GET'])
def getword(word):
    #链接数据库
    import pymysql
    # 打开数据库连接
    db = pymysql.connect(host='y.biomooc.com',port=7070,user='root', password='123456', database='wang',charset='utf8')
    # 使用cursor()方法获取操作游标 
    cursor = db.cursor()
    #sql语句
    sql='select * from word_ms where word="'+word+'";'
    # 执行sql语句
    cursor.execute(sql)
    results = cursor.fetchall()
    # 关闭数据库连接
    cursor.close()
    db.close()

    result=results[0]
    print(word, result)

    #准备返回值
    response = jsonify({
        'word': result[1], 
        'phoneticSymbol':result[2], 
        'meaning':result[3]
    })
    #允许跨域访问
    response.headers.add('Access-Control-Allow-Origin', '*')
    return response
#















========================================
|-- 添加牛津3000-5000单词标签
----------------------------------------
1.来源：
(1)
下载： https://www.oxfordlearnersdictionaries.com/wordlists/oxford3000-5000


(2)
解释：https://www.oxfordlearnersdictionaries.com/about/wordlists/oxford3000-5000

1)What is the Oxford 3000?
The Oxford 3000 is a list of the 3,000 core words that every learner of English needs to know.

The words have been chosen based on their frequency in the Oxford English Corpus and relevance to learners of English. Every word is aligned to the CEFR, guiding learners on the words they should know at A1-B2 level.


2)
What is the Oxford 5000?
The Oxford 5000 is an expanded core word list for advanced learners of English.

As well as the Oxford 3000 core word list, it includes an additional 2,000 words that are aligned to the CEFR, guiding advanced learners at B2-C1 level on the most useful high-level words to learn to expand their vocabulary.


3)
CEFR stands for the ‘Common European Framework of Reference’ for languages, which is a description of the language abilities of students at different levels of learning. The CEFR can be used to compare standards in language learning and create teaching programmes.

It grades language skills at six levels:

A1 and A2 indicate elementary and pre-intermediate levels of ability.
B1and B2 indicate lower- and upper-intermediate levels.
C1 indicates advanced level.
C2 indicates complete proficiency in the language.



(3) OX没有C2词汇
https://tracktest.eu/english-levels-cefr/

https://www.examenglish.com/CEFR/cefr.php
https://www.examenglish.com/CEFR/C2.htm





2.代码
## add tag to db
#step1 check if the word in DB
import re,time,os
import requests

#需要跑很多遍，run=1,测试单词是否在db,需要至少跑两次；
#run=2 测试单词是否完全相同，如有不同的，则修改
#run=3 添加标签到db
run=3

fpath='/home/wangjl/web/docs/word/ox3000.txt'
#fpath='/home/wangjl/web/docs/word/ox5000.txt'
fr=open(fpath,'r')
i=0
mydb=DBUtil()
for lineR in fr.readlines():
    i+=1;
    if i>10:
        #break;
        pass
    line=lineR.strip();
    arr=re.split('\s',line)
    word=arr[0]
    tag=arr[-1]
    #print(line, '|',word, tag)
    #查询是否有？
    sql='select * from word_ms where word="'+word+'";';
    rs=mydb.query(sql)
    if len(rs)!=1:
        url="http://10.21.127.192:20180/api/dict/"+word;
        if run==1:
            res=os.system("wget "+url)
            time.sleep(0.5)
        print('==============>',i,word, '|', len(rs),res )
    else:
        if run<2:
            continue;
        #有这个单词，且只有一个
        word2=rs[0];
        wid=int(word2[0])
        if word2[1]!=word:
            print('==Not equal===>',wid, word2[1],'|',word,tag)
        
        #
        if run<3:
            continue;
        sql='update word_ms set tag_ox="%s" where id=%d;' %(tag,wid);
        rs=mydb.execute(sql)
        # 进度条
        if i%100==0:
            print(wid, word2[1],'|',word,tag,'|', rs)
fr.close();
print('end')




========================================
|-- 雅思单词表，及标签
----------------------------------------
1.
雅思word list:
https://github.com/woshichuanqilz/others/blob/master/WindowsConfig/IELTS


添加新列，雅思词汇 tag_ielts: 第一批3000个标签为1, 默认是0；
alter table word_ms add tag_ielts int(3) DEFAULT 0 comment '雅思词汇' after tag_ox;
## ALTER TABLE word_ms DROP tag_ielts;





2.代码（依赖python 自定义mysql类）
## add tag to db
#step1 check if the word in DB
import re,time,os
import requests

#run=0 测试单词是否在db，没有则打印出来
#需要跑很多遍，run=1,测试单词是否在db,如果没有，则添加到db，需要至少跑两次；

#run=2 测试单词是否完全相同，如有不同的，则手动修改
#run=3 添加标签到db
run=3

#fpath='/home/wangjl/web/docs/word/ox3000.txt'
#fpath='/home/wangjl/web/docs/word/ox5000.txt'
#fpath='/home/wangjl/web/docs/word/freq2000.txt'
fpath='/home/wangjl/web/docs/word/ielts.txt'

fr=open(fpath,'r')
i=0
mydb=DBUtil()
for lineR in fr.readlines():
    i+=1;
    if i>100:
        #break;
        pass
    line=lineR.strip();#空白行跳过
    if len(line)==0:
        continue;
    
    arr=re.split('\s',line)
    word=arr[0]; word=word.strip('*');
    tag=arr[-1]
    #print(line, '|',word, tag)
    #查询是否有？
    sql='select * from word_ms where word="'+word+'";';
    rs=mydb.query(sql)
    #print(word, len(rs) )
    if len(rs)!=1:
        if run==0: 
            if  len(rs)==0:#打印出不在数据库的单词
                print('===0收录===>',word, len(rs) )

            if len(rs) >0:#对于多个词条，跳过
                print('==多个词条==>',word, len(rs) )
            continue; 
        url="http://10.21.127.192:20180/api/dict/"+word;
        
        if run==1:
            res=os.system("wget "+url)
            time.sleep(0.5)
            print('======插入DB========>',i,word, '|', len(rs),res )
    else:
        if run<2:
            continue;
        #有这个单词，且只有一个
        word2=rs[0];
        wid=int(word2[0])
        if word2[1]!=word and run==2:
            print('==Not equal===>',wid, word2[1],'|',word,tag)
        
        #
        tag='1'
        if run<3:
            continue;
        sql='update word_ms set tag_ielts="%s" where id=%d;' %(tag,wid);
        rs=mydb.execute(sql)
        # 进度条
        if i%100==0:
            print(wid, word2[1],'|',word,tag,'|', rs)
fr.close();
print('==end==; run=',run, '; i=',i)




3.统计个数
mysql> select count(*) from word_ms where tag_ielts=1;
## 3593




========================================
|-- 统计编号中断的单词编号，并添加新词
----------------------------------------
1. 不存在的编号
select model2.id-1 as noExistID from 
	(select model1.id from wang.word_ms as model1) as model2 
where model2.id>1 and not exists 
	(select model3.id from wang.word_ms as model3 where  model3.id=model2.id-1);
#

+-----------+
| noExistID |
+-----------+
|      1131 | *
|      5506 |
|      5523 |
|      5528 |
|      5535 |
|      5540 |
|      5547 |
|      5563 |
|      5565 |



(2) check 
mysql> select * from word_ms where id=1131;
Empty set (0.00 sec)



(3) 插入新值
insert into word_ms(id, word) values(1131, 'twitchiness');

然后用web补充完善发音和意思
http://ielts.dawneve.cc/dict/updateWord.html?id=1131

陌生程度strangeness 最高
> update word_ms set strangeness=10 where id=1131;


(4) check 
> select * from word_ms where id=1131;









========================================
|-- 汉英字典 //todo
----------------------------------------
1. 可用版：没有界面


(1)只能win cmd登陆
G:\xampp\mysql\bin>mysql -h y.biomooc.com -P 7070 -u root -p

(2) 
MySQL [(none)]> select * from wang.word_ms where meaning like '%推测%'\G

为什么使用ubuntu shell不能输入中文呢？ //todo




2. web界面版

//todo 




========================================
dawn语料库：最新已经有web版
----------------------------------------
1.数据库设计
dawn语料库，以行为单位保存(一行可能包含很多句子)
CREATE TABLE `sentence_dawn` (
  `id` int(10) NOT NULL AUTO_INCREMENT,
  `line` text,
  `source` varchar(50) DEFAULT NULL,
  `add_time` varchar(30) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;



2.给出文本，插入到数据库
#task: 给出一个文本，按照行插入数据库中。
#过滤掉：空行，you焊丝的行，重复的行，一行有且仅有一个句子且少于5个单词的
#v0.2 调整过滤
import re,time
def insertParaToDB(fname, source):
    mydb=DBUtil() #我的自定义mysql类，在python/入门中有
    #fname="/home/wangjl/web/docs/docs/NCE4.txt"
    #source='NCE4'
    
    add_time=int(time.time()) #插入时间
    fr=open(fname,'r',encoding='utf8')
    i=0
    j=0
    for lineR in fr.readlines():
        i+=1
        if i>100:
            #break
            pass
        line=lineR.strip()
        arr=re.split('[.?!]+',line)
        marker='OK'

        #过滤空行
        if len(line)==0:
            continue;
        #过滤带汉字的行
        if re.search(r'[\u4e00-\u9fa5\|]+',line)!=None:
            marker='No_汉字';
            continue;
        #过滤重复的行
        if re.search('Listen to the tape then answer the question below',line)!=None:
            marker='No_重复';
            continue;
        if re.search('https{0,1}://www',line)!=None or re.search('doi: ',line)!=None:
            marker='No_URL'
            continue;
        
        if len(arr)==1 and len(re.split('\s+',arr[0]) )<5:
                marker='No_仅有一句，且这一句不到5个单词'
                continue

        #整句的保存到数据库中
        j+=1
        rs=''
        sql="insert into sentence_dawn(line,source,add_time) values('%s','%s',%d);" % ( mydb.db().escape_string(line), source,add_time)
        rs=mydb.execute(sql)
        #print(j,line)
        #抽样检查
        if j%10==0:
            print('='*20,j,i,marker, len(arr),' | ',line)
            pass

    fr.close()
    print('==end== 实际插入行数 j=',j, '; 总行数 i=',i)
    

#test
fname="/home/wangjl/web/docs/txt/a1.txt"
source='Nature'
insertParaToDB(fname, source)

#test
fname="/home/wangjl/web/docs/docs/NCE4.txt"
source='NCE4'
insertParaToDB(fname, source)



3. 查询

统计
select * from sentence_dawn order by add_time DESC, id DESC limit 5;
select count(*) from sentence_dawn;

按照单词查找
select * from sentence_dawn where line like "%risk%" order by add_time DESC, id DESC limit 5;

添加了web页面，用于添加语料库。





========================================
权威引文字典
----------------------------------------

1.一百多GB的MDX词库资源集合下载，类ftp站 
https://mdx.mdict.org/
Mdict词库资源，免费下载mdx/mdd/css文件，支持欧路，深蓝，goldendict等APP软件！



2. 牛津高阶英汉双解词典（第9版）完整免费下载
https://mdict.org/post/oxford-9/




========================================
在线代理 查看原文
----------------------------------------
https://proxysite.page/en






========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------

