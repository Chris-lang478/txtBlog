scSeq-c1-RNA测序分析笔记



========================================
[经典]Question: Single Cell RNAseq data analysis protocol
----------------------------------------
(1) Tophat - Cufflink - Cuffdiff; 
(2) Subread - featureCounts - DESeq2; 
(3) STAR - RSEM - EBSeq; 
(4) Bowtie - eXpress - edgeR; 
(5) kallisto - sleuth; 
(6) HISAT - StringTie - Ballgown.

1.https://www.biostars.org/p/199310/
This tutorial was recently posted here: Analysis of single-cell RNA-seq data


2. I started a list of single-cell analysis software, tutorials and workshops here:
https://github.com/seandavi/awesome-single-cell




3. current issue of Genome Biology: Single-Cell Omics ( special issue)
Genome Biology highlights the emergence of this field with a special issue focused on single-cell methods and their applications.
http://www.biomedcentral.com/collections/singlecellomics



4. [经典]Tutorial: Analysis of single-cell RNA-seq data
github:https://github.com/hemberg-lab/scRNA.seq.course
web: http://hemberg-lab.github.io/scRNA.seq.course/index.html
pdf: http://hemberg-lab.github.io/scRNA.seq.course/scRNA-seq-course.pdf


http://hemberg-lab.github.io/scRNA.seq.course/construction-of-expression-matrix.html#mapping-qc

A survey of best practices for RNA-seq data analysis
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4728800/

sam文件格式：https://github.com/DawnEve/NGS_training/blob/master/day3.markdown

c1测序分析(P5)：http://www.pnas.org/content/113/12/3293.full.pdf




5. RNAseq的39个工具
文献：Sahraeian S M E, Mohiyuddin M, Sebra R, et al. Gaining comprehensive biological insight into the transcriptome by performing a broad-spectrum RNA-seq analysis[J]. Nature Communications, 2017, 8(1):59.

这是一篇在NC上发表的使用RNAseq工具对比的一篇文献，解读这篇文献对我们使用RNAseq发文提供了思路。

http://www.a-site.cn/article/1567422.html
http://www.360doc.com/content/17/1002/18/45962007_691819499.shtml



6.sanger研究所： Single Cell Bioinformatics Tools and Software
At the Wellcome Genome Campus, both the EBI and Sanger Institute are continually developing tools and software to help in the processing and analysing Single Cell data.

https://www.singlecellbioinformatics.org/tools/



7.单细胞splicing的研究
BRIE: transcriptome-wide splicing quantification in single cells
https://genomebiology.biomedcentral.com/articles/10.1186/s13059-017-1248-5




========================================
c1单细胞测序基本概念
----------------------------------------

========================================
|-- c1测序技术官网主页
----------------------------------------
http://cn.fluidigm.com/products/c1-system

软件下载：
http://cn.fluidigm.com/software

1. C1 mRNA Seq HT Demultiplex Script

demultiplex n. 多路分用；反多路转换；信号分离；分工

C1_mRNA_Seq_HT_Demultiplex_Script_v2_0_1-.zip (mRNASeqHT_demultiplex.pl)
http://cn.fluidigm.com/binaries/content/documents/fluidigm/consumables/software/c1-mrna-seq-ht-demultiplex-script/c1-mrna-seq-ht-demultiplex-script/fluidigm%3Afile

The C1™ mRNA Sequencing High Throughput Demultiplexer Perl script application programming interface (API) allows automatic demultiplexing of individual single-cell samples from each column using the cell barcodes on the R1 reads. The API also automatically separates the large FASTQ file generated from each column pool into 40 pairs. This enables your C1 medium-cell HT IFC data to be preprocessed in a more efficient way.
使用perl把细胞分成40对。（可能就是40行，每行有Read1和Read2）



========================================
|-- c1芯片 - IFC Chip (C1™ Single-Cell Auto Prep Integrated Fluidic Circuit)
----------------------------------------

2. c1, Fluidigm
http://cn.fluidigm.com/

(1)c1芯片
http://cn.fluidigm.com/reagents/genomics/101-4982-c1-single-cell-mrna-seq-ht-ifc-10-17um-5ifcs

C1™ Single-Cell mRNA Seq HT 10-17 µm—5 IFCs (Replaces product 101-0222)
Five C1 Single-Cell mRNA Seq HT IFC for capture, lysis, reverse transcription and cell multiplexing of 800 individual medium cells (10–17 µm).

Reagents sold separately. Replaces product 101-0222.

(2) 标准品
C1™ RNA Standard Assays
Primers for 3 internal RNA spike control assays sufficient for 50 C1 IFCs.


(3)c1 单细胞测序的技术噪声
https://www.nature.com/articles/nmeth.2645

Cell capture and library preparation for mouse cells using the Fluidigm C1 system.
用96孔板捕获单细胞，显微镜镜检有不是单细胞的去掉。
2,000 cells were loaded onto a 10- to 17-μm C1 Single-Cell Auto Prep IFC (Fluidigm), and cell capture was performed according to the manufacturer's instructions. The capture efficiency was inspected using a microscope, and there were single cells in 93 positions and two cells in three positions. These three positions were noted, and the data from these cells were subsequently removed from analysis.

细胞裂解，加入ERCC内参，合成cDNA，PCR扩增。
Upon capture, reverse transcription and cDNA preamplification were performed in the 10- to 17-μm C1 Single-Cell Auto Prep IFC using the SMARTer PCR cDNA Synthesis kit (Clontech) and the Advantage 2 PCR kit (Clontech). 1 μl of the ERCC Spike-In Control Mix (Ambion) in a 1:400 dilution in C1 Loading Reagent was added to the lysis mix.


稀释cDNA，Nextera建库。混库，在HiSeq上8通道PE75测序。
cDNA was harvested and diluted to a range of 0.1–0.3 ng/μl, and Nextera libraries were prepared using the Nextera DNA Sample Preparation Kit and the Nextera Index Kit (Illumina) by following the instructions in the Fluidigm manual “Using the C1 Single-Cell Auto Prep System to Generate mRNA from Single Cells and Libraries for Sequencing.” Libraries were pooled, and paired-end 75-bp sequencing was performed on eight lanes of an Illumina HiSeq. All experiments involving mice were approved by the local ethical review committee, and a certificate of designation from the UK Home Office (the national authority for animal experimentation) was obtained.




比对和标准化 Mapping of reads and normalization for the mouse data set (91 cells).
PE读段用GSNAP(版本号2013-02-05)软件map到38.70鼠基因组和ERCC上，默认参数。有两个reads数太少去掉了，剩下91个细胞。随后操作和A. thaliana数据一样。
Paired-end reads were mapped simultaneously to the M. musculus genome (Ensembl version 38.70) and the ERCC sequences using GSNAP (version 2013-02-05)17 with default parameters. Two cells were removed at this stage owing to very low numbers of reads mapping to these libraries, which left 91 cells in total. From here we proceeded as described for the A. thaliana data.





========================================
|-- ERCC spike-ins(Ambion)
----------------------------------------
https://www.biostars.org/p/217961/

Hello!

I apologise if I am asking a basic question but I was wondering if someone here could clue me in about the role of ERCC spike-in for RNA-Seq?

I've been given a few sets of RNA-Seq data to align to a reference genome and do differential gene expression analysis. I was going to do this via mapping to the reference as opposed to de novo.

I noticed when blasting my over-represented sequences generated from FASTQC that in one sample, I had an over-represented sequence caused by the ERCC spike in. I've tried to understand the role of this in differential gene expression analysis but I'm struggling a bit.

My questions are:

1)Is it normal to present as an over-represented sequence in 1 sample only? 2) Do I need to remove it for mapping and differential expression analysis? 3) If I need to remove it, what's the best way of going about it?

Thank you very much in advance,

Gill




========================================
|-- UMI
----------------------------------------
1.  UMI(4-10bp)是反转录时添加上的。方便去除扩增噪音干扰。
barcodes (4^N, where N is the length of UMI) 数目远小于一个细胞内的分子数，所以鉴定unique分子，要同时使用barcode and mapping location (transcript)。
当使用UMI时，一般只测有UMI的一端（通常是3'端）。

2.步骤
第一步是map UMI reads，推荐使用STAR，因为它快速且输出高质量BAM比对文件。另外，mapping location也很有用，比如识别转录本的不良注释的3'端UTR。

UMI测序通常使用PE测序，一端捕获cell和UMI barcode，另一端测序外显子序列。
注意： 推荐trimming and/or filtering 含有polyA的reads，防止他们含有内部polyA/polyT导致mapping error。

处理过UMI实验的reads后，通常还要：
1)UMI加到另一个配对read的名字上；
2)reads通过cell barcode分到不同的文件中。
	对于特别大量、浅数据集，cell barcode也可以加到read name上，来避免过多文件。


3.对barcode计数
实际上不是每个UMI对应一个分子，因为：
1）不同的UMI不一定就是不同的分子：UMI有可能扩增时出错。
2）不同的转录本不一定就是不同的分子：比对错误以及multimapping导致错误。
3）相同UMI不一定意味着同一个分子：UMI有编好，可能一个UMI结合到不同mRNA分子上。

4.矫正UMI错误的方法
1).UMI-tools’ directional-adjacency method implements a procedure which considers both the number of mismatches and the relative frequency of similar UMIs to identify likely PCR/sequencing errors.
2).Currently an open question. The problem may be mitigated by removing UMIs with few reads to support their association with a particular transcript, or by removing all multi-mapping reads.
3).Simple saturation (aka “collision probability”) correction proposed by Grun, Kester and van Oudenaarden (2014) to estimate the true number of molecules  
M

可视化检测方法：做log2(UMIs)-log2(Reads)图.

如何最佳的处理UMI是生信学术界一个热点。当前已经开发的方法包括：
	UMI-tools
	PoissonUMIs
	zUMIs
	dropEst

5.下游处理方法
当前UMI平台(DropSeq, InDrop, ICell8)的捕获效率很低、且变异很大。


实例：
Exercise 1 We have provided you with UMI counts and read counts from induced pluripotent stem cells generated from three different individuals (Tung et al. 2017) (see: Chapter 3.8 for details of this dataset)
http://hemberg-lab.github.io/scRNA.seq.course/construction-of-expression-matrix.html#ref-Tung2017-ba

6.
read QC or mapping QC 不合格的细胞都要remove。否则会干扰下游分析。
因为没有同意的标准，所以我们的QC都是和大多数比剔除离群值。

有一个c1平台测序的数据集：
http://hemberg-lab.github.io/scRNA.seq.course/construction-of-expression-matrix.html#expression-qc-reads
中的3.8.2部分。








========================================
|-- 细胞系(MDA-MB-468细胞系和HeLa细胞系)
----------------------------------------
1.细胞系
(1)小鼠胚胎成纤维细胞；MEF细胞
http://www.anhuibio.com/product/detail.html?id=1374

细胞名称	 小鼠胚胎成纤维细胞；MEF
形态特性	  成纤维细胞样　
生长特性	 贴壁生长　
特征特性	  取孕9天的615小鼠胚胎，去除脑、心脏等培养建立。该细胞可用作饲养层细胞，支持胚胎干细胞ES的生长并维持ES未分化的状态。当作为饲养层细胞时，MEF需经丝裂霉素C处理停止生长。建议作为ES细胞的饲养层时，MEF不要超过6代。 
培养条件	  DMEM-H: Dulbecco＇s Modified Eagle＇s Medium (DME H-21 4.5g/Liter Glucose)  10%CS　
传代方法	  1:3传代；3~4天1次。
传代情况	 P1
冻存条件	  基础培养基+8%DMSO+20%FBS　
支原体检测	 培养法（-）　

(2) MDA-MB-468细胞系
https://www.atcc.org/products/all/HTB-132.aspx

Organism	Homo sapiens, human
Tissue	
mammary gland/breast; derived from metastatic site: pleural effusion
Product Format	frozen
Morphology	epithelial
Culture Properties	adherent

Disease	adenocarcinoma
Age	51 years
Gender	female
Ethnicity	Black
Applications	
This cell line is a suitable transfection host.
Storage Conditions	liquid nitrogen vapor phase

Derivation:
The MDA-MB-468 cell line was isolated in 1977 by R. Cailleau, et al., from a pleural effusion of a 51-year-old Black female patient with metastatic adenocarcinoma of the breast.


Antigen Expression:	
Blood Type AB; HLA Aw23, Aw30, B27, Bw35, Cw2, Cw4 (patient)

Receptor Expression:	
epidermal growth factor (EGF); transforming growth factor alpha (TGF alpha)

Comments:	
Although the tissue donor was heterozygous for the G6PD alleles, the cell line consistently showed only the G6PD A phenotype. There is a G -> A mutation in codon 273 of the p53 gene resulting in an Arg -> His substitution. EGF receptor is present at 1 X 106 per cell.










========================================
|-- 细胞同步
----------------------------------------

3.细胞同步 胸苷法
(1)S期同步化方法
https://baike.baidu.com/item/%E7%BB%86%E8%83%9E%E5%90%8C%E6%AD%A5%E5%8C%96/9333283?fr=aladdin
胸腺嘧啶核苷(TdR)双阻断法：该法利用过量TdR能阻碍DNA合成的原理而设计，为了加强细胞同步化效果，常采用两次TdR阻断法，即双阻断法。第1次阻断时间相当于G2、M和G1期时间的总和或稍长，释放时间不短于S期时间，而小于G2+M+G1期时间，这样才能使所有位于G1/S期的细胞通过S期，而又不使沿周期前进最快的细胞进入下一个S期。第2次阻断时间同第1次，再释放。现以HeLa细胞为例加以说明(HeLa细胞周期时间为21 h，其中G1期为10 h，S期为7 h，G2期为3 h，M期为1 h)。
1．将细胞培养至指数生长期的早期。
2．加入含2 mmol/L TdR的培养基(2—2．5 mmol/L用于肿瘤细胞的同步化培养，而CHO细胞则用7 mmol/L TdR)，作用16 h。
3．弃掉TdR培养基，用Hanks液洗2—3次，再换上新鲜培养基继续温浴9 h。
4．重新加入TdR培养基(浓度同上)进行第2次阻断，作用16 h。
5．再弃掉TdR培养基，Hanks液洗2—3次后换上普通培养基。第2次TdR释放0 h时取样则细胞处于G1/S期交界处；如2-7 h取样则为不同阶段的S期细胞。 注意：具体TdR作用和释放的时间应参考每一种待同步化细胞的细胞周期各时相测定的参考值，也可根据经验确定。

(2)为什么做细胞同步化？
http://www.dxy.cn/bbs/topic/329264
细胞同步化的都是使细胞停止在细胞周期的某一时相。细胞同步化的方法有：短时饥饿法，放射法、机械震动法、药物抑制法等。这些方法可结合使用。我们见得最多的是短时饥饿法，即血清饥饿。还有，比如用抑制DNA合成的药物，大剂量的氨甲蝶呤、5-溴脱氧尿嘧啶核苷、脱氧胞嘧啶核苷等作用细胞后，再用正常培基替代，可是细胞达到95%的同化。

对于为啥要做细胞同步化，我有些也不大清楚。我只以自己的实验为例有一些自己的看法。我用生长因子刺激细胞，观察一个基因的表达，加生长因子前我都血清饥饿（0.25%）24小时，我个人觉得这里有一个实验组与组之间齐同和可比性的原则，就好比运动员都在同一起跑线上，同一时间出发，才具有可比性。这只是我肤浅的看法，希望大家补充。

细胞周期同步化是研究细胞生物学的一个重要手段。不同的细胞周期表达的细胞因子不同，有些基因的表达也存在周期特异性。比如
	- CDC在不同的周期表达就明显不同。
	- KI-67仅在增殖期中表达，在G0期细胞就无表达，等等。
另外我们不可能从一群不同周期的细胞中分检出某一特定周期的细胞，所以也要先对细胞进行同步化处理以分离出特定周期的细胞。同步化不是目的而是手段，除非你专门研究各种因素对细胞周期的影响。现在同步化手段和技术也在不断发展，最早就是用PHA来刺激，很粗糙。以后用胸苷，Brud等等。现在多用两种物质，双重阻断法，先用胸苷，再用Nacodazol，效果还可以。但是一定要记住，目前为止任何手段都不能百分之百同步化，能达到60-70%就不错了。至于你自己有什么目的，为什么要进行同步化，具体可参考相关文献。另外还有一种方法就是结合FACS，可以达到很高的同步化率。但是不太实际。除非你需要的细胞不多。









========================================
20180117 C1分细胞 根据标签对细胞对应
----------------------------------------
1.复制文件
find . -name "*" | xargs -i {} cp {}  /home/users/
注意:
# -i 参数是xargs命令的"替换字符串"选项.
# 大括号对的地方就是替换点.
xarg的man页中表示废弃-i参数。建议使用-I{}来代替。cp后面的{}会被替换成xargs的输入

2.简化文件名：
$ rename 'S294_05B_CHG011307-Mix2-40sc-' '' *
$ rename 'S294_05B_CHG011307-Mix2-bulkpopulation2_L00' 'bulkpop' *

3.解压缩
nohup gunzip 13* &

4.合并测序lane。

(6个)
$ ls 3_*_R1.fastq
3_L006_R1.fastq  3_L007_R1.fastq  3_L008_R1.fastq

$ nohup cat 3_*_R1.fastq >/data1/wangjl/wangjl/combine1/3_R1.fastq &
$ nohup cat 3_*_R2.fastq >/data1/wangjl/wangjl/combine1/3_R2.fastq &

(6个)
[wangjl@nih_jin fastq]$ ls 9_*_R1.fastq
9_L006_R1.fastq  9_L007_R1.fastq  9_L008_R1.fastq
$ nohup cat 9_*_R1.fastq >/data1/wangjl/wangjl/combine1/9_R1.fastq &
$ nohup cat 9_*_R2.fastq >/data1/wangjl/wangjl/combine1/9_R2.fastq &


3,6,7,8,9,13共6列。每列双端测序，共12组数据。
$ pwd
/data1/wangjl/wangjl/combine1

$ ls -lth
total 320G
-rw-r--r--. 1 wangjl user 29G Jan 16 17:11 8_R2.fastq
-rw-r--r--. 1 wangjl user 29G Jan 16 17:11 8_R1.fastq
-rw-r--r--. 1 wangjl user 23G Jan 16 17:11 9_R2.fastq
-rw-r--r--. 1 wangjl user 23G Jan 16 17:11 9_R1.fastq
-rw-r--r--. 1 wangjl user 26G Jan 16 17:08 7_R2.fastq
-rw-r--r--. 1 wangjl user 26G Jan 16 17:08 7_R1.fastq
-rw-r--r--. 1 wangjl user 28G Jan 16 17:06 6_R2.fastq
-rw-r--r--. 1 wangjl user 28G Jan 16 17:05 6_R1.fastq
-rw-r--r--. 1 wangjl user 27G Jan 16 17:02 3_R2.fastq
-rw-r--r--. 1 wangjl user 27G Jan 16 17:02 3_R1.fastq
-rw-r--r--. 1 wangjl user 30G Jan 16 16:58 13_R2.fastq
-rw-r--r--. 1 wangjl user 30G Jan 16 16:50 13_R1.fastq


$ ls *_R1.fastq
bulkpop6_R1.fastq  bulkpop7_R1.fastq  bulkpop8_R1.fastq
$ nohup cat *_R1.fastq >/data1/wangjl/wangjl/combine1/bulk_Mix2_R1.fastq &
$ nohup cat *_R2.fastq >/data1/wangjl/wangjl/combine1/bulk_Mix2_R2.fastq &




5.需要从R1中提取cell barcode.
R1(测得3'端序列):
5’-cell barcode(6 bases)-TTT…T(30 bases)VN-sequence-3’

$ head -n 1200 13_R1.fastq | awk -F "TTTTTT" '{if(NR%4==1||NR%4==2) print $1}' >test.txt


不再做，接着分好的细胞做，mapping、counting和Seurat软件包。





========================================
[官方脚本 mRNASeqHT_demultiplex.pl ] 按照每行的index把总fq文件分成细胞的fq文件
----------------------------------------

一、先做个大概的自检：检测不同barcode的read数量
1.查看前8行
$ zcat c2_R1.fastq.gz|head -n 8

2.sed每隔4行取出来一行序列
$ zcat c2_R1.fastq.gz|head -n 8|sed -n '2~4p'

3.取出序列的前6个字符
zcat c2_R1.fastq.gz|head -n 12|sed -n '2~4p'|cut -c1-6

4.前6个字符的频率
$ zcat c2_R1.fastq.gz|head -n 400|sed -n '2~4p'|cut -c1-6|sort | uniq -c

5.按照频率排序
$ zcat c2_R1.fastq.gz|head -n 4000|sed -n '2~4p'|cut -c1-6|sort | uniq -c|sort -k 1nr

6.对整个文件统计，输出结果到文件
$ zcat c2_R1.fastq.gz|sed -n '2~4p'|cut -c1-6|sort | uniq -c|sort -k 1nr >rowCount.c2_R1


7.批量化
$ vim getRowCount.sh
for i in `ls *_R1.fastq.gz`;
do
	zcat ${i}|sed -n '2~4p'|cut -c1-6|sort | uniq -c|sort -k 1nr >rowCount/${i}.rc &
done;




二、官方脚本

1.官方的index列表
http://cn.fluidigm.com/search?query=demultiplex&submit-search=Refine
http://cn.fluidigm.com/software

C1 mRNA Seq HT Demultiplex Script   v2.0.1   Updated 五月 16, 2018
The C1™ mRNA Sequencing High Throughput Demultiplexer Perl script application programming interface (API) allows automatic demultiplexing of individual single-cell samples from each column using the cell barcodes on the R1 reads. The API also automatically separates the large FASTQ file generated from each column pool into 40 pairs. This enables your C1 medium-cell HT IFC data to be preprocessed in a more efficient way.


使用mRNASeqHT_demultiplex.pl脚本，把每一列按照R1的barcode分成40个细胞。




2.测试脚本
./mRNASeqHT_demultiplex.pl -i /home/wangjl/data/c1_2019APA/sc/combine/test/ -o /home/wangjl/data/c1_2019APA/sc/combine/test_out/

输入文件名字要成对，类似：R1基本上只提供cell barcode，R2用于后续分析。 
c01_R1.fastq 
c01_R2.fastq




3.使用脚本，批量执行
$ pwd
/home/wangjl/data/c1_2019APA/sc/combine
$ mkdir sc_fq
$ cd /home/wangjl/data/c1_2019APA
$ ./mRNASeqHT_demultiplex.pl -i /home/wangjl/data/c1_2019APA/sc/combine/ -o /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/

单细胞的fq文件都在这里了。




4.根据脚本产生的表格(demultiplex_report.xls)画出log10(Read)热图：40row x 12column
R Script: /30_RE_cell_line/a01_visualReadsPerCell-after-mRNASeqHT_demultiplex.R





========================================
20180118 比对前处理
----------------------------------------
共178个单细胞fq文件。

1.质控：FastQC or Kraken.
之后可视化：Integrative Genomics Browser (IGV) or SeqMonk.

批量执行质控QC：
对单个测序文件质控，并输出到scFQ_QC/目录下
$ fastqc /home/wangjl/data/scFQ/c12_A1.fa.gz --outdir=/home/wangjl/data/scFQ_QC/

$ cd /home/wangjl/data/scFQ_QC/
$ ls /home/wangjl/data/scFQ/ >filelist.txt
$ awk '{printf("fastqc -o /home/wangjl/data/scFQ_QC/ -t 10 /home/wangjl/data/scFQ/%s\n",$0);}' filelist.txt > filelist_QC.sh

#基本语句 fastqc -o /home/wangjl/data/scFQ_QC/ -t 10 /home/wangjl/data/scFQ/c19_F3.fa.gz
$ chmod a+x filelist_QC.sh 
$ nohup ./filelist_QC.sh &




2. 切除质量低于25的碱基，去除polyA尾巴，去掉长度少于30的read。
http://cutadapt.readthedocs.io/en/stable/guide.html

cutadapt要求文件名结尾必须是fq，fastq或者fq.gz，fastq.gz，不能是fa.gz，否则报错。
$ cd /home/wangjl/data/scFQ
$ rename 'fa.gz' 'fq.gz' *

$ cd /home/wangjl/data/scFQ_filtered/ 
$ ls /home/wangjl/data/scFQ/ >filelist.txt

$ awk '{printf("cutadapt -a \"A{20}\" -q 25 -m 30 -o /home/wangjl/data/scFQ_filtered/filtered_%s /home/wangjl/data/scFQ/%s\n",$0,$0);}' filelist.txt > filelist_filtered.sh
 
# 基本语句 cutadapt -a "A{20}" -q 25 -m 30 -o /home/wangjl/data/scFQ_filtered/filtered_c19_A5.fq.gz /home/wangjl/data/scFQ/c19_A5.fq.gz
$ chmod a+x filelist_filtered.sh 
$ nohup ./filelist_filtered.sh &


//todo 还有很多 Illumina universal index没有去除。





3.再次执行QC:
$ cd /home/wangjl/data/scFQ_QC/
$ rm *
$ ls /home/wangjl/data/scFQ_filtered/*fq.gz >filelist.txt
$ awk '{printf("fastqc -o /home/wangjl/data/scFQ_QC/ -t 10 %s\n",$0);}' filelist.txt > filelist_QC.sh

#基本语句 fastqc -o /home/wangjl/data/scFQ_QC/ -t 10 /home/wangjl/data/scFQ_filtered/filtered_c19_F3.fq.gz
$ chmod a+x filelist_QC.sh 
$ nohup ./filelist_QC.sh &




========================================
20180118 使用STAR比对预处理后的数据
----------------------------------------
1. 可选软件 use the STAR or the TopHat aligner. 

$ cd /home/wangjl/data/afterMapping
$ ls /home/wangjl/data/scFQ_filtered/ |grep fq.gz >filelist.txt
$ sed -e 's/filtered_//' -e 's/.fq.gz//' filelist.txt > short_fname.txt

$ awk '{printf("STAR --runThreadN 10 --genomeDir /data1/hou/RNA/refs/hg19_ERCC92/index/star --readFilesIn /home/wangjl/data/scFQ_filtered/filtered_%s.fq.gz --readFilesCommand gunzip -c --outFileNamePrefix /home/wangjl/data/afterMapping/%s_ --genomeLoad LoadAndKeep\n",$0,$0);}' short_fname.txt > filelist_STAR.sh


#基本语句 STAR --runThreadN 10 --genomeDir /data1/hou/RNA/refs/hg19_ERCC92/index/star --readFilesIn /home/wangjl/data/scFQ_filtered/filtered_c13_F2.fq.gz --readFilesCommand gunzip -c --outFileNamePrefix /home/wangjl/data/afterMapping/c14_A1_ --genomeLoad LoadAndKeep
# --sjdbOverhang 149 #这个参数无法使用，因为index是按照100生成的。

$ chmod a+x filelist_STAR.sh 
$ nohup ./filelist_STAR.sh &




========================================
20180119 对STAR的Mapping结果进行预览和质检
----------------------------------------

1.画一个堆叠图(图例为 Uniquely Map, multi Map, Unmapped, 横坐标为cell的ID,纵坐标为Millions of Reads)

(1) 汇总Mapping的日志数据。
1)$ cd /home/wangjl/data/afterMapping/summary
$ head -n 40 ../*final.out >summaryOfSTAR.txt
$ sed -i '1i insertSth' summaryOfSTAR.txt #给该文件第一行加一行，凑成36的整数倍(6408/36=178.0)


2)后面尝试失败，用python实现了(见下文标号2)。
获取unique map的百分比（每隔36行打印一行，保存到文件中）
$ awk '{if(NR%36==12) print NR, $0}' summaryOfSTAR.txt > percentageUniquely_mapped_reads.txt

比对率集中在60-70%。我们希望每个细胞类似的比对率，如果有异常值，要去除。
低的比对百分比一般表示有污染。

$ head -n 72 summaryOfSTAR.txt | awk '{if(NR%36==2 || NR%36==8 || NR%36==11 || NR%36==26 || NR%36==28) print NR, $0}'
//todo 打算用python编程实现文本提取。
表格类似：
cellID, Uniquely Map, multi Map, Unmapped
c12_A1,2518014,305465,118562



2. python提取STAR日志中的比对统计参数
脚本名：extractMappingInfo.py
生成文件： summaryOfSTAR_extraction.txt
cellID	Uniquely	Multi	Unmapped
c12_A1	2518014	305465	118562
c12_A2	122654	18510	34592
c12_A3	2402296	336009	124764
c12_A4	3803840	491439	175807


3.使用R排序文件。
表达数除以1e6。




========================================
20180119 对RNA进行定量
----------------------------------------
to quantify the expression level of each gene for each cell, using HT-seq or FeatureCounts
两者的比较 featureCounts or htseq-count?：http://bioinformatics.cvr.ac.uk/blog/featurecounts-or-htseq-count/
Unique molecular identifiers (UMIs) 可以对分子绝对计数，并且在scRNA-seq中慢慢流行。后面会讲UMI。


1. HTSeq-count速度慢，如果样本数上升到几十及上百个样时，其所消耗的时间是以天记的。

$ cd /home/wangjl/data/afterMapping/quantify
#提取文件名字
$ sed -e 's/..\///' -e 's/_Aligned.out.sam//' fname.txt >id.txt
#组装命令
$ awk '{printf("htseq-count /home/wangjl/data/afterMapping/%s_Aligned.out.sam /data1/hou/RNA/refs/hg19_ERCC92/UCSC_hg19_geneid.gtf > htseq_%s.sam.count 2>htseq_%s.sam.count.log\n",$0,$0,$0);}' id.txt >htseq_count.sh
#基本命令 htseq-count /home/wangjl/data/afterMapping/c12_A1_Aligned.out.sam /data1/hou/RNA/refs/hg19_ERCC92/UCSC_hg19_geneid.gtf > htseq_c12_A1.sam.count 2>htseq_c12_A1.sam.count.log

$ chmod a+x htseq_count.sh
$ nohup ./htseq_count.sh &
耗时：17.41->00.21 






2.试试FeatureCounts

$ cd /home/wangjl/data/afterMapping/quantify2/
复制cell ID文件
$ cp ../quantify/id.txt .
#组装命令
$ awk '{printf("featureCounts -T 5 -O -M -a /data1/hou/RNA/refs/hg19_ERCC92/UCSC_hg19_geneid.gtf -o /home/wangjl/data/afterMapping/quantify2/fC_%s.sam.count ../%s_Aligned.out.sam 2>fC_%s.sam.count.log\n",$0,$0,$0);}' id.txt >FeatureCounts_count.sh
#基本命令 featureCounts -T 5 -O -M -a /data1/hou/RNA/refs/hg19_ERCC92/UCSC_hg19_geneid.gtf -o /home/wangjl/data/afterMapping/quantify2/fC_c12_A1.sam.count ../c12_A1_Aligned.out.sam 2>fC_c12_A1.sam.count.log

$ chmod a+x FeatureCounts_count.sh
$ nohup ./FeatureCounts_count.sh &
耗时：22.17-> 22.30

(2)提取精简基因表达信息(第一行和第七行)：
$ awk '{printf("cut -f 1,7 fC_%s.sam.count |grep -v '^#' >fC_%s.sam.count.lite\n",$0,$0);}' id.txt>simplify_fC.sh
#基本命令 cut -f 1,7 fC_c12_A1.sam.count |grep -v '^#' >fC_c12_A1.sam.count.lite
$ chmod a+x simplify_fC.sh
$ nohup ./simplify_fC.sh &

基因表达数据就看.lite文件即可。


(3) 20180120 featureCounts 批量定量
预计需要15min。
$ nohup ls ../../*sam |xargs featureCounts -T 15 -O -M -a /data1/hou/RNA/refs/hg19_ERCC92/UCSC_hg19_geneid.gtf -o matrix_fC.txt 2>matrix_fC.txt.log &

失败 todo






========================================
20180120 合并RNA定量结果，得到表达矩阵
----------------------------------------
合并成matrix
http://www.bio-info-trainee.com/255.html 使用R语言的数据框合并文件也是一个思路。


1. 主要步骤
(1)合并文件成一个。
(2)去掉全是0的基因；
(3)表达量都增加1，防止除以0产生错误；(还是不加1了，其他软件会加1的。
特别是log(rpm+1)之类换算时。
(4)去掉底部的描述信息，如no_feature, ambiguous等
(5)增加表头细胞ID

2. 有用代码片段
$ ls *count | awk '{printf("%s\t",$0);}'|xargs paste| grep -v "^__" > htseq_matrix178.txt
#合并成一个大文件，去掉底部__注释行。

#基因名字只保留第一列，其余去掉。 
$ awk '{print $1,$2,$4}' htseq_matrix178.txt | head



3. get_matrix_htseq.sh 脚本

合成一个行为基因，列为细胞的矩阵。
去掉结尾注释几行，__开头的行


#!/bin/bash
#############################
# v0.2.6
#############################
#获取细胞ID行。
fn=`ls ../*count`
echo $fn | sed -e 's/..\/htseq_//g' -e 's/.sam.count//g' > matrix_cellnames.txt
sed -i 's/ /\t/g' matrix_cellnames.txt #替换空格为制表符
sed -i 's/^/geneSybols\t/' matrix_cellnames.txt

#获取基因数字矩阵
tmp='temp_xxxxxx20180120'
mkdir $tmp


counter=0
for i in `cat matrix_cellnames.txt`
do
	if [ $counter != 0 ]
	then 
		echo "Processing cell $counter"
		awk -F"\t"  '{print $2}' ../htseq_${i}.sam.count > $tmp/${i}.num
		if [ $counter == 1 ]
		then
			awk -F"\t"  '{print $1}' ../htseq_${i}.sam.count > matrix_geneSymbol.txt #基因名字			
		fi
	fi
	((counter++))
done

#数值矩阵
echo $fn | sed -e "s/..\/htseq_/${tmp}\//g" -e "s/.sam.count/.num/g"|xargs paste| grep -v "^__" > matrix_num.txt

#基因名字和数值矩阵拼合
paste matrix_geneSymbol.txt matrix_num.txt >matrix_sb_num_raw.txt
#去掉统计信息
grep -v "^__" matrix_sb_num_raw.txt > matrix_sb_num.txt

#追加到细胞名字后面
cat matrix_cellnames.txt matrix_sb_num.txt > all_matrix_htseqCounts.txt

#清除临时文件
rm matrix*
#清理临时文件夹
rm -fR $tmp

#文件质检
echo "===========check the first and last 2 columns."
head all_matrix_htseqCounts.txt |awk -F"\t"  '{print $1,$2,$177,$178}'
echo '...'
tail all_matrix_htseqCounts.txt |awk -F"\t"  '{print $1,$2,$177,$178}'
echo "===========the rows of the matrix"
wc all_matrix_htseqCounts.txt #28616
#############################


(3)进行手动质检
抽检基因：uhrf,fox,p53
1)p53基因
总文件中搜索
$ awk '{if(NR==1)print $1,$2,$3,$100}' all_matrix_htseqCounts.txt
$ grep -i p53 all_matrix_htseqCounts.txt |awk '{print $1,$2,$3,$100}'
geneSybols c12_A1 c12_A2 c15_D1
RPL23AP53 0 0 0
TP53 14 34 14
TP53AIP1 0 0 0
TP53BP1 368 0 14
TP53BP2 1 0 109
TP53I11 177 4 55
TP53I13 0 0 0
TP53I3 0 40 0
TP53INP1 0 0 107
TP53INP2 0 0 0
TP53RK 0 0 0
TP53TG1 0 2 0
TP53TG3 0 0 0
TP53TG3B 0 0 0
TP53TG3D 0 0 0
TP53TG5 0 0 0
USP53 6 0 33
WRAP53 0 0 3

分文件中检索
$ grep -i P53 ../htseq_c12_A1.sam.count
$ grep -i P53 ../htseq_c12_A2.sam.count
$ grep -i P53 ../htseq_c15_D1.sam.count

2)uhrf
$ awk '{if(NR==1)print $1,$2,$23,$178}' all_matrix_htseqCounts.txt
$ grep -i uhrf all_matrix_htseqCounts.txt |awk '{print $1,$2,$23,$178}'
geneSybols c12_A1 c12_G2 c19_H4
UHRF1 0 17 0
UHRF1BP1 126 227 0
UHRF1BP1L 0 419 0
UHRF2 0 0 2

$ grep -i uhrf ../htseq_c12_A1.sam.count
$ grep -i uhrf ../htseq_c12_G2.sam.count
$ grep -i uhrf ../htseq_c19_H4.sam.count


这2个基因上，矩阵和分文件reads数一致。











========================================
提取polyA尾巴位点的方法
----------------------------------------
https://www.researchgate.net/publication/269467369_Extraction_of_PolyA_Sites_from_Large-Scale_RNA-seq_Data







========================================
定量后的分析：差异表达
----------------------------------------
1.https://ccb.jhu.edu/software/stringtie/index.shtml
StringTie's output can be processed by specialized software like Ballgown, Cuffdiff or other programs (DESeq2, edgeR, etc.).

2. https://combine-lab.github.io/salmon/getting_started/
After quantification
Quantifying your RNA-seq data with salmon is that simple (and fast). Once you have your quantification results you can use them for downstream analysis with differential expression tools like DESeq2, edgeR, limma, or sleuth. 
定量后做差异表达分析：DESeq2, edgeR, limma, or sleuth. 








========================================
--|--(基于抽样的，不靠谱)曾使用fastQ screen软件区分序列来源
----------------------------------------
http://www.bioinformatics.babraham.ac.uk/projects/fastq_screen/

FastQ Screen allows you to screen a library of sequences in FastQ format against a set of sequence databases so you can see if the composition of the library matches with what you expect.

依赖$ bwa
Program: bwa (alignment via Burrows-Wheeler transformation)
Version: 0.7.17-r1188
$ bwa index -a bwtsw ../hg19.fa

#to human
$ bwa mem -t 10 /home/wangjl/data/ref/human/BWA/hg19.fa /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left/c2_ROW01_R2.fastq > /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/BWA_human/c2_ROW01_bwa.sam

#to mouse
bwa mem -t 10 /home/wangjl/data/ref/mouse/BWA/mm9.fa /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left/c2_ROW01_R2.fastq > /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/BWA_mouse/c2_ROW01_bwa.sam

fastQ screen下载页
http://www.bioinformatics.babraham.ac.uk/projects/download.html#fastqscreen
下载： http://www.bioinformatics.babraham.ac.uk/projects/fastq_screen/fastq_screen_v0.13.0.tar.gz
文档：http://www.bioinformatics.babraham.ac.uk/projects/fastq_screen/_build/html/index.html


配置文件：
fastq_screen.conf.example 
Rename the file to fastq_screen.conf after you have finished editing.
设置bwa位置，human和mouse的index位置，线程数。

$ fastq_screen /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left/c2_ROW01_R2.fastq --outdir /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/BWA_screen


安装了bowtie2
$ bowtie2 -p 6 -3 5 --local -x mm10 -1 example_1.fastq -2 example_2.fastq -S SRR3208744.bam

$ bowtie2 -p 60 --local -x /home/wangjl/data/ref/human/bowtie2/hg19 -U /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left_trim/c2_ROW01_R2.fastq -S /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/bowtie2_human/c2_ROW01_R2.sam


$ bowtie2 -p 60 --local -x /home/wangjl/data/ref/human/bowtie2/hg19 -U /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left_trim/c2_ROW01_.fastq -S /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/bowtie2_human/c2_ROW01_R2.sam


aligned exactly 1 time: counts and pct.
	         no --local | with --local
没trim：  96580 (2.67%) | 366968 (10.14%)
trim过： 179779 (5.39%) | 451462 (13.54%)

结论：bowtie2的--local选项，有助于提高比对比率。
做trim也能提高比对counts数。
可能是去除两端残留的建库index，有助于精确比对。




重新设置bowtie2位置，human和mouse的index位置，线程数。
可以使用 --threads 设置线程数。
$ fastq_screen /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left_trim/c2_ROW01_.fastq --outdir /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/bowtie2_screen

$ fastq_screen /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left/c2_ROW01_R2.fastq --outdir /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/bowtie2_screen

感觉fastq_screen不靠谱，它依赖于每次抽样0.1M reads，然后比对的结果，不如完全比对来的直接。



========================================
基本流程
----------------------------------------



========================================
fastQC与multiqc
----------------------------------------
1. 版本号
$ fastqc --version
FastQC v0.11.7

$ multiqc --version
multiqc, version 1.7



2.基本命令
$ pwd
/home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left_QC
$ ls ../R2_left/c2_ROW01_R2.fastq | while read id; do fastqc -t 40 $id -o ./; done


###原始reads的
多进程
fastqc -t 4 /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left/c2_ROW02_R2.fastq -o /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left_QC/

###trimming后的reads的
fastqc -t 4 /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left_trim/c2_ROW02_.fastq -o /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left_trim_QC/


# multiqc 批量生成报告
multiqc *fastqc.zip -o /data/jinwf/wangjl/c1_2019APA/sc/combine/sc_fq/




========================================
使用trim_galore预处理
----------------------------------------

$ trim_galore --quality 25 --phred33 --stringency 3 --length 30 --gzip  --fastqc_args "-t 15" --output_dir /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/trim/galore/ /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left/c2_ROW01_R2.fastq


$ cd /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/trim/galore
$ multiqc *fastqc.zip -o /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/







========================================
预处理工具cutadapt
----------------------------------------

安装python3:
https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.3.1-Linux-x86_64.sh
$ pip install --user --upgrade cutadapt
$ cutadapt --version
2.3


cutadapt要求文件名结尾必须是fq，fastq或者fq.gz，fastq.gz，不能是fa.gz，否则报错。
http://cutadapt.readthedocs.io/en/stable/guide.html


$ pwd
/home/wangjl/data/c1_2019APA/sc/combine/sc_fq
$ mkdir R2_left_trim


获取左侧240个文件的ID
$ pwd
/home/wangjl/data/c1_2019APA/sc/combine/sc_fq
$ ls R2_left|cut -c1-8>left.ID
$ wc left.ID 
 240  240 2160 left.ID
$ head left.ID 
c2_ROW01
c2_ROW02
...


切除质量低于25的碱基，去除polyA尾巴，去掉长度少于30的read。
# 基本语句 
$ cutadapt -a "A{20}" -q 25 -m 30 -o /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left_trim/trim-c3_ROW01.fastq /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left/c3_ROW01_R2.fastq 1>/home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left_trim/c3_ROW01.log


多线程执行 cutadapt 代码: \30_RE_cell_line/a02_cutadapt_multyThread.py
输出结果：/home/wangjl/data/c1_2019APA/sc/combine/sc_fq/R2_left_trim





========================================
准备STAR软件
----------------------------------------
1.资源:下载基因组的fasta文件和gtf注释文件
参考基因组 http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/
jinlab: $ ls /data1/hou/RNA/refs/hg19


1.1 下载方式1
axel -n 30 http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/hg19.fa.gz

1.2 下载方法2
axel -n 40 http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/chromFa.tar.gz
tar -zxvf chromFa.tar.gz
cd chroms
cat *.fa >hg19.fa


下载老鼠mm9基因组
axel -n 20 http://hgdownload.cse.ucsc.edu/goldenPath/mm9/bigZips/mm9.2bit


(1)怎么把2bit转变成fasta？使用twoBitToFa工具
https://blog.csdn.net/weixin_40099163/article/details/86151988

mm9.2bit - contains the complete mm9 Mouse Genome
    in the 2bit format.  A utility program, twoBitToFa (available from our src tree), can be used to extract .fa file(s) from this file.  See also:
        http://genome.ucsc.edu/admin/cvs.html - CVS access to the source tree
        http://genome.ucsc.edu/admin/jk-install.html - building the utilities
A pre-compiled version of the command line tool can be found at: http://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/

下载
$ axel -n 30 http://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/twoBitToFa
$ chmod +x twoBitToFa
添加到~/bin下。

运行该软件：
$ twoBitToFa mm9.2bit mm9.fa


#下载mm10  http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/
cd /home/wangjl/data/ref/mm10
$ axel -n 80 http://hgdownload.cse.ucsc.edu/goldenPath/mm10/bigZips/mm10.2bit
#下载mm10 gtf和bed文件



(2)从UCSC下载gtf注释文件




2. 比对软件 STAR
(1)安装star 2.7：https://github.com/alexdobin/STAR
# Get latest STAR source from releases
wget https://github.com/alexdobin/STAR/archive/2.7.0f.tar.gz
tar -xzf 2.7.0f.tar.gz
cd STAR-2.7.0f

#编译 Compile under Linux
cd STAR/source
make STAR

#然后在~/bin下添加快捷方式
$ ln -s /home/wangjl/data/software/STAR-2.7.0f/source/STAR

#查看版本号
$ STAR --version
2.7.0f


最后使用的是(lab上一致的)老版本：
https://github.com/alexdobin/STAR/archive/2.5.2b.tar.gz




(2)使用
51页手册STARmanual.pdf： https://github.com/alexdobin/STAR/blob/master/doc/STARmanual.pdf

1)生成人的基因组STAR index（放在 nohup CMD & 中运行的）
STAR --runThreadN 50 --runMode genomeGenerate --genomeDir /home/wangjl/data/ref/human/STAR/  --genomeFastaFiles /home/wangjl/data/ref/human/hg19.fa --sjdbGTFfile /home/wangjl/data/ref/human/hg19_ucsc_genes-20190506.gtf --sjdbOverhang 100
[11:00 - 11:19]
参数解释：
	runThreadN 线程数
	runMode 运行模式，genomeGenerate 选项用来产生index;
	genomeDir 指定生成的index保存的位置
	genomeFastaFiles 输入的参考基因组文件fasta
	sjdbGTFfile 注释gtf文件
	sjdbOverhang : specifies the length of the genomic sequence around the annotated junction
to be used in constructing the splice junctions database. max(ReadLength)-1 或者默认100.


2)生成小鼠的基因组STAR index（放在 nohup CMD & 中运行的）
STAR --runThreadN 50 --runMode genomeGenerate --genomeDir /home/wangjl/data/ref/mouse/STAR/  --genomeFastaFiles /home/wangjl/data/ref/mouse/mm9.fa --sjdbGTFfile /home/wangjl/data/ref/mouse/mm9_ucsc_genes-20190506.gtf --sjdbOverhang 100
[11:05 - 11:21]
















2. 使用STAR做mapping
$ ls /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/trim/galore/|head
#c2_ROW01_R2.fastq_trimming_report.txt
#c2_ROW01_R2_trimmed_fastqc.html
#c2_ROW01_R2_trimmed_fastqc.zip
#c2_ROW01_R2_trimmed.fq.gz

###基本语句to hg19
STAR --runThreadN 10 --readFilesCommand zcat --genomeDir /home/wangjl/data/ref/human/STAR --readFilesIn /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/trim/galore/c2_ROW01_R2_trimmed.fq.gz --outFileNamePrefix /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/galore_human/c2_ROW01_ --genomeLoad LoadAndKeep

参数解释：
	runThreadN 线程数
	genomeDir 基因组index路径
	readFilesIn 带路径名的测序文件
	outFileNamePrefix 输出文件的前缀，默认是./
	--outSAMtype BAM SortedByCoordinate 输出格式为BAM并排序
如果加上这个参数，就直接是排序后的bam文件了。

由于上文没有这个设置该参数，需要使用samtools做三步：
samtools view -bS input.sam >out.bam #1.转换为bam
samtools sort -o aln.sorted.bam aln.bam #2.排序
samtools index aln.sorted.bam #3.建索引	


转为bam并排序索引：
cd /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/galore_mouse/; \
samtools view -bS c2_ROW01_Aligned.out.sam >c2_ROW01.n.bam; \
samtools sort -o c2_ROW01.sorted.bam c2_ROW01.n.bam; \
samtools index c2_ROW01.sorted.bam


[shell 10个线程，py并发10线程]
#for mouse 
    cmd="cd /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/galore_mouse/; \
samtools view -@ 10 -bS "+id+"_Aligned.out.sam >../bamR2Lm/"+id+".n.bam; \
samtools sort -@ 10 -o ../bamR2Lm/"+id+".sorted.bam ../bamR2Lm/"+id+".n.bam; \
samtools index -@ 10 ../bamR2Lm/"+id+".sorted.bam";
#for human
    cmd="cd /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/galore_human/; \
samtools view -@ 10 -bS "+id+"_Aligned.out.sam >../bamR2Lh/"+id+".n.bam; \
samtools sort -@ 10 -o ../bamR2Lh/"+id+".sorted.bam ../bamR2Lh/"+id+".n.bam; \
samtools index -@ 10 ../bamR2Lh/"+id+".sorted.bam";





========================================
geneBody_coverage 做mapping的QC
----------------------------------------

对第二列(c2)的mapping做QC
$ cd /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/bamR2Lh
$ geneBody_coverage.py -r /data/jinwf/wangjl/ref/human/hg19_ucsc_genes-20190509.bed -i c2_ROW01.sorted.bam,c2_ROW02.sorted.bam,c2_ROW03.sorted.bam,c2_ROW04.sorted.bam,c2_ROW05.sorted.bam,c2_ROW06.sorted.bam,c2_ROW07.sorted.bam,c2_ROW08.sorted.bam,c2_ROW09.sorted.bam,c2_ROW10.sorted.bam,c2_ROW11.sorted.bam,c2_ROW12.sorted.bam,c2_ROW13.sorted.bam,c2_ROW14.sorted.bam,c2_ROW15.sorted.bam,c2_ROW16.sorted.bam,c2_ROW17.sorted.bam,c2_ROW18.sorted.bam,c2_ROW19.sorted.bam,c2_ROW20.sorted.bam,c2_ROW21.sorted.bam,c2_ROW22.sorted.bam,c2_ROW23.sorted.bam,c2_ROW24.sorted.bam,c2_ROW25.sorted.bam,c2_ROW26.sorted.bam,c2_ROW27.sorted.bam,c2_ROW28.sorted.bam,c2_ROW29.sorted.bam,c2_ROW30.sorted.bam,c2_ROW31.sorted.bam,c2_ROW32.sorted.bam,c2_ROW33.sorted.bam,c2_ROW34.sorted.bam,c2_ROW35.sorted.bam,c2_ROW36.sorted.bam,c2_ROW37.sorted.bam,c2_ROW38.sorted.bam,c2_ROW39.sorted.bam,c2_ROW40.sorted.bam -o /home/wangjl/data/c1_2019APA/sc/combine/sc_fq/mapping/mappingQC_human/galore_human_c2_






========================================
统计学参数
----------------------------------------



========================================
|-- MAD(中位数绝对偏差)
----------------------------------------

MAD 定义为，一元序列 Xi 同其中位数偏差的绝对值的中位数（deviation，偏差本身有正有负）；
MAD=median(|Xi−median(X)|)


MAD 的方法相对于分位数方法的一大优势即在于 MAD 方法对样本大小是不敏感也即是稳定的鲁棒的一种评价指标。



https://blog.csdn.net/lanchunhui/article/details/80381516






========================================
|-- 阈值 median-3 x MAD
----------------------------------------
threshold=median(df2$counts)-mad(df2$counts)*3;threshold

Low-quality cells were discarded if the cell library size or the number of expressed genes(counts larger than 0) was smaller than pre-defined thresholds, which were the medians of all cells minus 3x median absolute deviation.[zhang zemin,2018,NM]

在衍生一个上限？
threshold2=median(df2$counts) + mad(df2$counts)*3;threshold2



========================================
----------------------------------------




========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------



========================================
+	[竞争]single cell APA 做的好的组 Rani Elkon (Tel Aviv University)
----------------------------------------
1.https://simons.berkeley.edu/talks/talk-12

Genome-scale Analysis of Alternative Polyadenylation (APA) using Single-cell RNA-seq
Wednesday, October 10th, 2018 11:30 am – 12:00 pm
Add to Calendar
Event: Koret-Berkeley-Tel Aviv Initiative in Computational Biology and BioinformaticsSpeaker: 
Rani Elkon (Tel Aviv University)
https://www.cs.tau.ac.il/~ranel/
http://www.elkonlab.tau.ac.il/



========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------




========================================
----------------------------------------


