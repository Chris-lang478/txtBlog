数据结构与算法 (本文主要是算法)

还有一个Python 版：py/Py201_algorithm.txt



算法与数据结构 是程序的灵魂，你丢弃了算法也就等于抛弃了优秀程序员的称号
c语言版 https://www.kancloud.cn/digest/linuxzhang/121697


算法】算法导论-麻省理工
https://www.bilibili.com/video/BV1Tb411M7FA?p=1


五大常用算法一(回溯,随机化,动态规划)
递归/回溯  /贪心法/分治法  /搜索算法/二叉树链表
https://www.jianshu.com/p/dec9a453573f







========================================
资料书
----------------------------------------
1. 数据结构与算法分析：C语言描述（原书第2版）是《data structures and algorithm analysis in c》一书第2版的简体中译本。
https://www.cnblogs.com/Ivyli4258/p/7851953.html

原书曾被评为20世纪顶尖的30部计算机著作之一，作者mark allen weiss在数据结构和算法分析方面卓有建树，他的数据结构和算法分析的著作尤其畅销，并受到广泛好评．已被世界500余所大学用作教材。

在本书中，作者更加精炼并强化了他对算法和数据结构方面创新的处理方法。通过c程序的实现，着重阐述了抽象数据类型的概念，并对算法的效率、性能和运行时间进行了分析。

数据结构与算法分析：C语言描述（原书第2版） PDF下载：http://pan.baidu.com/s/1pJ59aMv （本人是从这里下载的，感谢原博主）


全书特点如下：
●专用一章来讨论算法设计技巧，包括贪婪算法、分治算法、动态规划、随机化算法以及回溯算法
●介绍了当前流行的论题和新的数据结构，如斐波那契堆、斜堆、二项队列、跳跃表和伸展树
●安排一章专门讨论摊还分析，考查书中介绍的一些高级数据结构
●新开辟一章讨论高级数据结构以及它们的实现，其中包括红黑树、自顶向下伸展树。treap树、k-d树、配对堆以及其他相关内容
●合并了堆排序平均情况分析的一些新结果


目录
出版者的话
专家指导委员会
译者序
前言
第1章 引论
第2章 算法分析
第3章 表、栈和队列
第4章 树
第5章 散列
第6章 优先队列（堆）

第7章 排序
第8章 不相交集ADT
第9章 图论算法
第10章 算法设计技巧
第11章 摊还分析
第12章 高级数据结构及其实现索引


(2) 算法入门书籍
https://github.com/CodingDocs/awesome-cs-books



(3) 网页教程
https://www.zhihu.com/question/356351510/answer/1844573129
	贪心算法
	双指针
	二分查找
	各种排序
	深度优化搜索
	动态规划
	分而治之
	巧解数学问题
	神奇的位运算
	妙用数据结构


https://www.zhihu.com/question/315201616/answer/1960517601
涉及到了近二十种数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树；
超四十种常见算法思想：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。


- 移动机器人 机器人视觉 VSLAM 深度学习 目标检测识别 自动化脚本 编译器
	https://blog.csdn.net/xiaoxiaowenqiang
-


(4) 算法图解 小人书 不到200页。
第 1 章　算法简介
第 2 章　选择排序
第 3 章　递归
第 4 章　快速排序
第 5 章　散列表
第 6 章　广度优先搜索
第 7 章　狄克斯特拉算法
第 8 章　贪婪算法
第 9 章　动态规划
第 10 章　K最近邻算法
第 11 章　接下来如何做

有人做的总结 https://blog.csdn.net/qq_42379006/article/details/80888962






2. 视频教程
数据结构与算法Python版-北京大学-中国大学MOOC(慕课) 
https://www.bilibili.com/video/BV1QJ411w7bB?p=2 消失了
https://www.icourse163.org/course/0809PKU068-1206307812










========================================
数据结构和算法关系
----------------------------------------
数据结构：数据与数据之间的结构关系（数组、队列、树、图等结构）

算法：解决问题的步骤

总结：
1、程序 = 数据结构 + 算法 。数据是程序的中心。数据结构和算法两个概念间的逻辑关系贯穿了整个程序世界，首先二者表现为不可分割的关系。没有数据间的有机关系，程序根本无法设计。

2、数据结构与算法关系：数据结构是底层，算法高层。数据结构为算法提供服务。算法围绕数据结构操作。

3、解决问题（算法）需要选择正确的数据结构。例如：算法中经常需要对数据进行增加和删除用链表数据结构效率高，数组数据结构因为增加和删除需要移动数字每个元素所有效率低。

4、数据结构特点：每种数据结构都具有自己的特点。例如：队列：先进先出。栈：先进后出。等等

5、算法的特性：算法具有五个基本特征：输入、输出、有穷性、确定性和可行性。

6、数据结构应用：数据结构往往同高效的检索算法、索引技术、排序算法有关

7、数据结构（逻辑数据结构）通过计算机语言来实现数据结构（存储数据结构）。例如：树型数据结构：通过计算机语言中的数组（节点）和指针（指向父节点）来实现。

8、存储结构：逻辑数据结构的实现。存储结构通过计算机语言实现。  例如：堆数据结构，堆是一棵完全二叉树，所以适宜采用顺序存储结构（顺序存储：数组），这样能够充分利用存储空间。

9、算法目的：算法是为数据结构服务。例如：数据结构通常伴随有查找算法、排序算法等

10、数据结构的优劣：一种数据结构的优劣是在实现其各种运算的算法中体现的。

 

二、数据结构：分为逻辑数据结构和存储数据结构两种
（1）顺序存储方法（顺序存储结构） 
（2）链接存储方法（链式存储结构） 
同一种逻辑结构可采用不同的存储方法（以上两种之一或组合），这主要考虑的是运算方便及算法的时空要求。


https://www.cnblogs.com/Ivyli4258/p/7838675.html





========================================
算法的特征、算法设计的要求、算法有效率的评估（时间、空间复杂度）
----------------------------------------
1. 算法的特征
- 有穷性: 在有限个步骤后终止。
- 确定性: 对相同的输入，获得相同的输出。
- 可行性: 每个步骤可以在有限的时间内完成。
- 输入: 有0个或多个而输入。
- 输出: 有1个或多个输出。



2. 算法设计的要求 
- 正确性: 算法应该能够正确的求解问题。
- 可读性：算法应具有良好的可读性，以帮助人们理解。
- 健壮性：输入非法数据时，算法能适当的做出反应或进行处理，而不会产生莫名其妙的输出结果，程序也不会挂掉。
- 高效率
- 低存储




3. 时间复杂度

int sum(int n)
{
	int value=0;
	int ii=1;
	while(ii<=n){
		value+=ii;
		ii++;
	}
	return value;
}
程序需要执行 3n+3次
T(n)=O(f(n)) T表示Time， T(n)=O(3n+3)
时间复杂度关心的是数量级，所以对f(n) 函数表达式要简化，原则是: 
- 略去常数项
- 只保留最高阶的项
- 变量最高阶的系数为1

只关心程序代码中最内层的循环次数就可以了。




4. 空间复杂度 




todo: https://www.bilibili.com/video/BV1oN411Q7Yz/?p=3&spm_id_from=pageDriver



========================================
|-- NP 完全问题 (Non-deterministic Polynomial, NP)
----------------------------------------
1. P类问题、NP类问题

NP完全问题(NP-C问题)，是世界七大数学难题之一。 

NP的英文全称是Non-deterministic Polynomial的问题，即多项式复杂程度的非确定性问题。
简单的写法是 NP=P？，问题就在这个问号上，到底是NP等于P，还是NP不等于P。

(1)用通俗但不是很严谨的表述来总结一下。
  P类问题就是指那些计算机比较容易算出答案的问题。
  NP类问题就是指那些已知答案以后计算机可以比较容易地验证答案的问题。

(2) 严谨表述
==> P类问题：所有可以在多项式时间内求解的判定问题构成P类问题。
判定问题：判断是否有一种能够解决某一类问题的能行算法的研究课题。
判定问题是指回答结果输出为Yes或No的问题，比如：
	3233是否可以写成两个大于1的数字的乘积？
	是否存在一条路线有且仅有一次的走过七桥问题的每一座桥？

==> NP类问题：所有的非确定性多项式时间可解的判定问题构成NP类问题。
非确定性算法：非确定性算法将问题分解成猜测和验证两个阶段。算法的猜测阶段是非确定性的，算法的验证阶段是确定性的，它验证猜测阶段给出解的正确性。

比如：是否存在一个公式可以计算下一个质数是多少？这个问题的答案目前是无法直接计算出来的，但是如果某人给出了一个公式，我们却可以在多项式时间里对这个公式进行验证。


=> NP中的一类比较特殊的问题，这类问题中每个问题的复杂度与整个类的复杂度有关联性，假如其中任意一个问题在多项式时间内可解的，则这一类问题都是多项式时间可解。这些问题被称为NP完全问题。


问题类型	/是否能在多项式时间内求解	/是否能在多项式时间内验证
P	  /是   	/是
NP	 /是 or 否	/是
NP-C	/未知	/是


(3)生成问题的一个解通常比验证一个给定的解时间花费要多得多。

这是这种一般现象的一个例子。

与此类似的是，如果某人告诉你，数13,717,421可以写成两个较小的数的乘积，你可能不知道是否应该相信他，但是如果他告诉你他可以因式分解为3607乘上3803，那么你就可以用一个袖珍计算器容易验证这是对的。

人们发现，所有的完全多项式非确定性问题，都可以转换为一类叫做满足性问题的逻辑运算问题。既然这类问题的所有可能答案，都可以在多项式时间内计算，人们于是就猜想，是否这类问题，存在一个确定性算法，可以在多项式时间内，直接算出或是搜寻出正确的答案呢？这就是著名的NP=P？的猜想。 

不管我们编写程序是否灵巧，判定一个答案是可以很快利用内部知识来验证，还是没有这样的提示而需要花费大量时间来求解，被看作逻辑和计算机科学中最突出的问题之一。它是斯蒂文·考克于1971年陈述的。








========================================
排序：冒泡法、选择排序、插入排序、希尔排序、归并排序、快速排序
----------------------------------------
排序
	冒泡
	插入
	快排
	归并
	堆排


1. 冒泡排序

冒泡排序（英语：Bubble Sort）是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序（如从大到小、首字母从A到Z）错误就把他们交换过来。

每个位置都是最后才确定。

$ cat 01.c
#include<stdio.h>
void printArr(int arr[], int n){
	printf("[");
	for(int i=0; i<n; i++){
		if(i<n-1){
			printf("%d,", arr[i]);
		}else{
			printf("%d", arr[i]);
		}
	}
	printf("]\n");
}

void bubbleSort(int arr[], int n){
	int i=0, j=0;
	for(i=0; i<n-1; i++){
		for(j=0; j<n-1; j++){
			if(arr[j]>arr[j+1]){
				int tmp=arr[j];
				arr[j]=arr[j+1];
				arr[j+1]=tmp;
			}
		}
	}
}

int main(){
	int N=10, arr[]={0,1,-20,30,-40,500,-60,70,-800,90};
	printArr(arr, N);
	bubbleSort(arr, N);
	printArr(arr, N);
}

输出:
[0,1,-20,30,-40,500,-60,70,-800,90]
[-800,-60,-40,-20,0,1,30,70,90,500]



(2) 独立编译函数库
$ cat 00.c
#include<stdio.h>
void printArr(int arr[], int n){
	printf("[");
	for(int i=0; i<n; i++){
		if(i<n-1){
			printf("%d,", arr[i]);
		}else{
			printf("%d", arr[i]);
		}
	}
	printf("]\n");
}

void swap(int *a, int *b){
	int temp=*a;
	*a=*b;
	*b=temp;
}



$ gcc -c 00.c -o printArr.o


//todo 这是啥排序？
void selSort(int arr[], int n){
	int i=0, j=0;
	for(i=0; i<n; i++){
		for(j=i; j<n; j++){
			if(arr[i]>arr[j]){
				swap(&arr[i], &arr[j]);
			}
		}
	}
}






2.选择排序

选择排序（Selection sort）是一种简单直观的排序算法。它的工作原理如下。首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。

每一次循环，确定一个的位置。

$ cat 02.c
#include<stdio.h>
#include "00.c"

void selSort(int arr[], int n){
	int i,j;
	for(i=0; i<n-1; i++){
		int min=i; //最小值，默认为第一个元素
		for(j=i+1; j<n; j++){
			if(arr[j]<arr[min]){ //如果元素比第一个小，则记录其下标
				min=j;
			}
		}
		if(min != i){
			swap(&arr[min], &arr[i]);
		}
	}
}

int main(){
	int N=10, arr[]={0,1,-20,30,-40,500,-60,70,-800,90};
	printArr(arr, N);
	selSort(arr, N);
	printArr(arr, N);
}


编译输出
$ gcc 02.c 
$ ./a.out 
[0,1,-20,30,-40,500,-60,70,-800,90]
[-800,-60,-40,-20,0,1,30,70,90,500]





3. 插入排序

插入排序（英语：Insertion Sort）是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常采用in-place排序（即只需用到 O(1) 的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。


void insertion_sort(int arr[], int len){
    int i,j,temp;
    for (i=1;i<len;i++){
            temp = arr[i];
            for (j=i;j>0 && arr[j-1]>temp;j--){
                    arr[j] = arr[j-1];
			}
            arr[j] = temp;
    }
}



4. 希尔排序 //todo
希尔排序，也称递减增量排序算法，是插入排序的一种更高效的改进版本。希尔排序是非稳定排序算法。

希尔排序是基于插入排序的以下两点性质而提出改进方法的：
- 插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率
- 但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位


void shell_sort(int arr[], int len) {
    int gap, i, j;
    int temp;
    for (gap = len >> 1; gap > 0; gap = gap >> 1){
        for (i = gap; i < len; i++) {
            temp = arr[i];
            for (j = i - gap; j >= 0 && arr[j] > temp; j -= gap){
                arr[j + gap] = arr[j];
			}
            arr[j + gap] = temp;
        }
	}
}





5. 归并排序 //todo
把数据分为两段，从两段中逐个选最小的元素移入新数据段的末尾。

可从上到下或从下到上进行。






6.快速排序 //todo
在区间中随机挑选一个元素作基准，将小于基准的元素放在基准之前，大于基准的元素放在基准之后，再分别对小数区与大数区进行排序。







ref:
https://www.runoob.com/cprogramming/c-sort-algorithm.html






========================================
随机化：洗牌算法 -- 神一样的公平随机化
----------------------------------------
1.问题
给一套扑克牌，请给出公平的随机化排序方法。
公平: 每个位置出现每张牌的概率都相同。

当然尽量简洁，减少运算量。

这个算法就是大名鼎鼎的 Knuth-Shuffle，即 Knuth 洗牌算法





2. 参考答案
总体思路: 随机的取两张，互换位置。然后交换k次即可。请问k取多少合适呢？10,100,1000,...?

for(int i = n - 1; i >= 0 ; i -- )
    swap(arr[i], arr[rand() % (i + 1)])
# 为什么能做到保证：对于生成的排列，每一个元素都能等概率的出现在每一个位置了。


用js实现一下:

arr=[0,1,2,3,4]

n=arr.length
for(var i=n-1; i>=0; i--){
	var r=Math.round( Math.random()*n ) % (i+1);
	console.log('i=',i, '; r=', r, '; arr=', arr)
	var tmp=arr[i]
	arr[i]=arr[r]
	arr[r]=tmp;
}
arr //[3, 0, 4, 2, 1]

n=5;
第一个循环 i=n-1=4, 从前面几个随机挑选一个和最后一个(第4位)交换位置，也即是任何数字出现在最后一位的概率是 1/5;
第二个循环 i=3, 从0-3随机挑选一个数字放到第3位，则数字3出现的概率: 逃过第一个循环 4/5 * 第二次选中 1/4=1/5;
以此类推。


优点:
- 整个算法的复杂度是 O(n) 的。
- 从后向前简化代码。（因为生成 [0, i] 范围的随机数比生成 [i, n) 范围的随机数简单，直接对 i+1 求余就好了。）




3. 更多用法
在很多随机的地方，都能使用。

比如，扫雷生成随机的盘面。我们可以把扫雷的二维盘面先逐行连接，看作是一维的。之后，把 k 颗雷依次放在开始的位置。

算法从来不是枯燥的逻辑堆砌，而是神一样的逻辑创造。

尽管这个世界很复杂，但竟也如此的简洁，优雅。






ref:
https://www.jianshu.com/p/4be78c20095e







========================================
二分查找
----------------------------------------
二分查找(折半查找)
	优点：比较次数少，查找速度快，平均性能好，占用系统内存较少
	缺点：要求待查表为有序表，且插入删除困难。因此适用于不经常变动而查找频繁的有序列表。


算法描述：
首先，假设表中元素是按升序排列，将表中间位置记录的关键字与查找关键字比较，如果两者相等，则查找成功;
否则利用中间位置记录将表分成前、后两个子表，如果中间位置记录的关键字大于查找关键字，则进一步查找前一子表，否则进一步查找后一子表。
重复以上过程，直到找到满足条件的记录，使查找成功，或直到子表不存在为止，此时查找不成功。




1. 对已排序的数据进行二分查找，返回位置编号。
(1) 如果有该数据，则给出编号。

#include<stdio.h>
int BinarySearch(int arr[], int len, int target){
	int low=0, high=len-1, mid=(low+high)/2;
	int oldMid=mid;
	while(low < high){
		if(target > arr[mid]){
			low=mid;
			mid=(low+high)/2;
		}else if(target < arr[mid]){
			high=mid;
			mid=(low+high)/2;
		}else{
			return mid;
		}
		//看mid是否更新过，如果没有，则查找结束
		if(mid==oldMid){
			return -1;
		}else{
			oldMid=mid;
		}
	}
	return -1;
}

int main(){
	int arr[]={1,3,4,6,8,10};
	
	int num=8, index, n=sizeof(arr)/sizeof(int);
	index=BinarySearch(arr, n, num);
	printf("index = %d\n", index);
	return 0;
}

输出: index = 4

## 如果没有呢？如果超出范围呢？
尝试3个值，范围外2个，中间1个。
输出：index = -1




(2)优化后的 二分查找
让代码更简洁，同时使用的变量更少。

#include<stdio.h>
int BinarySearch(int arr[], int len, int target){
	int low=0, high=len-1, mid;
	while(low <= high){
		mid=(low+high)/2;
		
		if(target == arr[mid]){
			return mid;
		}else if(target < arr[mid]){
			high=mid-1;
		}else{
			low=mid+1;
		}
	}
	return -1;
}

int main(){
	int arr[]={1,3,4,6,8,10};
	
	int num=4, index, n=sizeof(arr)/sizeof(int);
	index=BinarySearch(arr, n, num);
	printf("index = %d\n", index);
	return 0;
}

输出: index = 2








(3) 递归法二分查找
http://data.biancheng.net/view/122.html

#include<stdio.h>
int BinarySearch2(int arr[], int low, int high, int target){
	if(low>high){
		return -1;
	}
	int mid;
	while(low <= high){
		mid=(low+high)/2;
		if(target == arr[mid]){
			return mid;
		}else if(target < arr[mid]){
			return BinarySearch2(arr, low, mid-1, target);
		}else{
			return BinarySearch2(arr, mid+1, high, target);
		}
	}
	return -1;
}

int main(){
	int arr[]={1,3,4,6,8,10};
	
	int num=4, index, n=sizeof(arr)/sizeof(int);
	index=BinarySearch2(arr, 0, n-1, num);
	printf("index if %d is %d\n", num,  index);
	return 0;
}

输出: index if 4 is 2






2. leetcode中第33.题：搜索旋转排序数组
假设按照升序排序的数组在预先未知的某个点上进行了旋转。( 例如，数组 [0,1,2,4,5,6,7] 可能变为 [4,5,6,7,0,1,2] )。
搜索一个给定的目标值，如果数组中存在这个目标值，则返回它的索引，否则返回 -1 。
可以假设数组中不存在重复的元素。算法时间复杂度必须是 O(log n) 级别。

示例 1:
输入: nums = [4,5,6,7,0,1,2], target = 0
输出: 4
示例 2:
输入: nums = [4,5,6,7,0,1,2], target = 3
输出: -1

这种旋转过的也可以二分查找？好好理解，

#include<stdio.h>
int BinarySearch3(int arr[], int len, int target){
	int low=0, high=len-1, mid;
	while(low <= high){
		mid=(low+high)/2;
		if(target == arr[mid]){
			return mid;
		//如果左边有序
		}else if(arr[0] < arr[mid]){
			if( arr[0]<=target && target<arr[mid] ){
				high=mid-1;
			}else{
				low=mid+1;
			}
		//如果右边有序
		}else{
			if( arr[mid]<target && target<arr[len-1] ){
				low=mid+1;
			}else{
				high=mid-1;
			}
			
		}
	}
	return -1;
}

int main(){
	int arr[]={4,5,6,7,0,1,2};
	int len=sizeof(arr)/sizeof(int);
	int num;
	num=0; printf("index if %d is %d\n", num,  BinarySearch3(arr, len, num) );
	num=3; printf("index if %d is %d\n", num,  BinarySearch3(arr, len, num) );
	return 0;
}

输出：
index if 0 is 4
index if 3 is -1






========================================
贪心算法 (某一个策略的穷举法)：只是局部最优解
----------------------------------------

例题1: 给出一系列课程的开始和结束时间，找出能安排到某个教室上课的做多课程是什么？
音乐 8:00-9:00
语文   8:30-9:30
数学    9:00-10:00
历史      9:30-10:30
英语      10:00-11:00

贪婪策略：找出最早结束的课程 音乐，
然后找出其结束后才开始的课程中(数学、历史、英语)，最早结束的课程 数学，
然后找出其结束后才开始的课程中(英语)，最早结束的课程 英语。
所以，最后的结果就是
音乐 8:00-9:00
数学    9:00-10:00
英语      10:00-11:00

记住贪心策略，每次选择的都是对于当前而言最优的。


1. 所谓贪心算法是指，在对问题求解时，总是做出在当前看来是最好的选择。
也就是说，不从整体最优上加以考虑，他所做出的仅是在某种意义上的局部最优解。

贪心算法没有固定的算法框架，算法设计的关键是贪心策略的选择。必须注意的是，贪心算法不是对所有问题都能得到整体最优解，选择的贪心策略必须具备无后效性，即某个状态以后的过程不会影响以前的状态，只与当前状态有关。

所以对所采用的贪心策略一定要仔细分析其是否满足无后效性。

(2) 贪心算法的基本思路：
1).建立数学模型来描述问题。
2).把求解的问题分成若干个子问题。
3).对每一子问题求解，得到子问题的局部最优解。
4).把子问题的解局部最优解合成原来解问题的一个解。


(3) 贪心算法适用的问题
贪心策略适用的前提是：局部最优策略能导致产生全局最优解。

实际上，贪心算法适用的情况很少。一般，对一个问题分析是否适用于贪心算法，可以先选择该问题下的几个实际数据进行分析，就可做出判断。

(4) 贪心算法的实现框架
从问题的某一初始解出发；
while （能朝给定总目标前进一步）
{ 
   利用可行的决策，求出可行解的一个解元素；
}
由所有解元素组合成问题的一个可行解；

(5) 贪心策略的选择
因为用贪心算法只能通过解局部最优解的策略来达到全局最优解，因此，一定要注意判断问题是否适合采用贪心算法策略，找到的解是否一定是问题的最优解。

与动态规划不同的是，贪心算法得到的是一个局部最优解（即有可能不是最理想的），而动态规划算法得到的是一个全局最优解（即必须是整体而言最理想的），一个有趣的事情是，动态规划中的01背包问题就是一个典型的贪心算法问题。





2. 代码实现

(1) 由浅入深，不妨先将动态规划中的01背包问题弄熟悉，再来学习贪心算法的基础思维，其实在很多时候自己并未发觉自己已经是在使用贪心了，当你基本掌握了一些贪心的概念的时候，可以做一些诸如装箱问题，切割问题，区域分配问题的题目，巩固自己的知识。

下面是一个可以试用贪心算法解的题目，贪心解的确不错，可惜不是最优解。

[背包问题]有一个背包，背包容量是M=150。有7个物品，物品可以分割成任意大小。
要求尽可能让装入背包中的物品总价值最大，但不能超过总容量。

物品  A  B  C  D  E  F  G
重量 35 30 60 50 40 10 25
价值 10 40 30 50 35 40 30

分析：
目标函数： ∑pi最大
约束条件是装入的物品总重量不超过背包容量：∑wi<=M( M=150)
1）根据贪心的策略，每次挑选价值最大的物品装入背包，得到的结果是否最优？
2）每次挑选所占重量最小的物品装入是否能得到最优解？
3）每次选取单位重量价值最大的物品，成为解本题的策略。

值得注意的是，贪心算法并不是完全不可以使用，贪心策略一旦经过证明成立后，它就是一种高效的算法。

贪心算法还是很常见的算法之一，这是由于它简单易行，构造贪心策略不是很困难。
可惜的是，它需要证明后才能真正运用到题目的算法中。
一般来说，贪心算法的证明围绕着：整个问题的最优解一定由在贪心策略中存在的子问题的最优解得来的。

对于例题中的3种贪心策略，都是无法成立（无法被证明）的，解释如下：
1）贪心策略：选取价值最大者。反例：
W=30
物品： A  B  C
重量：28 12 12
价值：30 20 20
根据策略，首先选取物品A，接下来就无法再选取了，可是，选取B、C则更好。

2）贪心策略：选取重量最小。它的反例与第一种策略的反例差不多。

3）贪心策略：选取单位重量价值最大的物品。反例：
W=30
物品： A  B  C
重量：28 20 10
价值：28 20 10
根据策略，三种物品单位重量价值一样，程序无法依据现有策略作出判断，如果选择A，则答案错误。




(2) 相关例题

有很多经典的应用，比如霍夫曼编码（Huffman Coding）、Prim 和 Kruskal 最小生成树算法、还有 Dijkstra 单源最短路径算法，最小生成树算法和最短路径算法，甚至是一些暴力求解题目，都是使用了贪心的这种思维。

可以直接从dotcpp网站标签中搜索贪心即可，贪心算法在很多题目中均或多或少有一些思维的应用，因此题目涵盖非常广阔，非常适合逐步练习。




(3) 发工资问题

财务处的小李最近就在考虑一个问题：如果每个员工的工资额都知道，最少需要准备多少张人民币，才能在给每位员工发工资的时候都不用员工找零呢？
这里假设程序猿的工资都是正整数，单位元，人民币一共有100元、50元、10元、5元、2元和1元六种。


输入数据包含多个测试实例，每个测试实例的第一行是一个整数n（n<100），表示员工的人数，然后是n个员工的工资。
n=0表示输入的结束，不做处理。

输出
对于每个测试实例输出一个整数x,表示至少需要准备的人民币张数。每个输出占一行。

样例输入
3 1 2 3
0

样例输出
4

思路：给每个员工最少的纸币，然后几个人加起来即可。
每个人最少，就是从最大的额度开始减，不为负就一直减，为负就换小额纸币。直到剩余金额为0.

示例代码:
#include<stdio.h>
int getLeast(int wage){
	int i, money[]={100,50,10,5,2,1};
	int num[]={0,0,0,0,0,0}; //存储每张纸币的个数
	int count=0, resid=wage;
	for(i=0; i<6; i++){
		while(resid - num[i]*money[i] >=0 ){
			num[i]++;
		}
		if(num[i]>0){
			num[i]--;
			resid -= num[i]*money[i];
		}
		if(resid==0){
			break;
		}
	}
	for(i=0; i<6; i++){
		count += num[i];
	}
	//printf("==> %d: %d\n", wage, count);
	return count;
}

int main(){
	int i, len=0, wage=0, number=0;
	scanf("%d", &len);
	for(i=0; i<len; i++){
		scanf("%d", &wage);
		number+= getLeast(wage);
	}
	printf("%d\n", number);
	return 1;
}

输出：
1 120
3

3 1 2 3
4

2 266 111
==> 266: 6
==> 111: 3
9


代码简化: 删掉中间变量 resid
#include<stdio.h>
int getLeast(int wage){
	int i, money[]={100,50,10,5,2,1};
	int j, count=0;
	for(i=0; i<6; i++){
		j=0;
		while(wage - j*money[i] >=0 ){
			j++;
		}
		if(j>0){
			j--;
			wage -= j*money[i];
		}
		count+=j;
		
		if(wage==0){
			break;
		}
	}
	return count;
}

int main(){
	int i, len=0, wage=0, number=0;
	scanf("%d", &len);
	for(i=0; i<len; i++){
		scanf("%d", &wage);
		number+= getLeast(wage);
	}
	printf("%d\n", number);
	return 1;
}



(4) Huffuman树
Huffman树在编码中有着广泛的应用。在这里，我们只关心Huffman树的构造过程。
给出一列数{pi}={p0,  p1,  …,  pn-1}，用这列数构造Huffman树的过程如下：
1). 找到{pi}中最小的两个数，设为pa和pb，将pa和pb从{pi}中删除掉，然后将它们的和加入到{pi}中。这个过程的费用记为pa  +  pb。
2).  重复步骤1，直到{pi}中只剩下一个数。
在上面的操作过程中，把所有的费用相加，就得到了构造Huffman树的总费用。
本题任务：对于给定的一个数列，现在请你求出用该数列构造Huffman树的总费用。

例如，对于数列{pi}={5,  3,  8,  2,  9}，Huffman树的构造过程如下：
1.  找到{5,  3,  8,  2,  9}中最小的两个数，分别是2和3，从{pi}中删除它们并将和5加入，得到{5,  8,  9,  5}，费用为5。
2.  找到{5,  8,  9,  5}中最小的两个数，分别是5和5，从{pi}中删除它们并将和10加入，得到{8,  9,  10}，费用为10。
3.  找到{8,  9,  10}中最小的两个数，分别是8和9，从{pi}中删除它们并将和17加入，得到{10,  17}，费用为17。
4.  找到{10,  17}中最小的两个数，分别是10和17，从{pi}中删除它们并将和27加入，得到{27}，费用为27。
5.  现在，数列中只剩下一个数27，构造过程结束，总费用为5+10+17+27=59。

输入
输入的第一行包含一个正整数n（n< =100）。 
接下来是n个正整数，表示p0,  p1,  …,  pn-1，每个数不超过1000。 

输出
输出用这些数构造Huffman树的总费用。 

样例输入
5 
5 3 8 2 9

样例输出
59


代码示例：

#include<stdio.h>

//去掉最小的数(其后的值前移)，并返回该值
int rmLeastIndex(int arr[], int *len){
	int i, index=0;
	for(i=0; i<*len; i++){
		if(arr[index] > arr[i]){
			index=i;
		}
	}
	//最小值
	int num=arr[index];
	for(i=index; i<*len-1; i++){
		arr[i]=arr[i+1];
	}
	(*len)--;
	return num;
}

int main(){
	int arr[]={5, 3, 8, 2, 9};
	int j, len=sizeof(arr)/sizeof(int), cost, totalCost=0;
	int val[2];
	
	while(len>1){
		cost=0;
		for(j=0; j<2; j++){
			val[j]= rmLeastIndex(arr, &len);
			cost += val[j];
		}
		// 末尾新增一个元素
		arr[len]=cost;
		len++;
		
		totalCost+=cost;
		printf("rm %d, %d, cost=%d, totalCost=%d, len=%d\n", val[0], val[1], cost, totalCost, len);
	}
	printf("=>total cost=%d\n", totalCost);
	return 0;
}

输出:
rm 2, 3, cost=5, totalCost=5, len=4
rm 5, 5, cost=10, totalCost=15, len=3
rm 8, 9, cost=17, totalCost=32, len=2
rm 10, 17, cost=27, totalCost=59, len=1
=>total cost=59






(5) 下面各种算法是否是贪婪算法 //todo
快速排序：不是。
广度优先排序：是。
迪克斯特拉算法：是。








ref: https://www.dotcpp.com/course/169



========================================
动态规划 Dynamic Programming
----------------------------------------

动态规划算法要求将求解问题拆分为一系列相互交叠的子问题。
动态规划三要素：
	最优子结构
	边界
	状态转移函数



1. 简介
(1)
动态规划（Dynamic Programming，DP）是运筹学的一个分支，是求解决策过程最优化的过程。20世纪50年代初，美国数学家贝尔曼（R.Bellman）等人在研究多阶段决策过程的优化问题时，提出了著名的最优化原理，从而创立了动态规划。动态规划的应用极其广泛，包括工程技术、经济、工业生产、军事以及自动化控制等领域，并在背包问题、生产经营问题、资金管理问题、资源分配问题、最短路径问题和复杂系统可靠性问题等中取得了显著的效果



(2) 基本思想
动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优值的解。

动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解。与分治法不同的是，适合于用动态规划求解的问题，经分解得到子问题往往不是互相独立的。若用分治法来解这类问题，则分解得到的子问题数目太多，有些子问题被重复计算了很多次。如果我们能够保存已解决的子问题的答案，而在需要时再找出已求得的答案，这样就可以避免大量的重复计算，节省时间。我们可以用一个表来记录所有已解的子问题的答案。不管该子问题以后是否被用到，只要它被计算过，就将其结果填入表中。这就是动态规划法的基本思路。

具体的动态规划算法多种多样，但它们具有相同的填表格式。


(3) 什么样的问题适合使用动态规划
- 求最大值/最小值
- 求可不可行
- 求方案总数
以上三个问题，90%的概率是使用DP来求解的。
说明: 如果让求出“所有的”方案和结果，肯定不是使用DP。




(4) 什么情况下用动态规划
https://www.zhihu.com/question/39948290

"So you didn't need to recount because you remembered there were eight!
Dynamic Programming is just a fancy way to say 'remembering stuff to save time later'"

DP is just a kind of smart recursion
动态规划就是记忆化搜索

取决于该问题是否能用动态规划解决的是这些“小问题”会不会被被重复调用。


(5) 三大步骤:
- 建立状态转移方程: 一个状态和之前状态的等式关系
	大概长这样
		* f[i][j] = f[i - 1][j] + f[i][j - 1]
		* f[i] = max{f[j] if j > i and …} + 1
		* f[i][j] = f[0][j - 1] && judge(1,i) || f[1][j - 1] && judge(2,i) || …
		
- 缓存并复用以往的结果
- 按顺序从小往大算






========================================
|-- 动态规划：爬楼梯问题
----------------------------------------

2. 爬楼梯问题
##########
例1: 有n个阶梯，一个人每一步只能跨一个台阶或是两个台阶，问这个人一共有多少种走法？

首先要对这个问题进行抽象，n个阶梯，每个阶梯都代表一个“位置”， 就像是图论中的一个“点”，然后这些n个不同位置之间会有一些桥梁把它们连起来：


简化: 假设有10个台阶。
抽象化，就是node1到node10有几种不同的路可以走。

如果1个台阶，就一种走法。
2个台阶，则是2种走法：1+1, 或 直接2。
走到10，只能从9+1，或8+2两种途径。
用F(x) 表示1到x的方法数，则
	F(x-1) 和 F(x-2) 被称作 F(x) 的最优子结构
	F(1)=1, F(2)=2 是问题的边界
	F(x) = F(x-1) + F(x-2) 叫状态转移方程

1)直观方法是用递归
def getways(n):
    #print("调用: n=", n);
    if n==1:
        return 1
    elif n==2:
        return 2
    else:
        return getways(n-1)+getways(n-2)
getways(10)
# 89

这里计算了 109 次。
有很多重复计算，比如 计算F(10) 需要计算F(9) 和 F(8); 而计算F(9) 有需要计算一次F(8)。


2)如何减少重复计算？
把中间结果保存下来，方便复用。
加上中间结果缓存步骤，就是动态规划算法了。

我们创建一个数组a[]，专门来存放中间结果，初始值记为0，
然后每当要计算到x的路径数时，先检测一下该路径数的值是不是大于0，如果大于0，就表示计算过了。
如果等于0，则计算，并保存到a[x]中。
def dp(n):
    results=[0]*11
    results[1]=1
    results[2]=2    
    for i in range(3, n+1):
        results[i]=results[i-1]+results[i-2]
    return results[n];
dp(10)


3)还可以更节省内存，只使用2个变量，依次往前平移
#step1: a  b 
#step2:    b  a+b
def dp2(n):
    if n==1:
        return 1
    if n==2:
        return 2
    a=1
    b=2
    tmp=0
    for i in range(3, n+1):
        tmp=a+b;
        a=b;
        b=tmp;
    return b;
dp2(10)

小结：动态规划能知道共几种走法，但是不知道具体走法是什么。
要知道具体路线，据说需要用 深度优化搜索。








========================================
|-- 动态规划：走网格问题
----------------------------------------
3. 走网格问题
##########
例2: 在一个7x3的网格中，左上角格子是入口，一次只能向下、或向左移动一次，问移动到右下角格子有几种不同的路径？

解答:
(1)如下方格3只能由1和2过来，所以 f(i,j)=f(i-1,j)+f(i, j-1)
   [1]
[2][3]

初始化 
f(1,1)=0, f(1,2)=1, 
f(2,1)=1, f(2,2)=2, 

最左边缘、最上边缘都是一种走法。
	所以可以全部初始化为1。
	且更新时不考虑这2个边缘。range(1, 7)

(2) 
实现1:
def walk(m,n):
    results=[[1 for i in range(n)] for j in range(m)] #[[1]*n]*m
    
    for i in range(1,m):
        for j in range(1,n):
            if results[i][j] == 1: #如果是初始值，则更新
                results[i][j]=results[i-1][j] + results[i][j-1]
            print('>> i=%d, j=%d' %(i,j),results)
    return results[-1][-1]
# test
walk(7,3) #28
# i=6, j=2 [[1, 1, 1], [1, 2, 3], [1, 3, 6], [1, 4, 10], [1, 5, 15], [1, 6, 21], [1, 7, 28]]


实现2:
import numpy as np
def walk(m,n):
    results=np.ones( (m,n) )
    
    for i in range(1,m):
        for j in range(1,n):
            if results[i][j]==1: #如果是初始值，则更新
                results[i][j]=results[i-1][j] + results[i][j-1]
            print('>> i=%d, j=%d \n' %(i,j),results)
    return results[-1][-1]
# test
walk(7,3) #28.0

#>> i=6, j=2 
 [[ 1.  1.  1.]
 [ 1.  2.  3.]
 [ 1.  3.  6.]
 [ 1.  4. 10.]
 [ 1.  5. 15.]
 [ 1.  6. 21.]
 [ 1.  7. 28.]]
#






========================================
|-- 动态规划：背包问题
----------------------------------------

4. 背包问题
https://www.geeksforgeeks.org/0-1-knapsack-problem-dp-10/

给定n个元素的重量和其对应的价值,将这些物品放在一个容量为W的背包中，并使得总价值最大。
数组val [0 . . n - 1]和wt [0 . . n - 1]，它们分别代表价值和重量。 总重量W代表背包容量，

具体化:
value[]={60,100,120};
weight[]={10,20,30};
W=50;
三个元素，价格分别是 value，重量分别是weight，只有一个最大承重为W的背包，最多能带走价值多少钱的物品？

(1) 递归版
每个元素都有2个状态，装进去1和不装进去0。
起始条件是
	装0个东西，价值是0.
	或者背包能装的重量是0，则这是价值为0.

第n个物品如果本身超重，就不能装了，直接返回不装它的情况。
然后返回装和不装第n个物品的价值中的较大值:
	装第n个物品，它的价值 val[n-1] + 前面价值 knapSack(W-wt[n-1], wt, val, n-1)，如果装了就把容量先占用了。
	不装第n个物品，则空箱子装前几个物品 knapSack(W, wt, val, n-1)

# A naive recursive implementation of 0-1 Knapsack Problem
# Returns the maximum value that can be put in a knapsack of capacity W
def knapSack(W, wt, val, n):
    # Base Case
    if n == 0 or W == 0:
        return 0

    # If weight of the nth item is more than Knapsack of capacity W,
    # then this item cannot be included in the optimal solution
    if (wt[n-1] > W):
        return knapSack(W, wt, val, n-1)
 
    # return the maximum of two cases:
    # (1) nth item included
    # (2) not included
    else:
        return max(
            val[n-1] + knapSack(W-wt[n-1], wt, val, n-1),
            knapSack(W, wt, val, n-1)
			)
# end of function knapSack

#Driver Code
val = [60, 100, 120]
wt = [10, 20, 30]
W = 50
n = len(val)
print( knapSack(W, wt, val, n) )
# This code is contributed by Nikhil Kumar Singh
# 220

分析重复了几种情况，简化：
函数变化的参数n和W
wt[] = {1, 1, 1}, W = 2, val[] = {10, 20, 30}
                       K(n, W)
                       K(3, 2)  
                   /            \ 
                 /                \               
            K(2, 2)                  K(2, 1)
          /       \                  /    \ 
        /           \              /        \
       K(1, 2)      K(1, 1)        K(1, 1)     K(1, 0)
       /  \         /   \              /        \
     /      \     /       \          /            \
K(0, 2)  K(0, 1)  K(0, 1)  K(0, 0)  K(0, 1)   K(0, 0)


(2) 如何把结果保存起来呢？
新建一个数组，保存初始化值。
找到递推关系。
然后从底部向顶部计算，中间结果保存，方便复用。

# A Dynamic Programming based Python Program for 0-1 Knapsack problem
# Returns the maximum value that can be put in a knapsack of capacity W
def knapSack(W, wt, val, n):
    K = [[0 for x in range(W + 1)] for x in range(n + 1)] # 初始化都是0

    # Build table K[][] in bottom up manner
    for i in range(n + 1):
        for w in range(W + 1):
            #i表示要装东西的个数，w表示背包剩余承重，任何一个为0，里面东西的价值只能是0.
            if i == 0 or w == 0: 
                K[i][w] = 0
            elif wt[i-1] <= w: #如果该物品本身不超重，它就有装和不装两个状态，返回价值最大的那个状态。
                K[i][w] = max(val[i-1] + K[i-1][w-wt[i-1]],  K[i-1][w])
            else: #该物品单品超重，则去掉该物品
                K[i][w] = K[i-1][w]
    return K[n][W]

# Driver code
val = [60, 100, 120]
wt = [10, 20, 30]
W = 50
n = len(val)
print(knapSack(W, wt, val, n)) #220
# This code is contributed by Bhavya Jain


(3) 更节省空间的动态规划
# A Dynamic Programming based Python Program for 0-1 Knapsack problem
# Returns the maximum value that can be put in a knapsack of capacity W
def knapSack(W, wt, val, n):
    dp = [0 for i in range(W+1)]  # Making the dp array
 
    for i in range(1, n+1):  # taking first i elements
		# starting from back,so that we also have data of 
		# previous computation when taking i-1 items
        for w in range(W, 0, -1): 
            if wt[i-1] <= w:
                # finding the maximum value
                dp[w] = max(dp[w], dp[w-wt[i-1]] + val[i-1])
 
    return dp[W]  # returning the maximum value of knapsack

# Driver code
val = [60, 100, 120]
wt = [10, 20, 30]
W = 50
n = len(val)
# This code is contributed by Suyash Saxena
print(knapSack(W, wt, val, n))










##########
例3: 正则表达式匹配的实现 [地狱级]
给定字符串string和一个字符规律pattern，请实现一个支持"."和"*"的正则表达式匹配。
说明: 
. 匹配任意 单个 字符
* 匹配0个或多个前面的那个字符。

解答:
https://www.zhihu.com/question/39948290
还没看懂...








3. 动态规划与其说是一个算法，不如说是一种方法论。该方法论主要致力于将 合适 的问题拆分成三个子目标一一击破：

- 建立状态转移方程
- 缓存并复用以往结果
- 按顺序从小往大算


更多练习:
https://www.lintcode.com/problem/?tag=dynamic-programming

https://www.es.ele.tue.nl/education/5MC10/Solutions/knapsack.pdf
http://cse.unl.edu/~goddard/Courses/CSCE310J/Lectures/Lecture8-DynamicProgramming.pdf






========================================
分而治之/分治: Divide-and-Conquer
----------------------------------------

1. 基本概念
(1)在计算机科学中，分治法是一种很重要的算法。字面上的解释是“分而治之”，就是把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并。这个技巧是很多高效算法的基础，如排序算法(快速排序，归并排序)，傅立叶变换(快速傅立叶变换)……


(2) 基本思想及策略

分治法的设计思想是：将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之。

分治策略是：对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题形式相同，递归地解这些子问题，然后将各子问题的解合并得到原问题的解。这种算法设计策略叫做分治法。

如果原问题可分割成k个子问题，1<k≤n，且这些子问题都可解并可利用这些子问题的解求出原问题的解，那么这种分治法就是可行的。由分治法产生的子问题往往是原问题的较小模式，这就为使用递归技术提供了方便。在这种情况下，反复应用分治手段，可以使子问题与原问题类型一致而其规模却不断缩小，最终使子问题缩小到很容易直接求出其解。这自然导致递归过程的产生。分治与递归像一对孪生兄弟，经常同时应用在算法设计之中，并由此产生许多高效算法。

(3) 分治法适用的情况
分治法所能解决的问题一般具有以下几个特征：
  1) 该问题的规模缩小到一定的程度就可以容易地解决
  2) 该问题可以分解为若干个规模较小的相同问题，即该问题具有最优子结构性质。
  3) 利用该问题分解出的子问题的解可以合并为该问题的解；
  4) 该问题所分解出的各个子问题是相互独立的，即子问题之间不包含公共的子子问题。

第一条特征是绝大多数问题都可以满足的，因为问题的计算复杂性一般是随着问题规模的增加而增加；

第二条特征是应用分治法的前提它也是大多数问题可以满足的，此特征反映了递归思想的应用；

第三条特征是关键，能否利用分治法完全取决于问题是否具有第三条特征，如果具备了第一条和第二条特征，而不具备第三条特征，则可以考虑用贪心法或动态规划法。

第四条特征涉及到分治法的效率，如果各子问题是不独立的则分治法要做许多不必要的工作，重复地解公共的子问题，此时虽然可用分治法，但一般用动态规划法较好。

(4) 可使用分治法求解的一些经典问题
  二分搜索
  大整数乘法
  Strassen矩阵乘法
  棋盘覆盖
  合并排序
  快速排序
  线性时间选择
  最接近点对问题
  循环赛日程表
  汉诺塔

(5) 分治法的基本步骤
分治法在每一层递归上都有三个步骤：
step1 分解：将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题；
step2 解决：若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题
step3 合并：将各个子问题的解合并为原问题的解。


(6) 依据分治法设计程序时的思维过程
 
实际上就是类似于数学归纳法，找到解决本问题的求解方程公式，然后根据方程公式设计递归程序。
1) 一定是先找到最小问题规模时的求解方法
2) 然后考虑随着问题规模增大时的求解方法
3) 找到求解的递归函数式后（各种规模或因子），设计递归程序即可。



2. 算法举例
(1) 回文
这里的回文是指资格字符串，它从头到尾读与从尾到头读的内容是一致的，比如说doggod,无论从左到右耗时从右到左都是一样的。

python代码: 可以看出算法就是利用递归不断的处理更小的子问题。
def isPal(s):
    if len(s) <= 1:
        return True
    else:
        return s[0]==s[-1] and isPal(s[1:-1])
 
s = 'doggod'
result = isPal(s)
print(result)


使用C语言:
#include<stdio.h>
int isPal(char arr[], int start, int end){
	if( end-start <=1){
		return 1;
	}
	
	return arr[start]==arr[end] && isPal(arr, start+1, end-1);
}

int main(){
	char arr[]="doggod";
	int len= sizeof(arr)/sizeof(char)-1; //字符串最后一位是 '\0' 不需要
	int rs = isPal(arr, 0, len-1);
	printf("rs=%d\n", rs);
	return 0;
}
输出: rs=1



(2) 二分查找
二分查找也是典型的分治算法的有应用。二分查找需要一个默认的前提，那就是查找的数列是有序的。 
二分查找的思路比较简单： 
  选择一个标志i将集合分为二个子集合 
  判断标志L(i)是否能与要查找的值des相等，相等则直接返回 
  否则判断L(i)与des的大小 
  基于判断的结果决定下步是向左查找还是向右查找 
  递归记性上面的步骤

#include<stdio.h>
int binarySearch(int arr[], int target, int low, int high){
	int mid=(low+high)/2;
	if( target == arr[mid]){
		return mid;
	}else if( target > arr[mid]){
		return binarySearch(arr, target, mid+1, high);
	}else{
		return binarySearch(arr, target, low, mid-1);
	}
}

int main(){
	int arr[]={1,3,5,7,9, 12, 200};
	int target=9, len=sizeof(arr)/sizeof(int);
	int index=binarySearch(arr, target, 0, len-1);
	printf("index of %d in arr is %d\n", target, index);
	return 0;
}

输出: index of 9 in arr is 4






小结：
分治算法的一个核心在于子问题的规模大小是否接近，如果接近则算法效率较高。

分治算法和动态规划都是解决子问题，然后对解进行合并；但是分治算法是寻找远小于原问题的子问题（因为对于计算机来说计算小数据的问题还是很快的），同时分治算法的效率并不一定好，而动态规划的效率取决于子问题的个数的多少，子问题的个数远小于子问题的总数的情况下（也就是重复子问题多），算法才会很高效。






========================================
回溯 //todo
----------------------------------------

https://blog.csdn.net/qq_39382769/article/details/80796100
https://blog.csdn.net/qq_37763204/article/details/79519671







========================================
分支界限法 //todo
----------------------------------------
https://blog.csdn.net/qq_37763204/article/details/79519980




========================================
广度优化搜索 //todo
----------------------------------------



========================================
深度优化搜索 //todo
----------------------------------------



========================================
双指针 //todo
----------------------------------------



========================================
递归 //todo
----------------------------------------


========================================
KMP //todo
----------------------------------------



========================================
神奇的位运算 //todo
----------------------------------------




========================================
巧解数学问题 & 妙用数据结构 //todo
----------------------------------------






========================================
K Nearest Neighbor算法又叫KNN算法 (K最近邻算法): Annoy 算法 //todo
----------------------------------------

1. 定义

如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。


K近邻算法哪家强？KDTree、Annoy、HNSW原理和使用方法介绍 https://zhuanlan.zhihu.com/p/152522906
在介绍具体算法之前，我们先简单回顾一下KNN算法的三要素：距离度量、k值的选择和分类决策规则。

距离最近的k个点
	距离怎么算？
	什么是最近？






2. 距离的定义
其中机器学习领域常用的距离度量方法，有欧式距离、余弦距离、曼哈顿距离、dot内积等

Seurat 4 中几种距离的计算方法，可选: euclidean, cosine, manhattan, and hamming

主流的近邻算法都支持上述不同的距离度量。其中n维特征空间的a、b向量的欧式距离: 差的平方和再开方，体现数值上的绝对差异；
而余弦距离基于余弦相似度（两个向量间夹角的余弦值），体现方向上的相对差异。
如果对向量做归一化处理，二者的结果基本是等价的。






3. K近邻算法的实现方法

K近邻的实现方式多达数十种，笔者从中挑选了几种常用、经典的方法作为分析案例。

首先最直观的想法（暴力法），是线性扫描法。将待预测样本和候选样本逐一比对，最终挑选出距离最接近的k个样本即可，时间复杂度O(n)。对于样本数量较少的情况，这种方法简单稳定，已经能有不错的效果。但是数据规模较大时，时间开销严重无法接受。

所以实际应用中，往往会寻找其他类型的数据结构来保存特征，以降低搜索的时间复杂度。

常用的存储结构可以分为树和图两大类。
	树结构的代表是KDTree，以及改进版BallTree和Annoy等；
	基于图结构的搜索算法有HNSW等。


(1) KDTree
kd 树是一种对k维特征空间中的实例点进行存储以便对其快速检索的树形数据结构。

kd树是二叉树，核心思想是对 k 维特征空间不断切分（假设特征维度是768，对于(0,1,2,...,767)中的每一个维度，以中值递归切分）构造的树，每一个节点是一个超矩形，小于结点的样本划分到左子树，大于结点的样本划分到右子树。

树构造完毕后，最终检索时（1）从根结点出发，递归地向下访问kd树。若目标点 [公式] 当前维的坐标小于切分点的坐标，移动到左子树，否则移动到右子树，直至到达叶结点；（2）以此叶结点为“最近点”，递归地向上回退，查找该结点的兄弟结点中是否存在更近的点，若存在则更新“最近点”，否则回退；未到达根结点时继续执行（2）；（3）回退到根结点时，搜索结束。

kd树在维数小于20时效率最高，一般适用于训练实例数远大于空间维数时的k近邻搜索；当空间维数接近训练实例数时，它的效率会迅速下降，几乎接近线形扫描。


(2) BallTree
为了解决kd树在样本特征维度很高时效率低下的问题，研究人员提出了“球树“BallTree。KD 树沿坐标轴分割数据，BallTree将在一系列嵌套的超球面上分割数据，即使用超球面而不是超矩形划分区域。

具体而言，BallTree 将数据递归地划分到由质心 C 和 半径 r 定义的节点上，以使得节点内的每个点都位于由质心C和半径 r 定义的超球面内。通过使用三角不等式 [公式] 减少近邻搜索的候选点数。



(3) Annoy
annoy全称“Approximate Nearest Neighbors Oh Yeah”，是一种适合实际应用的快速相似查找算法。Annoy 同样通过建立一个二叉树来使得每个点查找时间复杂度是O(log n)，和kd树不同的是，annoy没有对k维特征进行切分。

annoy的每一次空间划分，可以看作聚类数为2的KMeans过程。收敛后在产生的两个聚类中心连线之间建立一条垂线（图中的黑线），把数据空间划分为两部分。

在划分的子空间内不停的递归迭代继续划分，直到每个子空间最多只剩下K个数据节点，划分结束。

最终生成的二叉树具有如下类似结构，二叉树底层是叶子节点记录原始数据节点，其他中间节点记录的是分割超平面的信息。

查询过程和kd树类似，先从根向叶子结点递归查找，再向上回溯即可，完整构建、查找过程可以参考快速计算距离Annoy算法。



步骤:
首先构建一个“AnnoyIndex”索引对象，需指定特征维度和距离度量标准（支持多种距离度量方式），并将所有数据集样本特征顺序添加到索引对象中。

之后需要在 build(n_trees) 接口中指定棵数。annoy通过构建一个森林（类似随机森林的思想）来提高查询的精准度，减少方差。构建完成后，我们可以将annoy索引文件保存到本地，之后使用时可以直接载入。（完整说明文档参考annoy的github仓库）

最后，我们对输入的200条文本依次查找top3近邻。







ref:
KD 树: https://blog.csdn.net/qq_27396609/article/details/111639106 平衡kd树




========================================
----------------------------------------

========================================
----------------------------------------


========================================
----------------------------------------

========================================
----------------------------------------

========================================
----------------------------------------

