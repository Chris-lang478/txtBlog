Python104-packages(under jupyter notebook and python shell)
提示: 本文数据都是随手编造的，仅用于演示相应Python包的使用。


https://github.com/DawnEve/pydata-book
Python 数据分析的底层基石 Numpy； Python 数据清洗大杀器 Pandas。



https://www.data.gov/

NumPy 官网 http://www.numpy.org/
NumPy 源代码：https://github.com/numpy/numpy

SciPy 官网：https://www.scipy.org/
SciPy 源代码：https://github.com/scipy/scipy

Matplotlib 官网：https://matplotlib.org/
Matplotlib 源代码：https://github.com/matplotlib/matplotlib





========================================
Numpy + Pandas 是python进行数据分析的基石
----------------------------------------
https://www.youtube.com/watch?v=To3YL92HZyc&list=PLXO45tsB95cKKyC45gatc8wEc3Ue7BlI4


Google在线深度学习神器Colab: https://www.jianshu.com/p/81eae79ee78b


1.因为基于C写的Numpy，所以速度快，比Python自身运算要快很多。
而且矩阵的计算也做了优化，比原生Python快十倍。

http://www.numpy.org/
NumPy is the fundamental package for scientific computing with Python. It contains among other things:

a powerful N-dimensional array object
sophisticated (broadcasting) functions
tools for integrating C/C++ and Fortran code
useful linear algebra, Fourier transform, and random number capabilities

除了科学计算，还可以任意定义数据，方便和数据库整合。Besides its obvious scientific uses, NumPy can also be used as an efficient multi-dimensional container of generic data. Arbitrary data-types can be defined. This allows NumPy to seamlessly and speedily integrate with a wide variety of databases.




2. 安装
pip install Numpy
pip install Pandas 


3.测试
import numpy as np
import pandas as pd

pd.test()
#报错 ImportError: Need pytest>=3.0 to run tests

安装 
$ pip install --user pytest

再测试，又报错：
$ pip install -U --user setuptools

不管了，先用吧。




========================================
numpy基本功能、矩阵操作
----------------------------------------
官方教程： https://numpy.org/devdocs/user/quickstart.html
中文版：https://www.jianshu.com/p/a260a8c43e44



1. 入门
import numpy as np

#pd.test()
array=np.array([
    [1,2,3],
    [4,5,6]])
print(array)
#[[1 2 3]
#[4 5 6]]

array.size #6
array.shape  #(2, 3)
array.ndim #2


2.用np创建array
NumPy中创建数组的方式有若干种。最简单的，可以直接利用Python中常规的list和tuple进行创建。

a=np.array([1,23,4])
a # array([ 1, 23,  4])

b=np.array((1,23,4)) #但是 b=np.array(1,23,4) 是错的，会报错 


#dtype 定义数据的位数，越高占的空间也越多
a=np.array([1,23,4],dtype=np.int)
print(a.dtype) #np.array([1,23,4])

a=np.array([1,23,4],dtype=np.float)
print(a.dtype) #float64

a=np.zeros((3,4));a #3行4列的0矩阵。
np.ones((2,4)) #2行4列的1矩阵


创建等差数列
np.arange(10,20) #array([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
np.arange(10,20,2) #等差是2 array([10, 12, 14, 16, 18])


#np.arange返回的不是list，而是array
np.arange( 10, 30, 5 ) #从10到29，以5为间隔
#array([10, 15, 20, 25])

np.arange(12).reshape(3,4) #3行4列
#array([[ 0,  1,  2,  3],
#       [ 4,  5,  6,  7],
#       [ 8,  9, 10, 11]])

np.linspace(1,10,5) #把1-10之间给出5个数字，平均间隔相同 
#array([ 1.  ,  3.25,  5.5 ,  7.75, 10.  ])
#该函数常用于为函数画点图
x = np.linspace( 0, 2*np.pi, 100 )
# useful to evaluate function at lots of points
f = np.sin(x)



3.矩阵运算

(1)加减乘除
a=np.array([10,20,40,30])
b=np.arange(4)
print(a,b) #[10 20 40 30] [0 1 2 3]

#减法
c=a-b
print(c) #[10 19 38 27]

b**2 #array([0, 1, 4, 9]) #乘方

10*np.sin(a) #三角函数 
#array([-5.44021111,  9.12945251,  7.4511316 , -9.88031624])

a<35 #布尔运算 array([ True,  True, False,  True])


(2)矩阵乘法
* 表示按照元素相乘。
a*b #array([ 0, 20, 80, 90])

使用@(python>=3.5)或者dot函数表示矩阵乘积
A = np.array( [[1,1],
             [0,1]] )
B = np.array( [[2,0],
             [3,4]] )
A@B #或者 A.dot(B)
#array([[5, 4],
#       [3, 4]])


(3)+= and *=直接修改已有矩阵，而不是创建一个新的
a = np.ones((2,3), dtype=int)
b = np.random.random((2,3))
a *= 3
a
#array([[3, 3, 3],
#       [3, 3, 3]])
b += a
b
#array([[3.57371054, 3.01654088, 3.23986455],
#      [3.4613754 , 3.11336145, 3.40659914]])
a +=b #报错，b不会自动转为整数，因为会丢失精度【upcasting向上转型问题】
a+b #这样不会报错
b +=a #int->float向下转型无所谓，因为不丢失任何精度。


向下转型没问题，越来越细，占用越来越多空间
a=np.ones(3,dtype=np.int32);print(a)
b=np.linspace(0,np.pi, 3); print(b)
#[1 1 1]
#[0.         1.57079633 3.14159265]
b.dtype #dtype('float64')
c=a+b;print(c); #[1.         2.57079633 4.14159265]
c.dtype #dtype('float64')
d=np.exp(c*1j);print(d)
d.dtype #dtype('complex128')


(4)很多像sum等计算一元类的是以ndarray类的方法提供的
a = np.random.random((2,3))
a.sum()
a.min()
a.max()
a.mean()

还可以指定轴参数axis：
b = np.arange(12).reshape(3,4)
b
# array([[ 0,  1,  2,  3],
#        [ 4,  5,  6,  7],
#        [ 8,  9, 10, 11]])
print( b.sum() ) #总和 66
print( b.sum(axis=0) ) #列求和 array([12, 15, 18, 21])
b.sum(axis=1) #行求和 array([ 6, 22, 38])
b.cumsum(axis=1) #每一行的累加
# array([[ 0,  1,  3,  6],
#        [ 4,  9, 15, 22],
#        [ 8, 17, 27, 38]])




(5)通用函数
NumPy提供很多数学函数，如sin, cos, and exp，统称通用函数“universal functions”(ufunc)。作用于每个元素，输出为array。
>>> B = np.arange(3)
>>> B
array([0, 1, 2])
>>> np.exp(B)
array([ 1.        ,  2.71828183,  7.3890561 ])
>>> np.sqrt(B)
array([ 0.        ,  1.        ,  1.41421356])
>>> C = np.array([2., -1., 4.])
>>> np.add(B, C)
array([ 2.,  0.,  6.])






========================================
|-- numpy 索引、切片、迭代(Indexing, Slicing and Iterating)
----------------------------------------
1. 一维数组可以像list和其他python序列一样索引、切片、迭代。

a=np.arange(10)**3;a
# array([  0,   1,   8,  27,  64, 125, 216, 343, 512, 729])

a[2] #8 第一个下标是0
a[2:5] # 有头2无尾5 array([ 8, 27, 64])

a[:6:2] = -1000 # equivalent to a[0:6:2] = -1000; from start to position 6, exclusive, set every 2nd element to -1000
a
# array([-1000,     1, -1000,    27, -1000,   125,   216,   343,   512,
         729])
a[ : :-1]  # reversed a		 
# array([  729,   512,   343,   216,   125, -1000,    27, -1000,     1,
       -1000])
for i in a:
     print(i**(1/3.))




2. 多维数组，则每个轴可以有一个index。
>>> def f(x,y):
...     return 10*x+y
...
>>> b = np.fromfunction(f,(5,4),dtype=int)
>>> b
array([[ 0,  1,  2,  3],
       [10, 11, 12, 13],
       [20, 21, 22, 23],
       [30, 31, 32, 33],
       [40, 41, 42, 43]])
>>> b[2,3]
23
>>> b[0:5, 1]            # each row in the second column of b
array([ 1, 11, 21, 31, 41])
>>> b[ : ,1]             # equivalent to the previous example
array([ 1, 11, 21, 31, 41])
>>> b[1:3, : ]            # each column in the second and third row of b
array([[10, 11, 12, 13],
       [20, 21, 22, 23]])

#当维度少于实际维度时，则认为剩余维度为全部。
b[-1]     # the last row. Equivalent to b[-1,:]，或者用三个点 b[-1,...]
# array([40, 41, 42, 43])

三个点可以表达任意维度的全部：
 x[1,2,...] is equivalent to x[1,2,:,:,:],
 x[...,3] to x[:,:,:,:,3] and
 x[4,...,5,:] to x[4,:,:,5,:].





3. 迭代
对多维数组的迭代是相对于第一维度的。
for row in b:
     print(row)
# [0 1 2 3]
# [10 11 12 13]
# [20 21 22 23]
# [30 31 32 33]
# [40 41 42 43]

如果相对每一个元素做运算，则可以使用flat属性展开一个array
for element in b.flat:
     print(element)
# 0
# 1
# 2
# 3
# 10
# 11





========================================
|-- numpy的IO
----------------------------------------
1.读取csv文件
$ cat score.csv 
1,2,3,4,5
10,20,30,40,50

score=np.genfromtxt("/home/wangjl/score.csv",delimiter=",")
score
# array([[ 1.,  2.,  3.,  4.,  5.],
#        [10., 20., 30., 40., 50.]])


2.保存结果






========================================
Scipy: high-level scientific computing(教程)
----------------------------------------
https://docs.scipy.org/doc/numpy/user/quickstart.html

1.描述
SciPy (pronounced “Sigh Pie”) 是一个开源软件，用于数学、科研、工程计算。
依赖NumPy提供的方便快速的N维数组操作。
SciPy库建立在NumPy数组上，提供用户友好的、高效的数值路径：数据整合和优化。
它们在主流系统上都能跑，好安装，免费。
NumPy and SciPy使用方便，收到世界顶级科学家和工程师的信赖。
If you need to manipulate numbers on a computer and display or publish the results, give SciPy a try!

scipy包含致力于科学计算中常见问题的各个工具箱。它的不同子模块相应于不同的应用。像插值，积分，优化，图像处理，统计，特殊函数等等。



2. Scipy简介
文件输入和输出scipy.io
线性代数操作scipy.linalg
快速傅里叶变换scipy.fftpack
优化器scipy.optimize
统计工具scipy.stats

因为兼容等历史原因，scipy明星空间本身有很多numpy导入的函数(尝试 scipy.cos 就是 np.cos)。
建议任何时候都不要使用 import scipy，而要使用：
from scipy import stats
或
import scipy.io as spio



3. Scipy课程
http://www.scipy-lectures.org/
每个课程1-2h，由浅入深。

SciPy Tutorial
https://docs.scipy.org/doc/scipy/reference/tutorial/index.html
https://docs.scipy.org/doc/scipy/reference/tutorial/
https://docs.scipy.org/doc/scipy/reference/

中文：
https://www.jianshu.com/p/1a3db06e786d

Scipy有很多子模块可以应对不同的应用，例如插值运算，优化算法、图像处理、数学统计等。
https://blog.csdn.net/q583501947/article/details/76735870






========================================
Matplotlib: 散点图、折线图、直方图、柱状图、箱线图
----------------------------------------
四个可视化目标：
分布：柱状图、散点图、概率密度曲线图
相关：散点图with相关系数、拟合曲线
构成：柱状图with不同颜色、饼图
比较：柱状图、分面


官网：https://matplotlib.org/contents.html
教程：http://www.scipy-lectures.org/intro/matplotlib/index.html



1.简介
使用Matplotlib，它是用Python写的类似Matlib的库，能实现Matlib的功能，而且画图的质量很高，可用于做论文发表。

Matplotlib需要配合numpy,scipy才能使用，使用pip安装。
$ pip install --user matplotlib



2.实例：绘制散点图
# -*- coding: utf-8 -*-
"""
绘制散点图
"""
import numpy as np
import matplotlib.pyplot as plt

# 数据个数
n = 1024
# 均值为0, 方差为1的随机数
x = np.random.normal(0, 1, n)
y = np.random.normal(0, 1, n)

# 计算颜色值
color = np.arctan2(y, x)
# 绘制散点图
plt.scatter(x, y, s = 75, c = color, alpha = 0.5)
# 设置坐标轴范围
plt.xlim((-1.5, 1.5))
plt.ylim((-1.5, 1.5))

# 不显示坐标轴的值
plt.xticks(())
plt.yticks(())

plt.show()






3.实例：绘制柱状图，上下方向成对的柱状图
# -*- coding: utf-8 -*-

"""
绘制柱状图
"""

import matplotlib.pyplot as plt
import numpy as np

# 数据数目
n = 10
x = np.arange(n)
# 生成数据, 均匀分布(0.5, 1.0)之间
y1 = (1 - x / float(n)) * np.random.uniform(0.5, 1.0, n)
y2 = (1 - x / float(n)) * np.random.uniform(0.5, 1.0, n)

# 绘制柱状图, 向上
plt.bar(x, y1, facecolor = 'blue', edgecolor = 'white')
# 绘制柱状图, 向下
plt.bar(x, -y2, facecolor = 'green', edgecolor = 'white')

temp = zip(x, y2)
# 在柱状图上显示具体数值, ha水平对齐, va垂直对齐
for x, y in zip(x, y1):
    plt.text(x + 0.05, y + 0.1, '%.2f' % y, ha = 'center', va = 'bottom')

for x, y in temp:
    plt.text(x + 0.05, -y - 0.1, '%.2f' % y, ha = 'center', va = 'bottom')

# 设置坐标轴范围
plt.xlim(-1, n)
plt.ylim(-1.5, 1.5)
# 去除坐标轴
plt.xticks(())
plt.yticks(())
plt.show()







4.实例：绘制登高线图
# -*- coding: utf-8 -*-
"""
绘制登高线图
"""
import matplotlib.pyplot as plt
import numpy as np

# 定义等高线高度函数
def f(x, y):
    return (1 - x / 2 + x ** 5 + y ** 3) * np.exp(- x ** 2 - y ** 2)

# 数据数目
n = 256
# 定义x, y
x = np.linspace(-3, 3, n)
y = np.linspace(-3, 3, n)

# 生成网格数据
X, Y = np.meshgrid(x, y)

# 填充等高线的颜色, 8是等高线分为几部分
plt.contourf(X, Y, f(X, Y), 8, alpha = 0.75, cmap = plt.cm.hot)
# 绘制等高线
C = plt.contour(X, Y, f(X, Y), 8, colors = 'black', linewidth = 0.5)
# 绘制等高线数据
plt.clabel(C, inline = True, fontsize = 10)

# 去除坐标轴
plt.xticks(())
plt.yticks(())
plt.show()





5.实例：绘制heatmap
# -*- coding: utf-8 -*-
"""
绘制Image 
"""
import matplotlib.pyplot as plt
import numpy as np

# 定义图像数据
a = np.linspace(0, 1, 16).reshape(4, 4)
# 显示图像数据
plt.imshow(a, interpolation = 'nearest', cmap = 'bone', origin = 'lower')
# 添加颜色条
plt.colorbar()
# 去掉坐标轴
plt.xticks(())
plt.yticks(())
plt.show()








6.实例：绘制3D图形
# -*- coding: utf-8 -*-
"""
绘制3d图形
"""

import matplotlib.pyplot as plt
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
# 定义figure
fig = plt.figure()
# 将figure变为3d
ax = Axes3D(fig)

# 数据数目
n = 256
# 定义x, y
x = np.arange(-4, 4, 0.25)
y = np.arange(-4, 4, 0.25)

# 生成网格数据
X, Y = np.meshgrid(x, y)

# 计算每个点对的长度
R = np.sqrt(X ** 2 + Y ** 2)
# 计算Z轴的高度
Z = np.sin(R)

# 绘制3D曲面
ax.plot_surface(X, Y, Z, rstride = 1, cstride = 1, cmap = plt.get_cmap('rainbow'))
# 绘制从3D曲面到底部的投影
ax.contour(X, Y, Z, zdim = 'z', offset = -2, cmap = 'rainbow')

# 设置z轴的维度
ax.set_zlim(-2, 2)

plt.show()








7.实例：subplot绘制多图
# -*- coding: utf-8 -*-
"""
subplot绘制多图 
"""

import matplotlib.pyplot as plt

plt.figure()

# 绘制第一个图
plt.subplot(2, 2, 1)
plt.plot([0, 1], [0, 1])
# 绘制第二个图
plt.subplot(2, 2, 2)
plt.plot([0, 1], [0, 1])
# 绘制第三个图
plt.subplot(2, 2, 3)
plt.plot([0, 1], [0, 1])
# 绘制第四个图
plt.subplot(2, 2, 4)
plt.plot([0, 1], [0, 1])
plt.show()




第一行占3列的布局：
# -*- coding: utf-8 -*-
"""
subplot绘制多图 
"""
import matplotlib.pyplot as plt
plt.figure()

# 绘制第一个图
plt.subplot(2, 1, 1) #2行1列的第1行
plt.plot([0, 1], [0, 1])
# 绘制第二个图
plt.subplot(2, 3, 4) #2行3列的第4个
plt.plot([0, 1], [0, 1])
# 绘制第三个图
plt.subplot(2, 3, 5)
plt.plot([0, 1], [0, 1])
# 绘制第四个图
plt.subplot(2, 3, 6)
plt.plot([0, 1], [0, 1])
plt.show()











refer:
https://matplotlib.org/contents.html
https://github.com/matplotlib/matplotlib

http://lib.csdn.net/article/python/43397
https://blog.csdn.net/qq_34337272/article/details/79555544




========================================
pandas: 数据清洗 powerful Python data analysis toolkit (df可保存到excel文件中)
----------------------------------------
1.简介
官网： http://pandas.pydata.org/
文档：http://pandas.pydata.org/pandas-docs/stable/
Cookbook: http://pandas.pydata.org/pandas-docs/stable/cookbook.html#cookbook

中文：https://www.yiibai.com/pandas/python_pandas_series.html



安装
$ conda install pandas
或
$ pip install pandas
$ pip install --upgrade pandas


pandas 解决什么问题？
python善于数据整理和预处理，不太擅长数据分析和建模，pandas弥补了这一点。
对于线性拟合和panel回归之外的建模，请使用statsmodels and scikit-learn包。
距离Python成为统计建模环境的一类公民还很远，我们正在努力。


pandas包含的数据类型：Series和DataFrame。
 - Series：一维数组，与Numpy中的一维array类似。二者与Python基本的数据结构List也很相近。Series如今能保存不同种数据类型，字符串、boolean值、数字等都能保存在Series中。
 - Time- Series：以时间为索引的Series。
 - DataFrame：二维的表格型数据结构。很多功能与R中的data.frame类似。可以将DataFrame理解为Series的容器。
 - Panel ：三维的数组，可以理解为DataFrame的容器。

我们重点学习DataFrame



2. 10分钟入门
http://pandas.pydata.org/pandas-docs/stable/10min.html
首先导入pandas库，一般都会用到numpy库，所以我们先导入备用：

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt #可能画图

(1)创建对象
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html

nlist=['artical 1','a20','a30','a40','a50']
plist=[10,20,30,40,50]
clist=['评论1','评论2','评论3','评论4','评论5']

df=pd.DataFrame( data={'name':nlist, 'price':plist, 'comment':clist} )
#print(df.dtypes)
df
## 结果
# 	name	price	comment
# 0	artical 1	10	评论1
# 1	a20	20	评论2
# 2	a30	30	评论3
# 3	a40	40	评论4
# 4	a50	50	评论5

#转置行和列 https://blog.csdn.net/u013817676/article/details/94861359
df2=df.stack();
#print(df2) #将df格式从表格形式转化成了花括号结构
df3=df2.unstack(0) #行列转置，将第二行的列索引转化成行索引
df3
# 	0	1	2	3	4
# name	artical 1	a20	a30	a40	a50
# price	10	20	30	40	50
# comment	评论1	评论2	评论3	评论4	评论5

# 保存到excel中 pip install openpyxl
with pd.ExcelWriter('aaa.xlsx') as writer:
    df.to_excel(writer, sheet_name="aaa")

# 简洁形式
df=pd.DataFrame(data={'name':nlist, 'price':plist})
df.to_excel(xlsName, sheet_name=sheet_name)


#更复杂的形式：合并2个数据框
#df1 = pd.DataFrame(nlist,columns=['product'])
#df2 = pd.DataFrame(plist,columns=['price'])
#df3 = pd.concat([df1,df2],axis=1,ignore_index=False)
#df3.to_excel('aaa.xlsx',sheet_name='aaa')




(2)用pandas筛选annovar结果文件
ex=pd.read_csv("EX23_.hg19_multianno.csv", na_values=["."]) #读取csv文件，并填充空值
ex

ex.shape #(628993, 88)

ex.dtypes

ex=ex.fillna(0) #用0填充na值

#测试语句
tmp=ex["1000g2015aug_all"].iloc[50:60]
print(tmp)
tmp<0.01

#filter1:
print( ex["Func.refGene"].value_counts() ) #对某一列进行计数
ex2=ex[ex["Func.refGene"].isin(['exonic',"exonic;splicing","splicing"])] #对一列进行筛选
ex2.shape #(25347, 88)

#filter2:
ex3=ex2[ (ex2["1000g2015aug_all"]<0.01) & (ex2['1000g2015aug_eas']<0.01) & (ex2['esp6500siv2_all']<0.01) \
        & (ex2['ExAC_ALL']<0.01)& (ex2['ExAC_EAS']<0.01)] #对一列进行筛选
ex3.shape #(1484, 88)

#filter?:是不是要挑出来 非同意突变
ex3["ExonicFunc.refGene"].value_counts()

#过滤后的结果，保存到csv中
ex3.to_csv("EX23_.hg19_multianno.filter1_2.csv")






3.python:pandas 合并多个DataFrame
https://www.jianshu.com/p/5ecea164cec6

http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html
 - merge 左右合并
 - join
 

 - append 上下合并
 - concat





========================================
|-- pandas 读取文件(文本/excel/mysql)、数据结构(Series/DataFrame)
----------------------------------------
视频:
https://www.bilibili.com/video/BV1UJ411A7Fs?p=1
https://www.bilibili.com/video/BV16E411G7sd?p=1

英文视频:
https://www.bilibili.com/video/BV1zA411b7Ly?from=search&seid=7102611799471868216




使用jupyter演示。
首先引入库
import pandas as pd;



1. 读取数据
数据类型	说明	pandas读取方法
csv/tsv/txt 逗号、tab分割的纯文本文件 pd.read_csv()
excel	微软xls/xlsx文件 pd.read_excel()
mysql 关系型数据库 	pd.read_sql()


例1: 读存文本文件
fpath="xx.csv"
ratings=pd.read_csv(fpath); #读取csv文件 help(pd.read_csv)查看更多参数
	# sep="\t" 指定分隔符为tab，默认为逗号;
	# header=None, 没有标题行
	# names=['pdate', 'pv', 'uv'] 给出列名
ratings.head();#查看前几行

ratings.shape #查看行列数
ratings.columns #查看列名

ratings.index #查看索引列

ratings.dtypes #查看每一列数据类型


例2: 读取excel
fpath="xx.xlsx"
pvuv=pd.read.excel(fpath);


例3: 读取mysql
import pymysql
conn=pymysql.connect(
	host='127.0.0.1',
	user='root',
	password="123456",
	database='test',
	charset='utf8'
)

mysql_page=pd.read_sql('select * from tableName', con=conn)
mysql_page







2. pandas的数据结构: 
DataFrame 二维数据，整个表格，多行多列;
Series 一维数据，一行或一列；

竖着为 df.columns;
横着为 df.index;

(1) Series例子
例1: a=pd.Series([1,2,3,4,5]); 默认三个参数 data,index默认是从0开始的编号,dtype
a
# 0    1
# 1    2
# 2    3
# 3    4
# 4    5
# dtype: int64

加更多参数
a=pd.Series([1,2,3,4,5], index=['a','b','c','d','e'], dtype=float);
a
# a    1.0
# b    2.0
# c    3.0
# d    4.0
# e    5.0
# dtype: float64



例2: 也可以使用numpy作为输入
import numpy as np;
a=np.arange(5);
pd.Series(a)
结果同例1。


例3: 传入字典
dic={'name':'Lee', 'gender':'M', 'age':18}
pd.Series(dic) #key变索引，value变data; 如果这里再次设置index则会覆盖字典的key
# name      Lee
# gender      M
# age        18
# dtype: object


例4: 当一个值，却多个索引时
pd.Series(5, [0,1,10])
# 0     5
# 1     5
# 10    5
# dtype: int64

#pd.Series([3,5], [0,1,10,100]) 报错 Length of passed values is 2, index implies 4





(2) DataFrame数据结构，和R的data.frame类似

例1: 创建数据框
a=np.random.randint(0,10,(2,3)) #2行3列
pd.DataFrame(a, index=['a', 'b'], columns=['x','y','z']) #定义index行名，columns列名
#	x	y	z
#a	0	5	1
#b	6	3	2


例2: 传入字典 
population={'beijing':1000, 'shanghai':1200,'guangzhou':999}
a=pd.Series(population)
b=pd.DataFrame(a) ##直接传入字典会报错；
#传入index=population.keys()输出也是不正确的; pd.DataFrame(population, index=population.keys())
print(a)
b
# beijing      1000
# shanghai     1200
# guangzhou     999
# dtype: int64
#
#            0
# beijing	1000
# shanghai	1200
# guangzhou	999

pd.DataFrame(a, columns=['population']) #可以修改列名
# 	   population
# beijing	1000
# shanghai	1200
# guangzhou	999

#如果非要传入字典，也可构建字典形式的参数:
pd.DataFrame( {'data2':population} )
# 	      data2
# beijing	1000
# guangzhou	999
# shanghai	1200

#再补充一个json数据，key要一致，则构建两列数据框：
gdp={'beijing':1, 'shanghai':1.5,'guangzhou':3}
pd.DataFrame( {'population':population, 'gdp':gdp} )
#	population	gdp
#beijing	1000	1.0
#guangzhou	999	3.0
#shanghai	1200	1.5

#还可以添加一个常数列
pd.DataFrame( {'population':population, 'gdp':gdp, 'country':'China'} )
#	   population	gdp	country
# beijing	1000	1.0	China
# guangzhou	999	3.0	China
# shanghai	1200	1.5	China






3. 属性
a=pd.DataFrame( {'population':population, 'gdp':gdp} )
a
#	population	gdp
#beijing	1000	1.0
#guangzhou	999	3.0
#shanghai	1200	1.5

a.values
# array([[1.00e+03, 1.00e+00],
#        [9.99e+02, 3.00e+00],
#        [1.20e+03, 1.50e+00]])

a.index #获取行名
# Index(['beijing', 'guangzhou', 'shanghai'], dtype='object')

a.columns #获取列名
# Index(['population', 'gdp'], dtype='object')

a.shape #(3, 2) 3行2列

a.size #几个元素 6

a.dtypes #每列数据的类型
# population      int64
# gdp           float64
# dtype: object



========================================
|-- 索引、切片、赋值、新增列/行
----------------------------------------
数据接上文
a
# 	   population	gdp
# beijing	1000	1.0
# guangzhou	999	3.0
# shanghai	1200	1.5


1. 如何取一列? 直接使用[]
a['gdp'] #取列名为gdp的一列
# beijing      1.0
# guangzhou    3.0
# shanghai     1.5
# Name: gdp, dtype: float64

或者使用点号
a.gdp #同上




2. 如何取出一行 loc[]
(1)
a.loc['beijing'] #注意是方括号，不是圆括号！
# population    1000.0
# gdp              1.0
# Name: beijing, dtype: float64


#取多行数据
a.loc[ ['beijing', 'guangzhou'] ] #注意输入的是数组形式
#	  population	gdp
# beijing	1000	1.0
# guangzhou	999	3.0

#如果不是数组呢
a.loc[ 'beijing', 'guangzhou' ]
# 报错 'the label [guangzhou] is not in the [index]' 说明第二个参数要是列
a.loc[ 'beijing', 'population' ] #1000 精确返回 beijing行 population列的数据



(2) 切片的方式取出多行，冒号
a.loc[ 'beijing':'guangzhou' ]
# 	  population	gdp
# beijing	1000	1.0
# guangzhou	999	3.0


(3)还可以使用数字编号指定行
a.iloc[0] #第一行
# population    1000.0
# gdp              1.0
# Name: beijing, dtype: float64

a.iloc[1] #第二行
# population    999.0
# gdp             3.0
# Name: guangzhou, dtype: float64

a.iloc[[0,2]] #第1,3行
# 	   population	gdp
# beijing	1000	1.0
# shanghai	1200	1.5




3. 取出一个具体的数值，行列交叉
(1)
a.loc[ 'shanghai', 'gdp' ] #1.5
a.iloc[ 2, 1] #1.5

(2) 按照numpy数组形式取值
print(type(a.values)) #<class 'numpy.ndarray'> 转为numpy类
a.values[2,1] #1.5 
a.values[2][1] #1.5


(3) iloc切片方式
a.iloc[:2, :] #前0,1行，全部列
#	population	gdp
#beijing	1000	1.0
#guangzhou	999	3.0


#切片a:b是一个[a,b)区间
t1=[10,1,2,3,4,5,6,7]
print( t1[0:4])
t1[1:4] # 左闭右开区间



4. 对某一列按条件筛选
a.gdp>1
# beijing      False
# guangzhou     True
# shanghai      True
# Name: gdp, dtype: bool

a[a.gdp>1]
# 	  population	gdp
# guangzhou	999	3.0
# shanghai	1200	1.5

a[a.gdp==1.5]
#	  population	gdp
# shanghai	1200	1.5




5. 赋值
(1)修改某个值，就是使用loc，iloc等定位到元素，然后就可以赋值了
a.iloc[1,1] #3
a.iloc[1,1]=3.2 #赋值

a
#	  population	gdp
# beijing	1000	1.0
# guangzhou	999	3.2 #这里已经修改了
# shanghai	1200	1.5






6. 新增行或列
(1) 新增一列
先新建一个Series，行标题index和原来一样
s=pd.Series([10,20,30], index=['beijing', 'shanghai', 'guangzhou'])
s
# beijing      10
# shanghai     20
# guangzhou    30
# dtype: int64


a['cName']=s; #指定列名
a
# 	  population	gdp	cName
# beijing	1000	1.0	10
# guangzhou	999	3.2	30
# shanghai	1200	1.5	20



(2) 新增一行
a.loc['zhengzhou'] = [1300,0.8,9]
a
# 	  population	gdp	cName
# beijing	1000.0	1.0	10.0
# guangzhou	999.0	3.2	30.0
# shanghai	1200.0	1.5	20.0
# zhengzhou	1300.0	0.8	9.0

(3) 通过合并2个数据框，新增一行或多行
df1=pd.DataFrame([888,0.9,9.5]).T #默认是列向量，变为行向量;
df1.columns = a.columns # 修改df1的column和a的一致
df1.index=['nj'] #修改行名
df1
#   population	gdp	cName
# nj	888.0	0.9	9.5


# 把两个dataframe合并，需要设置 ignore_index=True
#pd.concat([a,df1],ignore_index=True) #ignore_index就会损失掉index
pd.concat([a,df1])
#	  population	gdp	cName
# beijing	1000.0	1.0	10.0
# guangzhou	999.0	3.2	30.0
# shanghai	1200.0	1.5	20.0
# zhengzhou	1300.0	0.8	9.0
# nj	888.0	0.9	9.5



ref:
https://www.bilibili.com/video/BV16E411G7sd?p=5



========================================
|-- 数据查看
----------------------------------------
#先构建数据
dates=pd.date_range(start="2020-1-1", periods=6)
dates
#DatetimeIndex(['2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04',
#               '2020-01-05', '2020-01-06'],
#              dtype='datetime64[ns]', freq='D')

df=pd.DataFrame(np.random.randint(0,10,(6,4)), index=dates, columns=['A','B','C','D'])
df
# 	           A	B	C	D
# 2020-01-01	5	4	7	2
# 2020-01-02	7	6	9	2
# 2020-01-03	0	6	6	8
# 2020-01-04	9	2	5	5
# 2020-01-05	8	2	5	6
# 2020-01-06	8	3	4	9

1. 查看每一列的数据的特征
df.describe() #统计角度
#           A              B          C         D
# count	6.000000	6.000000	6.000000	6.000000
# mean	6.166667	3.833333	6.000000	5.333333
# std	3.311596	1.834848	1.788854	2.943920
# min	0.000000	2.000000	4.000000	2.000000
# 25%	5.500000	2.250000	5.000000	2.750000
# 50%	7.500000	3.500000	5.500000	5.500000
# 75%	8.000000	5.500000	6.750000	7.500000
# max	9.000000	6.000000	9.000000	9.000000


df.info() #对每一类的描述(内存角度)
# <class 'pandas.core.frame.DataFrame'>
# DatetimeIndex: 6 entries, 2020-01-01 to 2020-01-06 #对索引的描述
# Freq: D
# Data columns (total 4 columns): #对每一列的数据表述
# A    6 non-null int64
# B    6 non-null int64
# C    6 non-null int64
# D    6 non-null int64
# dtypes: int64(4)
# memory usage: 240.0 bytes



2. 查看前几行、后几行
df.head() #默认前5行
df.head(2)

df.tail() #末尾5行



3. 转置行和列
df.T


4. 排序
df.sort_index(axis=1, ascending=False) #按照列名排序，倒序
# 	           D	C	B	A
# 2020-01-01	2	7	4	5
# 2020-01-02	2	9	6	7
# 2020-01-03	8	6	6	0
# 2020-01-04	5	5	2	9
# 2020-01-05	6	5	2	8
# 2020-01-06	9	4	3	8

df.sort_index(axis=0, ascending=False) #按照行名排序，倒序
#               A	B	C	D
# 2020-01-06	8	3	4	9
# 2020-01-05	8	2	5	6
# 2020-01-04	9	2	5	5
# 2020-01-03	0	6	6	8
# 2020-01-02	7	6	9	2
# 2020-01-01	5	4	7	2


df.sort_values('C') #按照"C"列排序
#          A	B	C	D
# 2020-01-06	8	3	4	9
# 2020-01-04	9	2	5	5
# 2020-01-05	8	2	5	6
# 2020-01-03	0	6	6	8
# 2020-01-01	5	4	7	2
# 2020-01-02	7	6	9	2



========================================
|-- pandas 的计算、缺失值处理
----------------------------------------

1. 矩阵的运算
(1)和常量的加减法
a=pd.DataFrame([1,2,3])
a #3行1列的列向量
#      0
#0	1
#1	2
#2	3

a+7 #向量每个元素都增加7
# 	0
# 0	8
# 1	9
# 2	10

a.add(b) #结果同上。


(2) 矩阵和矩阵的加减法
b=pd.DataFrame([4,5,6])
a+b #就是对应元素相加
#	0
#0	5
#1	7
#2	9


(3) 矩阵的乘法
c=pd.DataFrame(np.random.randint(10, size=(1,3))) #1行3列
c
#	0	1	2
#0	7	1	3


d=a@c
d
# 	0	1	2
# 0	7	1	3
# 1	14	2	6
# 2	21	3	9
或者 a.dot(c)


(4)再次验证加法add()方法:
# 矩阵相加，如果维度不同，则缺失部分补0；如果直接使用+，则维度不同的地方直接NaN
a+d
#  	0	1	2
# 0	8	NaN	NaN
# 1	16	NaN	NaN
# 2	24	NaN	NaN

a.add(d, fill_value=0)
#      0	1	2
# 0	8	1.0	3.0
# 1	16	2.0	6.0
# 2	24	3.0	9.0







2. 缺失值的处理
创建一个有缺失值的矩阵
# pd.DataFrame( np.arange(9).reshape([3,3]) )
d.iloc[:2,2]=np.nan
d
#	 0	1	2
#0	7	1	NaN
#1	14	2	NaN
#2	21	3	9.0

(1) 直接丢掉含缺失值的行
d.dropna()
#	0	1	2
#2	21	3	9.0

(2) 直接丢掉含缺失值的列
d.dropna(axis=1)
#	0	1
# 0	7	1
# 1	14	2
# 2	21	3


(3) 如果只丢掉全部都是NaN的列呢？有一个NaN还可以接受
d.dropna(axis=1, how="all") #any默认, all
则返回值和原矩阵一行，因为没有全是NaN的列。


(4) 如果想挽救缺失值呢，NaN都填充为0
d.fillna(0)
#	0	1	2
# 0	7	1	0.0
# 1	14	2	0.0
# 2	21	3	9.0
注意: 原始的矩阵d并没有被改变！




========================================
|-- 合并(concat)和对齐(merge)
----------------------------------------
1. concat就是简单合并
a=pd.DataFrame(np.zeros([3,4]), columns=['a', 'b', 'c', 'd']);
b=pd.DataFrame(np.ones([3,4]), columns=['a', 'b', 'c', 'd']);
print(a)
b
#      a    b    c    d
# 0  0.0  0.0  0.0  0.0
# 1  0.0  0.0  0.0  0.0
# 2  0.0  0.0  0.0  0.0
# 
# 	 a	b	c	d
# 0	1.0	1.0	1.0	1.0
# 1	1.0	1.0	1.0	1.0
# 2	1.0	1.0	1.0	1.0


(1) 垂直合并
pd.concat([a,b])
#	a	b	c	d
#0	0.0	0.0	0.0	0.0
#1	0.0	0.0	0.0	0.0
#2	0.0	0.0	0.0	0.0
#0	1.0	1.0	1.0	1.0
#1	1.0	1.0	1.0	1.0
#2	1.0	1.0	1.0	1.0


#如果不想要行标题，设置ignore_index参数，行标题变成递增的编号
pd.concat([a,b], ignore_index=True)


(2) 水平合并
pd.concat([a,b], axis=1)
#	a	b	c	d	a	b	c	d
# 0	0.0	0.0	0.0	0.0	1.0	1.0	1.0	1.0
# 1	0.0	0.0	0.0	0.0	1.0	1.0	1.0	1.0
# 2	0.0	0.0	0.0	0.0	1.0	1.0	1.0	1.0



(3) 如果待合并的矩阵的行名和列名不一致，怎么合并？
a2=pd.DataFrame(np.zeros([3,4]),index=[0,1,2], columns=['a', 'b', 'c', 'd']);
b2=pd.DataFrame(np.ones([3,4]),index=[1,2,3], columns=['c', 'd','E','F']);
print(a2)
b2
#     a    b    c    d
#0  0.0  0.0  0.0  0.0
#1  0.0  0.0  0.0  0.0
#2  0.0  0.0  0.0  0.0
#
#	c	d	E	F
#1	1.0	1.0	1.0	1.0
#2	1.0	1.0	1.0	1.0
#3	1.0	1.0	1.0	1.0

pd.concat([a2,b2], axis=1) #水平合并(水平不做调整)
# 	a	b	c	d	c	d	E	F #可见，列名重复了，列名仅仅是简单平凑一起。
# 0	0.0	0.0	0.0	0.0	NaN	NaN	NaN	NaN
# 1	0.0	0.0	0.0	0.0	1.0	1.0	1.0	1.0
# 2	0.0	0.0	0.0	0.0	1.0	1.0	1.0	1.0
# 3	NaN	NaN	NaN	NaN	1.0	1.0	1.0	1.0
#行名做了整合，相同的行名只出现一次，没有数据的填充NaN;



(4) 
c=pd.Series([1,2,3,4], index=['a', 'b', 'c', 'd'])
c
# a    1
# b    2
# c    3
# d    4
# dtype: int64

a2.append(c, ignore_index=True) #底部新增一行
# 	a	b	c	d
# 0	0.0	0.0	0.0	0.0
# 1	0.0	0.0	0.0	0.0
# 2	0.0	0.0	0.0	0.0
# 3	1.0	2.0	3.0	4.0
#注意 a2 本身没有被改变







2. merge的用法:按照某一列合并
(1)
a3=pd.DataFrame([[2,0],[3,1]], columns=['A','B'])
a3
#	A	B
#0	2	0
#1	3	1

b3=pd.DataFrame([[20,0],[30,1]], columns=['C','B'])
b3
#	C	B
#0	20	0
#1	30	1

pd.merge(a3,b3) #相当于中间列B是一个桥梁中介，类似于sql中的where a.id=b.uid;
#	A	B	C
#0	2	0	20
#1	3	1	30







========================================
|-- 分组、数据透视表(groupby)
----------------------------------------
1. 分组查看
df=pd.DataFrame({'key':list('ABCCBA'),
	'data1':range(6),
	'data2':range(20,26)
})
df.iloc[0,1]=4 #修改一个值
df

# 	key	data1	data2
# 0	A	4	20
# 1	B	1	21
# 2	C	2	22
# 3	C	3	23
# 4	B	4	24
# 5	A	5	25

(1) 
df.groupby('key') #<pandas.core.groupby.groupby.DataFrameGroupBy object at 0x7faac8f64fd0>
df.groupby('key').sum()
#	data1	data2
#key		
#A	9	45
#B	5	45
#C	5	45

df.groupby('key').mean()
# 	data1	data2
# key		
# A	4.5	22.5
# B	2.5	22.5
# C	2.5	22.5

df.groupby('key')['data1'].mean() #某一列的均值
#      key
# A    4.5
# B    2.5
# C    2.5
# Name: data1, dtype: float64


df.groupby('key')[['data1']].mean() #返回数据框的形式
# 	data1
# key	
# A	4.5
# B	2.5
# C	2.5



(2) 自定义统计函数
def func1(x):
	x['data1'] /= x['data1'].sum();
	return x;
df.groupby('key').apply(func1)
# 	key	data1	data2
# 0	A	0.444444	20
# 1	B	0.200000	21
# 2	C	0.400000	22
# 3	C	0.600000	23
# 4	B	0.800000	24
# 5	A	0.555556	25
#确实已经做了改变;





2. 数据透视表
(1)导入数据集
import seaborn as sns;
titannic=sns.lead_dataset('titanic');
titannic.head()






========================================
Seaborn 包简介
----------------------------------------
1. 简介

seaborn的数据来自github: https://github.com/mwaskom/seaborn-data

(1) 示例和教程
seaborn 的图表很漂亮: https://blog.csdn.net/weixin_44766179/article/details/89133526
https://blog.csdn.net/weixin_44766179/article/details/89095211

(2) 官方教程
官网 http://seaborn.pydata.org/introduction.html
http://seaborn.pydata.org/tutorial/color_palettes.html







2. 安装
pip install seaborn;

使用seaborn总是报错:
ConnectionRefusedError: [Errno 111] Connection refused
URLError: <urlopen error [Errno 111] Connection refused>


==>方案1:https://blog.csdn.net/m0_37842667/article/details/83243722
添加:
import ssl
ssl._create_default_https_context = ssl._create_unverified_context
还是报错;

==>方案2: https://blog.csdn.net/qq_41477675/article/details/103543268
添加 iris=sns.load_dataset("iris",engine='python')
还是报错;











========================================
Python数据预处理（一）一抽取多源数据文本信息
----------------------------------------
https://www.imooc.com/learn/1105

本课程由数据预处理整个流程到综合实战。包括：Anaconda、Sublime、Pywin32、数据采集、数据集成、缺失值处理、正则、jieba分词、NLTK、词袋模型、数据抽样、特征词抽取、文本向量化、gensim、数据降维、numpy、sicpy、pandas、matplotlib、seabom、Xgboost等核心技术。



========================================
Python数据预处理（二）- 清洗文本数据
----------------------------------------
https://www.imooc.com/learn/1122

本课介绍数据预处理过程体系，包括数据类型与采集、文本转化与抽取、数据集成与规约、中文分词、数据清洗、特征提取与变换、特征向量化、特征降维、特征选择、可视化、词典模型、TF-IDF向量模型、主题模型等。




========================================
Python可视化包
----------------------------------------
https://www.jianshu.com/nb/30715100

seaborn，matplotlib，pychart包都可以。



========================================
|-- matplotlib-venn包绘制韦恩图 
----------------------------------------


使用
matplotlib-venn 包提供了四个主要的函数：venn2、venn2-circles、venn3 和 venn3-circles。
venn2和venn2_circles接受一个3元素（Ab，aB，AB）构成的 tuple 作为各个子集所包含元素的个数（不是具体的元素）：

Ab：包含A，但不包含B，即A中非B的部分，A∩¬BA∩¬B
aB：包含B，但不包含A，即B中非A，B∩¬AB∩¬A
AB：既包含A，又包含B，即A与B的交集，A∩B




核心代码：
from matplotlib_venn import venn2, venn2_circles
venn2(subsets=(3, 2, 1), set_labels=('A', 'B'))
venn2([set(['A', 'B', 'C', 'D']), set(['D', 'E', 'F'])])


实例: 
1.需要安装包
pip install --user matplotlib_venn

2.求两个集合的交集、差集的大小
n1=0
n2=0
for p in pasAll:
    if p in pasDB3:
        n1+=1
    else:
        n2+=1
print(n1, n2) #5576 128391

#
c1=0
c2=0
for p in pasDB3:
    if p in pasAll:
        c1+=1
    else:
        c2+=1
print(c1, c2) #5576 284593

3.绘图
#有标题
from matplotlib import pyplot as plt
from matplotlib_venn import venn2, venn2_circles
plt.figure(figsize=(6,6))
venn2(subsets=(n2,c2, c1), set_labels=('pA-Seq', 'PolyA_DB3'))
plt.title("(cid=all)M_gt5_No4A)")


#没有标题
from matplotlib_venn import venn2, venn2_circles
venn2(subsets=(n2,c2, c1), set_labels=('pA-Seq', 'PolyA_DB3'))








refer:
https://www.jianshu.com/p/25b0dc441247
https://pypi.org/project/matplotlib-venn/




========================================
|-- plt.pie 饼图
----------------------------------------
import matplotlib as mpl
import matplotlib.pyplot as plt

# 生成数据
labels = ['M', '1S', '2S', 'Other']
share = [0.49, 0.24, 0.2, 1-0.49-0.24-0.2] #41%, 24%, 20%

#颜色
colors=['lightgreen','gold','lightskyblue','lightcoral',"lightred"]
# 设置分裂属性
explode = [0, 0, 0, 0]

# 分裂饼图
plt.pie(share, explode = explode,
        labels = labels, autopct = '%3.1f%%',
        startangle = 0, #shadow = True,
        colors =colors )
plt.title('Mapping End by Cigar of c12_ROW03') # 标题
plt.axis('equal') #正圆
plt.show()



========================================
|-- matplotlib使用plt.savefig()保存图片文件
----------------------------------------
1.实例1：曲线图
#import numpy as np
import matplotlib.pyplot as plt
#import matplotlib

# 定义数据
x = np.arange(0, 10, 0.1)
y = 0.05 * x ** 2

#绘制图像
plt.plot(x, y)

# 设置坐标轴
plt.xlabel('x data')
plt.ylabel('y data')

# 默认保存为png格式
plt.savefig('/home/wangjl/data/apa/190610APA/pdf/test.png')
#plt.show()




2. 实例二： 获取当前 figure 的引用，然后调用 figure 对象的 savefig() 方法。
import numpy as np
import matplotlib.pyplot as plt
 
x = np.linspace(1, 100, 100)
y1 = np.random.randint(20, 60, size=100)
y2 = np.random.randint(30, 70, size=100)
y3 = np.random.randint(50, 90, size=100)
 
fig = plt.figure(num="111", figsize=(6, 4), facecolor="pink", edgecolor="green")
plt.plot(x, y1, c="red", label="y1_low")
plt.plot(x, y2, c="blue", label="y2_middle")
plt.plot(x, y3, c="yellow", label="y3_high")
plt.legend(loc="best")
# plt.show()
re = fig.savefig("a")




3.命令行运行时报错：RuntimeError: Invalid DISPLAY variable
https://blog.csdn.net/gdkyxy2013/article/details/79585922

原因：matplotlib的默认backend是TkAgg，而FltAgg、GTK、GTKCairo、TkAgg、Wx和WxAgg这几个backend都要求有GUI图形界面，所以在ssh操作的时候会报错。

解决办法：在导入matplotlib的时候指定不需要GUI的backend（Agg、Cairo、PS、PDF和SVG）。例如：
import matplotlib.pyplot as plt
plt.switch_backend('agg')




注意：
1. 在 plt.show() 之前调用 plt.savefig()，否则可能是空白图片；
　　import matplotlib.pyplot as plt
　　""" 一些画图代码 """
　　plt.savefig("filename.png")
　　plt.show()
#
2. 画图的时候获取当前图像（这一点非常类似于 Matlab 的句柄的概念）：
 　 # gcf: Get Current Figure
　　fig = plt.gcf()
　　plt.show()
　　fig1.savefig('test.png', dpi=100)

3.文件格式
savefig(fname, dpi=None, facecolor='w', edgecolor='w',
        orientation='portrait', papertype=None, format=None,
        transparent=False, bbox_inches=None, pad_inches=0.1,
        frameon=None)

参数：
fname : str 或者 file 对象，如果是 str 格式，文件的输出格式是根据 str 中的后缀决定的。如果字符串中没有后缀指定文件格式，则由 rc 参数 savefig.format 决定。
format ： str，文件格式，一般支持 png、pdf、ps、eps 和 svg。





https://blog.csdn.net/tz_zs/article/details/81365576 
https://matplotlib.org/api/_as_gen/matplotlib.pyplot.savefig.html



========================================
|-- matplotlib 可视化简介
----------------------------------------
1.一般流程
定义分析目标，数据采集及预处理，数据分析挖掘，数据可视化。

2.数据分析案例
(1)电影放映时间和入座率的时间序列模型；
(2)导航软件；
  全球飞机航线图；
(3)超市物品摆放；
  啤酒尿布案例。
  人口年龄的性别分布；
(4) 常见的可视化形式和工具
柱状图、折线图: 比较高低
分布散点图: 看趋势

(5) 常用的工具
分析工具: pandas, SciPy, numpy, sklearn;
绘图工具: matplotlib, Pychart, reportlab;
平台工具: Jupyter notebook, PyCharm;

Matplotlib 是Python的绘图库。
可以和 NumPy 一起使用，提供了一种有效的Matlab开源替代方案。
也可以和图形工具包一起使用，如PyQt和wxPython。

3. 安装
(1)安装 anaconda: Python环境和包管理工具，能切换Python版本。类似Java的Maven。
(2)安装 Jupyter Notebook: 基于网页的交互计算应用程序。可被用于全过程计算：开发、文档编写、运行代码和展示结果。
(3) 安装 matplotlib包。是Python的2D会图库，它以各种硬拷贝格式和跨平台的交互式环境生成出版级别的图形。

我是使用的 pip安装的包。


4. Hello world 绘图 
(1)黑窗口输入 jupyter notebook ，打开网页，新建py3文件；
(2)输入画图代码
import matplotlib.pyplot as plt
print('==load plt==', plt)

x=[1,2]
y=[3,4]
plt.bar(x,y)
plt.show()
## 画基本柱状图


5. 基本配置：如果不配置，可能中文不正常显示。
官网搜索 rcParams 参数，可见到详细参数意义。
常用设置：
(1)输出中文 
import matplotlib.pyplot as plt

import matplotlib as mpl
mpl.rcParams['font.sans-serif']=['SimHei'] #为了正常显示中文

x=[1,2]
y=[3,14]
plt.title("柱状图")
plt.bar(x,y)
plt.show()


(2) 正常输入坐标轴上的负数
import matplotlib.pyplot as plt

import matplotlib as mpl
mpl.rcParams['font.sans-serif']=['SimHei'] #为了正常显示中文
mpl.rcParams['axes.unicode_minus']=False #正常输入坐标轴上的负数

x=[1,2]
y=[-3,14]
plt.title("柱状图")
plt.bar(x,y)
plt.show()

(3) 修改线条宽度和类型
import matplotlib.pyplot as plt
%matplotlib inline
#
import matplotlib as mpl
mpl.rcParams['font.sans-serif']=['SimHei'] #为了正常显示中文
mpl.rcParams['axes.unicode_minus']=False #正常输入坐标轴上的负数
#
mpl.rcParams['lines.linewidth']=10 #修改线条宽度
mpl.rcParams['lines.linestyle']='--' #线条类型改为虚线

x=[1,2,3]
y=[-3,14,-9]
plt.title("折线图")
plt.plot(x,y)
plt.show()




========================================
|-- matplotlib 直方图、条形图、折线图和饼图
----------------------------------------
1. 直方图 需要2个参数(原始数据，区间)
每个柱子的高度等于该区间内数据的个数。

import matplotlib.pyplot as plt
#%matplotlib inline

height=[168,155,182,170,173,161,155,173,181,166,172,170]
bins=range(150, 191, 5) #步长为5

plt.title("hist plot")
plt.hist(height, bins=bins)
plt.show()




2. 条形图 plt.bar(X,Y)
使用宽度相同的条形的高度或长度来表示数据的数值。
更直观的显示图形关系。

import matplotlib.pyplot as plt

classes=['Class 1', 'Class 2', 'Class 3']
scores=[70,80,90]

plt.title("bar plot")
plt.bar(classes, scores)
plt.show()



3. 折线图 plt.plot(X,Y)
体现两个数据的关系，是否相关？是否正相关？能大致拟合为什么函数？

import matplotlib.pyplot as plt

classes=['Class 1', 'Class 2', 'Class 3']
scores=[70,80,90]

year=range(2017,2021) #区间是[)的，所以是2017-2020年的共4年
height=[157,170,176,180]

plt.plot(year, height)
plt.show()



4. 饼图 plt.pei(data)
饼图常用于显示一个数据系列中各项的大小与各项总和的比例。

#饼图
import matplotlib.pyplot as plt

labels=['Clothes', 'Food', 'Housing', 'Travel', 'Others']
data=[0.1, 1.45, 0.3, 0.1, 0.05] #可以不是百分比，直接放原始数据，自动计算百分比

# plt.pie(data, labels=labels) #没有显示百分比
plt.pie(data, labels=labels, autopct="%1.1f%%") #加2个百分号就能正常显示百分号了
plt.show()


========================================
|-- matplotlib 散点图和箱线图
----------------------------------------
1. 散点图 方便观察二维数据之间的关系

#######
# 散点图
import matplotlib.pyplot as plt

data=[[64,181], [50,120], [70,150], [55,100]]

weight=[item[0] for item in data]
height=[item[1] for item in data]
print(weight,height)

plt.scatter(weight, height)


(2)添加坐标轴文字

# 添加坐标轴标签
plt.xlabel('Weight(kg)')
plt.ylabel('Height(cm)')

plt.title('Scatter')

#在固定的位置插入文字
plt.text(60,140, 'low | high')


(3)箱线图 又叫盒子图 plt.boxplot(X)





========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------

