NGS statistics 统计学和统计学参数

统计学尽量不写，因为太多参数
paper中常见的统计学，还是要硬啃的。


本文记录paper中遇到的统计学。
还有一个R和数理统计学: R/R03-statistics.txt 




========================================
权威统计学资料
----------------------------------------
《Introduction to Statistics With Python》 https://github.com/thomas-haslwanter/statsintro_python

有很多统计学和基本R使用案例: http://www.instantr.com/

R与统计学(卡方检验等)： http://www.sthda.com/english/wiki/r-basic-statistics


多组的比较 kruskal-wallis http://www.sthda.com/english/wiki/kruskal-wallis-test-in-r






========================================
ROC曲线的意义
----------------------------------------
ROC曲线的意义
http://www.cnblogs.com/emanlee/archive/2011/05/29/2062280.html

　　ROC曲线指受试者工作特征曲线(receiver operating characteristic curve), 是反映敏感性和特异性连续变量的综合指标,是用构图法揭示敏感性和特异性的相互关系，它通过将连续变量设定出多个不同的临界值，从而计算出一系列敏感性和特异性，再以敏感性为纵坐标、（1-特异性）为横坐标绘制成曲线，曲线下面积越大，诊断准确性越高。在ROC曲线上，最靠近坐标图左上方的点为敏感性和特异性均较高的临界值. 　　
SPSS统计软件包的10.0版本有ROC曲线的统计功能。ROC曲线真阳性率为纵坐标,假阳性率为横坐标,在座标上由无数个临界值求出的无数对真阳性率和假阳性率作图构成,计算ROC曲线下面积AUCROC来评价诊断效率。



========================================
什么是SSLP和ISSR？
----------------------------------------
什么是SSLP和ISSR？
http://www.cnblogs.com/emanlee/archive/2011/05/29/2062282.html

简单序列长度多态性（simple sequence length polymorphism，SSLP）是据串联重复排列微卫星基序两侧的单一序列设计引物，对微卫星序列（microsatellite DNA或simple sequence repeats，SSR）进行扩增，由微卫星基序重复数目的变异而产生多态性。由于基因组中某一特定的微卫星的侧翼序列通常都是保守性较强的单一序列，因而可以将微卫星侧翼的DNA片段克隆、测序，然后根据微卫星的侧翼序列就可以人工合成引物进行PCR扩增，从而将单个微卫星位点扩增出来。由于单个微卫星位点重复单元在数量上的变异，个体的扩增产物在长度上的变化就产生长度的多态性，这一多态性称为SSLP，每一扩增位点就代表了这一位点的一对等位基因。 SSLP是一些长度不等的重复序列、有多个等位基因位点，它们多为2-4个核苷酸序列重复（也叫微卫星标记），在不同动植物品系中其重复次数不同，故可用 PCR法来检测各该多态性序列的长度，从而快速测定出多种回交后代中标记物的分离方式。
由于微卫星标记在基因组中广泛分布，等位性变异丰富，检测手段简便，稳定可靠而受重视，但是微卫星标记要求已知微卫星两侧单一序列信息而使其发展受到限制，同时微卫星标记具有严格的种属特异性也使其应用上受到限制。

http://liu3305602.blog.163.com/blog/static/148546532007214112732384/


========================================
LOD值 LOD score
----------------------------------------
http://www.cnblogs.com/emanlee/archive/2011/05/29/2062286.html

LOD值 LOD score　　

定义：

确定两个基因座是否在染色体上距离很近，因此可能一起遗传的统计学评估。三个或更多的LOD评价通常显示了两个基因座的位置很紧密。　　      

详解：

遗传学上通常用或然率的常用对数作为标准的衡量方法，该值的对数值称为Lod值或对数优势比：根据两个非此即彼的假设，计算数据的整体或然性，以确定两个基因座或是按一定的重组率而相互连锁的可能性或是互不连锁的可能性；这两种可能性之比，是基因座实际上为连锁的可能性；这个比率的10作底的对数就是对数优势比。为了确定两对基因之间是否存在连锁，一般要求或然比大于1000：1，即Lod>3；而要否定连锁存在，则要求或然小于100：1，即Lod<2。　　                

通常判定连锁关系是以Lod值大小为依据。Lod值为0，意味着连锁假设与不连锁假设的可能性相等；Lod值为正值，有利于连锁；Lod值为负值，表示有一定重组率的连锁。显著的域值是＋3和－2。Lod＝＋3时，连锁的概率为95％。

当Lod>1时,表示存在连锁;
Lod>3时,表示肯定连锁;
Lod<-2时,表示否定连锁.

http://www.ag.ndsu.nodak.edu/plantsci/adv_genetics/genetics/lod/lod02.htm
http://www.nature.com/scitable/definition/lod-score-logarithm-of-odds-152





========================================
生物学上描述DNA/RNA的长度常用的kb、nt、bp是指什么
----------------------------------------
kb=千碱基 kilobase

nt＝核苷酸 nucleotide

bp＝碱基对 base pair


========================================
Gene Ontology （GO）简介 GO分析
----------------------------------------
http://www.cnblogs.com/emanlee/archive/2011/08/02/2125314.html


为了查找某个研究领域的相关信息，生物学家往往要花费大量的时间，更糟糕的是，不同的生物学数据库可能会使用不同的术语，好比是一些方言一样，这让信息查找更加麻烦，尤其是使得机器查找无章可循。Gene Ontology就是为了解决这种问题而发起的一个项目。

     Gene Ontology中最基本的概念是term。GO里面的每一个entry都有一个唯一的数字标记，形如GO:nnnnnnn，还有一个term名，比如"cell", "fibroblast growth factor receptor binding"，或者"signal transduction"。每个term都属于一个ontology，总共有三个ontology，它们分别是molecular function（分子功能）, cellular component（细胞组分）和biological process（生物过程）。

     一个基因product可能会出现在不止一个cellular component里面，也可能会在很多biological process里面起作用，并且在其中发挥不同的molecular function。比如，基因product "cytochrome c" 用molecular function term描述是"oxidoreductase activity"，而用biological process term描述就是"oxidative phosphorylation"和"induction of cell death"，最后，它的celluar component term是"mitochondrial matrix"和"mitochondrial inner membrane"。

     Ontology中的term有两种相互关系，它们分别是is_a关系和part_of关系。is_a关系是一种简单的包含关系，比如A is_a B表示A是B的一个子集/子类。比如nuclear chromosome is_a chromosome。part_of关系要稍微复杂一点，C part_of_D意味着如果C出现，那么它就肯定是D的一部分/组成成分，但C不一定总会出现。比如nucleus part_of cell，核肯定是细胞的一部分，但有的细胞没有核。

     Ontology的结构是一个有向无环图，有点类似于分类树，不同点在于 Ontology的结构中一个term可以有不止一个parent。比如 biological process term "hexose biosynthesis" 有两个parents，它们分别是"hexose metabolism"和"monosaccharide biosynthesis"，这是因为生物合成是代谢的一种，而己糖又是单糖的一种。

 

Gene Ontology （GO）简介

     Gene Ontology（GO）包含了基因参与的生物过程，所处的细胞位置，发挥的分子功能三方面功能信息，并将概念粗细不同的功能概念组织成DAG（有向无环图）的结构。Gene Ontology是一个使用有控制的词汇表和严格定义的概念关系，以有向无环图的形式统一表示各物种的基因功能分类体系，从而较全面地概括了基因的功能信息，纠正了传统功能分类体系中常见的维度混淆问题。在基因表达谱分析中，GO常用于提供基因功能分类标签和基因功能研究的背景知识。利用GO的知识体系和结构特点，旨在发掘与基因差异表达现象关联的单个特征基因功能类或多个特征功能类的组合。

    根据GO的知识体系，使用“功能类”（或者叫做“功能模块”）这一概念具有以下优点：我们认为，单个基因的表达情况的改变不足以反映特定功能/通路的整体变化情况。因为类似人类社会的组织结构，生物体的功能的实现决不仅仅是依靠一两个基因功能的改变来实现的。因此过分着重单个基因表达变化，将会在后期结果处理中严重干扰对于结果的合理分析，导致偏倚性加大，而且是无法避免的。因此利用GO的结构体系，把参与同样功能/通路的基因进行“功能类”层面的抽象和整合，提供比基因更高一层次的抽象结论，对理解疾病的发病机制或药物的作用机理等更有帮助。

    但是该方法也存在一定的不足，由于生物体内部的调控网络可能具有“scale-free network”的特点，个别功能重要的基因（主效基因）具有“Hub节点”的重要特性，它的功能改变可能对于整个网络来说是至关重要的，在这点上，这些重要的基因又具有一定的“自私独裁”特点。而“功能类”之观点模糊了这种差别特性，过于强调“共性”，而忽视了“个性”，这也是“功能类”的一个不足之处，这就需要结合相关的生物学知识才能够实现.

 

基因本体
Gene Ontology

     基因本体（Gene Ontology，GO）是一个在生物信息学领域中广泛使用的本体。它主要包括三个分支: 生物过程、分子功能和细胞组件。

     基因本体是一个有向无环图（DAG）型的本体。目前，GO中使用了is_a和part_of两种关系。

     Ontology: 哲学中称为本体论/存在论，这里本质是指一系列特定的文字可用来形容一些特定的模式、元件或角色，因此在国外的华人生物信息学家中试译为语义(学)。

     GO（gene ontology）对大家而言也许会是一个相对陌生的名词，但是它已经成为生物信息领域中一个极为重要的方法和工具，并正在逐步改变着我们对 biological data的组织和理解方式，它的存在已经大大加快了我们对所拥有的生物数据的整合和利用，我们应该逐步学会理解和掌握这种思想和工具。

     众所周知，sequence based biology中的核心内容即是对序列的Annotation（注释），其中主要包含structural annotation和functional annotation，前者涉及分析sequence在genome中的locus以及exon，intron，promoter等的location，而后者则是推断序列编码产物的功能，也正是我们在六月论题中所着重探讨的。应该说，这二者是相互关联的。

     随着多种生物genome的相继解码，同时大量ESTs以及gene expression profile date的积累，使得annotation的工作量和复杂度大大增加。然而另一方面，大多数基因在不同真核生物中拥有共同的主要生物功能，通过在某些物种中获得的基因或者蛋白质（shared protein）的生物学信息，可以用以解释其他物种中对应的基因或蛋白（especially in comparative genomics）。由于这些繁复的功能信息主要是包含在积累的文献之中，如何有效的提取和综合这些信息就是我们面临的核心困难，这也是GO所要着力解决的问题。通过建立一套具有动态形式的控制字集（controlled vocabulary），来解释真核基因及蛋白在细胞内所扮演的角色，并随着生命科学研究的进步，不断积累和更新。一个ontology会被一个控制字集来描述并给予一定的名称，通过制定“本体”ontologies并运用统计学方法及自然语言处理技术，可以实现知识管理的专家系统控制。

     到目前为止，Gene Ontology Consortium（GO的发起组织）的数据库中有3大独立的ontology被建立起来：biological process生物过程, molecular function分子功能及cellular component细胞组分。而这三个ontology下面又可以独立出不同的亚层次，层层向下构成一个ontologies的树型分支结构。可以说， GO是生物学的统一化工具。

GO的目的：类似于语义网络。是为了生物界有一个统一的数据交流语言。

     因为在生物学界，存在在种种同名异义、异议同名的现象。为此产生了GO项目。 
     概要：GO是用一套统一的词汇表来描述生物学中的分子功能、生物过程和细胞成分。

     其思想大概过程：对于一个基因产品（蛋白质或RNA），用某些词汇来描述它是干什么的或位于细胞哪里、或者参与了哪个生物过程，而这些词汇就是来自GO的Term。

     Term是GO里面的基本描述单元。它结构如下：

Accession：
GO:0005515
Ontology：
molecular function
Synonyms：
related: alpha-2 macroglobulin receptor-associated protein activity
related: protein degradation tagging activity
related: protein tagging activity
exact: protein amino acid binding
alt_id: GO:0045308
Definition：
Interacting selectively with any protein or protein complex (a complex of two or more proteins that may include other nonprotein molecules). [source: GOC:go_curators]
Comment：
None
Subset：
gene_ontology.obo 示例：

[Term]
id: GO:0000003
name: reproduction
namespace: biological_process
alt_id: GO:0019952
alt_id: GO:0050876
def: "The production by an organism of new individuals that contain some portion of their genetic material inherited from that organism." [GOC:go_curators, GOC:isa_complete, ISBN:0198506732]
subset: goslim_generic
subset: goslim_pir
subset: goslim_plant
subset: gosubset_prok
exact_synonym: "reproductive physiological process" []
xref_analog: Wikipedia:Reproduction
is_a: GO:0008150 ! biological_process

 

     说白了，GO就是为了对gene和gene product进行统一注释说明而成了的一个标准。这些注释说明来自称为“Ontology”的一套词汇。


GO(Gene Ontology) 
     介绍：GO 是用一套具有动态(dynamic)形式的控制字汇(controlled vocabulary)，来解释真核生物的基因或蛋白质在细胞内所扮演的角色及生医学方面的知识，同时这些字汇随着生命科学研究的进步，一直不断的累积与改变。一个本体（ontology）会被一个控制字汇(controlled vocabulary)来描述并给予统一的名称，到目前为止，在 Gene Ontology 下有三大独立的本体被建立∶biological process,molecular function 及 cellular component。一个基因或蛋白质可从三个层面进行注解，首先是构成在细胞内的特定组件(cellular 过程(biologicalprocess)，因此科学家试着收集各真核生物(如SGD,MGI,FlyBase,..)的基因或蛋白质，利用已知 component)，其次是此组件在分子功能上所扮演的角色(molecular function)，最后是基因或蛋白质参与的生物的文献资料及序列比较资讯为基础，将所有的真核生物的基因或蛋白质都基于在此系统(Gene ontology)下作注解(annotation)与分类(classification)。 
网址：http://www.geneontology.org/ or http://www.ebi.ac.uk/GO/index.html 
软件：interproscan


Understanding relations in GO
http://www.cnblogs.com/emanlee/archive/2012/04/13/2446147.html






========================================
如何看懂NCBI BLAST输出结果
----------------------------------------
http://www.cnblogs.com/emanlee/archive/2011/11/11/2245397.html

解读报告前需要掌握的概念
alignments 代表比对上的两个序列

hits 表示两个序列比对上的片段

Score 比对得分，如果序列匹配上得分，不一样，减分，分值越高，两个序列相似性越高 
E Value 值越小，越可信，相对的一个统计值。 
Length 输入序列的长度 
Identities 一致性，就是两个序列有多少是一样的 
Query 代表输入序列 
Sbjct 代表数据库中的序列


from: http://blog.163.com/henry_by/blog/static/572653582010101343853958/




========================================
|-- blast+
----------------------------------------
download:
	ftp://ftp.ncbi.nih.gov/blast/executables/blast+/
	ftp://ftp.ncbi.nih.gov/blast/executables/release/2.2.18
	ftp://ftp.ncbi.nih.gov/blast/executables/blast+/2.5.0/


blast formatdb 使用方法介绍
http://www.cnblogs.com/emanlee/archive/2011/11/18/2254604.html


megablast 采用贪婪式算法，速度较一般blast快，多用于数据量大且序列相似性较高的情况。
http://www.cnblogs.com/emanlee/archive/2011/11/19/2254863.html



========================================
k-means k均值聚类的弱点/缺点
----------------------------------------
http://www.cnblogs.com/emanlee/archive/2012/03/06/2381617.html

Similar to other algorithm, K-mean clustering has many weaknesses:

1 When the numbers of data are not so many, initial grouping will determine the cluster significantly.  当数据数量不是足够大时，初始化分组很大程度上决定了聚类，影响聚类结果。 
2 The number of cluster, K, must be determined before hand.  要事先指定K的值。 
3 We never know the real cluster, using the same data, if it is inputted in a different order may produce different cluster if the number of data is a few. 数据数量不多时，输入的数据的顺序不同会导致结果不同。 
4 Sensitive to initial condition. Different initial condition may produce different result of cluster. The algorithm may be trapped in the local optimum. 对初始化条件敏感。 
5 We never know which attribute contributes more to the grouping process since we assume that each attribute has the same weight. 无法确定哪个属性对聚类的贡献更大。 
6 weakness of arithmetic mean is not robust to outliers. Very far data from the centroid may pull the centroid away from the real one. 使用算术平均值对outlier不鲁棒。 
7 The result is circular cluster shape because based on distance.  因为基于距离，故结果是圆形的聚类形状。

 

One way to overcome those weaknesses is to use K-mean clustering only if there are available many data. To overcome outliers problem, we can use median instead of mean.  克服缺点的方法： 使用尽量多的数据；使用中位数代替均值来克服outlier的问题。

Some people pointed out that K means clustering cannot be used for other type of data rather than quantitative data. This is not true! See how you can use multivariate data up to n dimensions (even mixed data type) here. The key to use other type of dissimilarity is in the distance matrix.

 

http://people.revoledu.com/kardi/tutorial/kMean/Weakness.htm







========================================
----------------------------------------




========================================
负二项分布
----------------------------------------
负二项分布(Negative binomial distribution)。在实际生活中，我们可以使用负二项分布描述某种机器在坏掉前，能够工作的天数的分布；某运动员在获取r个奖牌前失败次数的分布等等。


1. 定义
负二项分布也基于伯努利试验，其定义有下面两种形式：

在一系列伯努利试验中，失败次数到达指定次数时，成功次数的离散概率分布
在一系列伯努利试验中，成功次数到达指定次数（记为r）时，失败次数（记为k）的离散概率分布

这两种定义只是将“成功”和“失败”对调，其本质上没差别。由于R中相关函数都采用第二种形式，因此下面将以第二种形式为例。







refer:
https://www.jianshu.com/p/ad24bb90b972
负 字从何而来？ https://www.zhihu.com/question/24253978
R统计学(06): 负二项分布 https://www.jianshu.com/p/d60252dfb8ec
英文公开课:http://open.163.com/movie/2017/5/5/6/MCJQECVBF_MCL7VIT56.html 






========================================
多重假设检验：Bonferroni 和 FDR
----------------------------------------
1.概念
FDR，Q value，adjust p value
p-value：衡量一次检验假阳性率的指标（False positive rate） ；
q value：衡量错误发现率的指标（False discovery rate，简称FDR，所有检验中假阳性的概率）。即使用Q value的这个参 数预估FDR。Q value 需要利用公式从p value 校正计算后得到，所以Q value 通常又被称为adjusted p value。所以一般情况下：我们可以认为Q value = FDR = adjusted p value，即三者是一个东西，虽然有些定义上的细微区别，但是问题也不大。


2.矫正
如要使用的校正办法有两种：Bonferroni 校正；FDR（FalseDiscovery Rate） 校正
(1).Bonferroni 校正
Bonferroni 校正法可以称作是“最简单粗暴有效”的校正方法，它拒绝了所有的假阳性结果发生的可能性，通过对p值的阈值进行校正来实现消除假阳性结果。

Bonferroni 校正的公式为p*(1/n)，其中p为原始阈值，n为总检验次数。

如果像我们举的例子一样，原始的P值为0.05，检验次数为10000次，那么在Bonferroni 校正中，校正的阈值就等于5%/ 10000 = 0.000005，所有P值超过0.00005的结果都被认为是不可靠的。这样的话假阳性结果在10000次检验中出现的次数为 10000 * 0.000005 =0.5，还不到1次。

但是这也存在问题：Bonferroni 委实太过严格，被校正后的阈值拒绝的不只有假阳性结果，很多阳性结果也会被它拒绝。



(2).FDR（FalseDiscovery Rate） 校正
相对Bonferroni 来说，FDR温和得多，这种校正方法不追求完全没有假阳性结果，而是将假阳性结果和真阳性的比例控制在一定范围内。

举个例子，我们最开始设定的情况中进行了10000次检验，这次我们设定FDR<0.05，如果我们的检验对象为差异表达的基因，那么在10000次检验中假如得到了500个基因，那么这500个基因中的假阳性结果小于 500*5% = 25 个。

FDR的计算方法有很多种，这里介绍一个比较常用的：


1)BH（Benjaminiand Hochberg）法：
BH 法需要将总计m次检验的结果按由小到大进行排序，k为其中一次检验结果的P值所对应的排名。
找到符合原始阈值α的最大的k值，满足P(k)<=α*k/m，认为排名从1到k的所有检验存在显著差异，并计算对应的q值公式为q = p*(m/k)。
举个例子，如果我们有总共六个结果进行FDR校正：

Gene	p-value 
G1	P1=0.053
G2	P2=0.001
G3	P3=0.045
G4	P4=0.03
G5	P5=0.02
G6	P6=0.01

Order:
G2	P2=0.001
G6	P6=0.01
G5	P5=0.02
G4	P4=0.03
G3	P3=0.045
G1	P1=0.053

按α=0.05进行计算：
排名第四的 P (4) = 0.03 < 0.05*4/6 = 0.033，符合要求
排名第五的 P (5)= 0.045 > 0.05*5/6 = 0.041，不满足P(k)<=α*k/m. 
因此在这个列表里排名前四的G2,G6,G5,G4 为具有显著差异的基因。


我们也可以用q值进行FDR校正：
G2	P2=0.001	q2=0.001*6/1=0.006
G6	P6=0.01	q6=0.01*6/2=0.03
G5	P5=0.02	q5=0.02*6/3=0.04
G4	P4=0.03	q4=0.03*6/4=0.045
G3	P3=0.045	q3=0.045*6/5=0.054
G1	P1=0.053	q1=0.053*6/6=0.053
其中，G3的q值大于0.05，故G2,G6,G5,G4 为具有显著差异的基因。



refer: https://www.jianshu.com/p/949626b18e69



========================================
Benjamini correction == FDR == adjusted p-value
----------------------------------------
https://www.biostars.org/p/293613/

Benjamini correction is your false discovery rate and it is your adjusted p-value. So you should forget about your p-value after correction. So your test is significant if your adjusted p-value is smaller than criteria (such as 0.05 or 0.01). If you want to more about multiple testing, you can check here





========================================
方差分析(analysis of variance, 简写为ANOVA)
----------------------------------------
方差分析(analysis of variance, 简写为ANOVA)是工农业生产和科学研究中分析试验数据的一种有效的统计方法. 引起观测值不同(波动)的原因主要有两类: 一类是试验过程中随机因素的干扰或观测误差所引起不可控制的的波动, 另一类则是由于试验中处理方式不同或试验条件不同引起的可以控制的波动.

方差分析的主要工作就是将观测数据的总变异(波动)按照变异的原因的不同分解为因子效应与试验误差，并对其作出数量分析，发现多组数据之间的差异显著性，比较各种原因在总变异中所占的重要程度，以此作为进一步统计推断的依据.

在进行方差分析之前先对几条假设进行检验，由于随机抽取，假设总体满足独立、正态，考察方差齐次性（用bartlett检验）.


1.正态性检验
在进行方差分析前先对输入数据做正态性检验。
对数据的正态性，利用Shapiro-Wilk正态检验方法(W检验)，它通常用于样本容量n≤50时，检验样本是否符合正态分布。

R中，函数shapiro.test()提供了W统计量和相应P值，所以可以直接使用P值作为判断标准(P值大于0.05说明数据正态)，其调用格式为shapiro.test(x)，参数x即所要检验的数据集，它是长度在3到5000之间的向量。

(1)
nx <- c(rnorm(10));nx
#[1] -0.83241783 -0.29609562 -0.06736888 -0.02366562 0.23652392 0.97570959
#[7] -0.85301145 1.51769488 -0.84866517 0.20691119
shapiro.test(nx)
#Shapiro-Wilk normality test
#data: nx
#W = 0.9084, p-value = 0.2699

检验结果，因为p 值小于W 值，所以数据为正态分布.

(2)更多正态性检验见：R语言做正态分布检验 https://www.cnblogs.com/blueicely/archive/2013/01/08/2850929.html
其中，D检验(Kolmogorov - Smirnov)是比较精确的正态检验法。

SPSS 规定:当样本含量3 ≤n ≤5000 时,结果以Shapiro - Wilk (W 检验) 为准,当样本含量n > 5000 结果以Kolmogorov - Smirnov 为准。
SAS 规定:当样本含量n ≤2000 时,结果以Shapiro - Wilk (W 检验) 为准,当样本含量n >2000 时,结果以Kolmogorov - Smirnov (D 检验) 为准。





2. 方差齐性检验
方差分析的另一个假设：方差齐性，需要检验不同水平下的数据方差是否相等。R中最常用的是Bartlett检验,bartlett.test()调用格式为
bartlett.test(x，g…)
其中，参数X是数据向量或列表(list) ; g是因子向量，如果X是列表则忽略g.当使用数据集时，也通过formula调用函数:
bartlett.test(formala, data, subset，na.action…)
formula是形如lhs一rhs的方差分析公式;data指明数据集:subset是可选项，可以用来指定观测值的一个子集用于分析:na.action表示遇到缺失值时应当采取的行为。

> x=c(x1,x2,x3)
> account=data.frame(x,A=factor(rep(1:3,each=7)))
> bartlett.test(x~A,data=account)
# Bartlett test of homogeneity of variances
# data: x by A
# Bartlett's K-squared = 0.13625, df = 2, p-value = 0.9341
由于P值远远大于显著性水平a=0.05，因此不能拒绝原假设，我们认为不同水平下的数据是等方差的。





3. 方差分析：F-Test
In R the function var.test allows for the comparison of two variances using an F-test.Although it is possible to compare values of s2 for two samples, there is no capability within R for comparing the variance of a sample,s2,to the variance of a population, σ2. The syntax for the testing variances is :

var.test(X, Y, ratio = 1, alternative = "two.sided", conf.level = 0.95)


> std.method<-c( 21.62, 22.20, 24.27, 23.54, 24.25, 23.09, 21.01 )
> new.method<-c(21.54 ,20.51 ,22.31, 21.30, 24.62, 25.72, 21.54 ) 
> var(std.method); var(new.method) 
[1] 1.638495
[1] 3.690329
> var.test(std.method, new.method)    

	F test to compare two variances

data:  std.method and new.method
F = 0.444, num df = 6, denom df = 6, p-value = 0.3462
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.07629135 2.58395513
sample estimates:
ratio of variances 
         0.4439971

#


1）判断组间是否有差别
R中的函数aov()用于方差分析的计算，其调用格式为:
aov(formula, data = NULL, projections =FALSE, qr = TRUE,contrasts = NULL, ...)

其中的参数formula表示方差分析的公式，在单因素方差分析中即为x~A ;
data表示做方差分析的数据框:projections为逻辑值，表示是否返回预测结果;
qr同样是逻辑值，表示是否返回QR分解结果，默认为TRUE;
contrasts是公式中的一些因子的对比列表;
通过函数summary()可列出方差分析表的详细结果。


以淀粉为原料生产葡萄的过程中, 残留许多糖蜜, 可作为生产酱色的原料. 在生产酱色的过程之前应尽可能彻彻底底除杂, 以保证酱色质量.为此对除杂方法进行选择. 在实验中选用5种不同的除杂方法, 每种方法做4次试验, 即重复4次, 结果见表.
除杂方法 / 除杂量X
A1/ 25.6 22.2 28 29.8
A2/ 24.4 30.0 29.0 27.5
...


> X<-c(25.6, 22.2, 28.0, 29.8, 24.4, 30.0, 29.0, 27.5, 25.0, 27.7,
       23.0, 32.2, 28.8, 28.0, 31.5, 25.9, 20.6, 21.2, 22.0, 21.2)
> A<-factor(rep(1:5, each=4))
> miscellany<-data.frame(X, A)
> miscellany
     X A
1  25.6 1
2  22.2 1
3  28.0 1
4  29.8 1
5  24.4 2
6  30.0 2
...
> aov.mis<-aov(X~A, data=miscellany)
> aov.mis
# Call:
#    aov(formula = X ~ A, data = miscellany)
# 
# Terms:
#                       A Residuals
# Sum of Squares  131.957   114.915
# Deg. of Freedom       4        15
# 
# Residual standard error: 2.767851
# Estimated effects may be unbalanced

> summary(aov.mis)
            Df Sum Sq Mean Sq F value Pr(>F)  
A            4  132.0   32.99   4.306 0.0162 *
Residuals   15  114.9    7.66                 
---
Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

代码解释
上述结果中, Df表示自由度; sum Sq表示平方和; Mean Sq表示均方和;
F value表示F检验统计量的值, 即F比; Pr(>F)表示检验的p值; A就是因素A;
Residuals为残差.
可以看出, F = 4.3061 > F0.05(5-1, 20-5) = 3.06, 或者p=0.01618<0.05,
说明有理由拒绝原假设, 即认为五种除杂方法有显著差异.



2）如果有差别，判断是哪两组间有差别
其中，上述所得结果为5个除杂方法之间的差异显著性分析，如果假设上述5中处理中A1为对照组，其余A2,A3,A4,A5均为处理组，现在若想分析一个对照和多个处理间的差异显著性，可以通过以下代码实现：

> A1A2<-miscellany[1:8,]
> A1A2
     X A
1 25.6 1
2 22.2 1
...
> an.aov.mis<-aov(X~A, data=A1A2)
> summary(an.aov.mis)
            Df Sum Sq Mean Sq F value Pr(>F)
A            1   3.51   3.511   0.419  0.542
Residuals    6  50.31   8.385


即选取对照为一组数据，处理为另一组，缺点是对于多个处理一个对照需要重复此操作，现在还没找到好的处理办法，希望以后能学到或者有谁知道望相告。
最近总结出的另一个比较有效的办法：
接上aov()的F检验通过summary(aov.mis)看出五种除杂方法有显著差异.接下来考察具体的差异（多重比较）通过 TukeyHSD()函数：

> TukeyHSD(aov.mis)
##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = X ~ A, data = miscellany)
## 
## $A
##       diff        lwr        upr     p adj
## 2-1  1.325  -4.718582  7.3685818 0.9584566
## 3-1  0.575  -5.468582  6.6185818 0.9981815
## 4-1  2.150  -3.893582  8.1935818 0.8046644
## 5-1 -5.150 -11.193582  0.8935818 0.1140537
## 3-2 -0.750  -6.793582  5.2935818 0.9949181
## 4-2  0.825  -5.218582  6.8685818 0.9926905
## 5-2 -6.475 -12.518582 -0.4314182 0.0330240
## 4-3  1.575  -4.468582  7.6185818 0.9251337
## 5-3 -5.725 -11.768582  0.3185818 0.0675152
## 5-4 -7.300 -13.343582 -1.2564182 0.0146983
#TukeyHSD图
> plot(TukeyHSD(aov.mis))

注意：可以看出上述结果是所有分组间的两两比较，但经常我们所需要的仅仅是一个对照组和其他几个处理组间的比较，这时multcomp包是不错的选择；


a = c(56,60,44,53)
b = c(29,38,18,35)
c = c(11,25,7,18)
d = c(26,44,20,32)
strains.frame = data.frame(a, b, c, d)
strains = stack(strains.frame)  #stack是reshape2包中的一个函数，用于将宽格式数据转化为长格式；
colnames(strains) = c("weight", "group")
##常规的两两相互比较计算
TukeyHSD( aov(weight ~ group, data=strains) )
library(multcomp)
summary(glht(aov(weight ~ group, data=strains), linfct=mcp(group="Dunnett")))
## The first group ("a" in this example) is used as the reference group. 
## If this is not the case, use the relevel() command to set the reference.
strains$group = relevel(strains$group, "b")
str(strains)
head(strains)
summary(glht(aov(weight ~ group, data=strains), linfct=mcp(group="Dunnett")))
plot(glht(aov(weight ~ group, data=strains), linfct=mcp(group="Dunnett")))


More: http://barcwiki.wi.mit.edu/wiki/SOPs/anova

multcomp包部分参数解释：
glht：General Linear Hypotheses，General linear hypotheses and multiple comparisons for parametric models, including generalized linear models, linear mixed effects models, and survival models.
linfct：a specification of the linear hypotheses to be tested，即指定之前的线性model将用于何种检验。
mcp (Multiple comparisons)：多重比较的意思，For each factor, which is included in model as independent variable, a contrast matrix or a symbolic description of the contrasts can be specified as arguments to mcp，其参数意思为Tukey’s all-pair comparisons or Dunnett’s comparison with a control.


> person <- rep(c(1:10),2)
> treat <- c("A","B","A","A","B","B","A","B","A","B","B","A","B","B","A","A","B","A","B","A")
> phase <- rep(c(1,2),each=10)
> x <- c(760,860,568,780,960,940,635,440,528,800,770,855,602,800,958,952,650,450,530,803)
> data46 <- data.frame(person,treat,phase,x)
> data46$person<-factor(data46$person)
> data46
   person treat phase   x
1       1     A     1 760
2       2     B     1 860
...
> result<-aov(x~phase+person+treat,data=data46)
> summary(result)
            Df Sum Sq Mean Sq  F value   Pr(>F)    
phase        1    490     490    9.925   0.0136 *  
person       9 551111   61235 1240.195 1.32e-11 ***
treat        1    198     198    4.019   0.0799 .  
Residuals    8    395      49                      
---
Signif. codes:  0 ?**?0.001 ?*?0.01 ??0.05 ??0.1 ??1

观察p adj值发现两两二者间的方差显著性.

据上述结果可以填写下面的方差分析表:
方差来源  |自由度 /平方和 /均方和 /F比 /p值
因素A     |4  /131.95 /32.989 /4.3061 /0.01618
误差      |15 /114.915 /7.661
总和      |19 /246.872

再通过函数plot( )绘图可直观描述5种不同除杂方法之间的差异, R中运行命令
> plot(miscellany$X~miscellany$A)

从图形上也可以看出, 5种除杂方法产生的除杂量有显著差异, 特别第5种与前面的4种, 而方法1与3, 方法2与4的差异不明显。



ref:
http://www.360doc.com/content/18/0731/12/46931810_774642090.shtml










========================================
非参数检验: Mann-whitney U test(== Wilcoxon rank sum test)， 及R/Python代码
----------------------------------------
1.对分组变量的差异显著性检验是微生物生态数据分析中常见的内容。

T-test是最为常用的检验方法，但t-test要求数据符合正态分布，在不符合正态分布的时候检验准确性要大打折扣。检验数据是否符合正态分布的方法可见往期推文“看SPSS如何检验数据是否服从正态分布”。如果被检数据不符合正态分布怎么办呢？

Wilcoxon test无需数据服从正态分布，适合在数据总体方差未知或知道甚少的情况下使用。
相应的缺点是，在数据符合正态分布的情况下，检验的准确性要比t-test低。下面介绍如何在R中实现Wilcoxon test。


曼-惠特尼U检验又称“曼-惠特尼秩和检验”，是由H.B.Mann和D.R.Whitney于1947年提出的。
它假设两个样本分别来自除了总体均值以外完全相同的两个总体，目的是检验这两个总体的均值是否有显著的差别。

Mann-Whitney U 检验是用得最广泛的两独立样本秩和检验方法。简单的说，该检验是与独立样本t检验相对应的方法，当正态分布、方差齐性等不能达到t检验的要求时，可以使用该检验。
其假设基础是：若两个样本有差异，则他们的中心位置将不同。


wilcoxon秩和及wilcoxon符号秩检验是对原假设的非参数检验，在不需要假设两个样本空间都为正态分布的情况下，测试它们的分布是否完全相同。






2.利用R进行Mann-Whitney U test检验(wilcox_test)：
Wilcoxon test使用方法和t-test类似，在R中输入‘?wilcox.test()’即可查看使用方法。如下：
Description: Performs one- and two-sample Wilcoxon tests on vectors of data; the latter is also known as ‘Mann-Whitney’ test.

Usage:wilcox.test(x, ...)

(1)## Default S3 method:
wilcox.test(x, y = NULL,
            alternative = c("two.sided", "less", "greater"),
            mu = 0, paired = FALSE, exact = NULL, correct = TRUE,
            conf.int = FALSE, conf.level = 0.95, ...)
#
非配对数据，样本个数不一定一样，比较均值大小。在R中执行wilcox.test(x, y, alternative ='two.sided')。
这里两处理的样品数目可以不等。我们不知道x和y谁大谁小，所以我们选择双尾检验（‘two.sided’）。如果要验证x是否显著大于y，可以选择‘greater’；验证x是否显著小于y，可以选择‘less’。
#
处理前后的配对数据，比较均值大小。则在R中执行wilcox.test(x, y, alternative ='two.sided',paired=T)。
这里各样品处理前后数据要一一对应，数目相等。同样地，用‘greater’或‘less’可以验证x是否显著大于或小于y。

(2)## S3 method for class 'formula'
wilcox.test(formula, data, subset, na.action, ...)



因为有公式，还是看原文好。
有书了尽量看书。
refer:
1.https://blog.csdn.net/qq_34734303/article/details/80296316
2.https://www.jianshu.com/p/8c0e7ce7a290








3.实例
>s1<-c(6,1,1,1,1,1)
>s2<-c(5,5,5,5,5,0)
>s<-c(s1,s2)
>type<-c(rep(1,6),rep(2,6))
>wd<-as.dataframe(cbind(s,as.factor(type)))
>wilcox_test(s~type,data=wd)
  Asymptotic Wilcoxon-Mann-Whitney test
data:data by type(1,2)
Z=-1.2086,p-value=0.2268
alternative hypothesis:true mu is not equal to 0

根据结果显示，p-value值大于0.05，认为支持零假设，两个样品无差异。





##### (1). 在R中利用wilcox.test函数进行曼-惠特尼U检验。
用来检验两组独立样品是否来自两组不同的样品。不要求样本数量必须相等。
曼-惠特尼U检验Mann–Whitney Test: 两个独立样本，均匀分布，非正太分布, 两组样本量必须大于20
t检验假设两个样本的数据集之间的差别符合正态分布（当两个样本集都符合正态分布时，t检验效果最佳）


例1
library(stats)
data("mtcars")
boxplot(mtcars$mpg~mtcars$am, ylab='mpg', names = c('automatic','manual'))
## 手动、自动挡mpg每英里耗油量。

#执行wilcoxon秩和检验验证自动档手动档数据分布是否一致
## wilcox.test(mtcars$mpg[mtcars$am==0],mtcars$mpg[mtcars$am==1])（与下面等价）
> wilcox.test(mpg ~ am, data=mtcars)
## 	Wilcoxon rank sum test with continuity correction
## data:  mpg by am
## W = 42, p-value = 0.001871
## alternative hypothesis: true location shift is not equal to 0

原假设为两种变速器的油耗完全相同，p-value小于0.05，拒绝原假设，意味着两种变速器的油耗有显著差异。



例2
## Formula interface.
boxplot(Ozone ~ Month, data = airquality)
wilcox.test(Ozone ~ Month, data = airquality, subset = Month %in% c(5, 8)) ## 看5月和8月是否有显著区别？
##
	Wilcoxon rank sum test with continuity correction
data:  Ozone by Month
W = 127.5, p-value = 0.0001208
alternative hypothesis: true location shift is not equal to 0
## p<0.05，决绝零假设，也就是两组有显著差别。







### (2) 威尔科克森符号秩检验实现(处理前后、配对数据)
配对样本，均匀分布，非正太分布: Wilcoxon signed-rank test。Wilcoxon Signed-Rank Test, 用来进行配对样品的非参数检验。

# 一个样本：使用药物前后病情指数，配对样本。
x <- c(1.83,  0.50,  1.62,  2.48, 1.68, 1.88, 1.55, 3.06, 1.30)
y <- c(0.878, 0.647, 0.598, 2.05, 1.06, 1.29, 1.06, 3.14, 1.29)
wilcox.test(x, y, paired = TRUE, alternative = "greater") #要指定单尾测试，我们将替代参数设置为greater。
wilcox.test(y - x, alternative = "less")    # The same.
wilcox.test(y - x, alternative = "less",
            exact = FALSE, correct = FALSE) # H&W large sample
# approximation
## Wilcoxon signed rank test
## data:  x and y
## V = 40, p-value = 0.01953
## alternative hypothesis: true location shift is greater than 0
p<0.05，拒绝零假设，因此治疗前后是有差异的。






4. Nonparametric Comparison of Two Groups:
Mann–Whitney Test
If the measurement values from two groups are not normally distributed we have to resort to a nonparametric test. 
The most common nonparametric test for the comparison of two independent groups is the Mann–Whitney(–Wilcoxon) test.
Watch out, because this test is sometimes also referred to as Wilcoxon rank-sum test. 
This is different from the Wilcoxon signed rank sum test! 
注意和Wilcoxon signed rank sum test不同！

The test-statistic for this test is commonly indicated with u:
u_statistic, pVal = stats.mannwhitneyu(group1, group2)

https://github.com/thomas-haslwanter/statsintro_python/tree/master/ISP/Code_Quantlets/08_TestsMeanValues/twoGroups








========================================
|-- Wilcoxon 检验之 rank-sum(秩和检验，独立样本) 与 signed-rank(符号秩检验，配对样本) 的区分
----------------------------------------
Wilcoxon rank-sum test（我翻译为秩和检验）和 Wilcoxon signed-rank test（我翻译为符号秩检验）。

Frank Wilcoxon (1892—1965) 是美国的统计学家，发表了 70 篇左右论文，但其最大的贡献就是这 2 个以他名字命名的非参假设检验方法：秩和检验 和 符号秩检验。
他在 1945 年发表的论文 1 中将二者分别称为 非成对检验 （unpaired experiment）和 成对检验（paired comparison）。 正是因为其巨大影响力使得这两个检验方法都以他的名字命名，并流传下来。


假设检验有点类似于我们高中数学中常见的“反证法”，即提出一个错误的假设，然后证明它是错的。那么我们提出的假设叫做 原假设 (Null Hypothesis)，简写为 H0，应为一般假设没有区别，也叫零假设，承认没有区别。
我们备选的假设叫做 备选假设 (Alternative Hypothesis)，简写为 Hα或H1。是零假设的否定，也就是有差别。
注意，在假设检验中只有 2 个假设，即原假设和备选假设，我们的目的就是要拒绝原假设。





1.Wilcoxon rank-sum test 定义如下，

In statistics, the Mann–Whitney U test (also called the Mann–Whitney–Wilcoxon (MWW), Wilcoxon rank-sum test, or Wilcoxon–Mann–Whitney test) is a nonparametric test.
This test can be used to determine whether two independent samples were selected from populations having the same distribution. 2

概念： 在统计学中，Wilcoxon rank-sum test（威尔科克森秩和检验）也叫 Mann-Whitney U test（曼-惠特尼 U 检验），或者 Wilcoxon-Mann-Whitney test。

秩和检验是一个非参的假设检验方法，一般用来检测 2 个数据集是否来自于相同分布的总体。特别地，秩和检验不要求 2 个数据集大小相同，也就是说进行秩和检验并不是两两成对比较，这一点区别于下面描述的符号秩检验。

例子:
x1=c(9,5,8,7,10,6,7) #n1=7个元素
x2=c(7,4,5,6,3,6,4,4) #n2=8个元素

step1: 排序，记下每个数的顺序
遇到相同的数字，则他们的rank取平均rank。
计算rank之和
R1=sum( c(14,5.5,13,11,15,8,11) )=77.5
R2=sum( c(11,3,5.5,8,1,8,3,3) )=42.5

step2:令T表示样本小的秩和，T=R1=77.5，根据公式计算：
U1=n1*n2 + n1*(n1+1)/2 -T=6.5
U2=n1*n2 -U1=49.5

step3: 由于U1更小，查Wilcoxon双尾临界表，当alpha=0.05，n1=7,n2=8的临界值是10.
由于U1=6.5<10，所以拒绝原假设。
结论：x1和x2存在显著性差异，他们来自不同的总体。


(1)Python中使用scipy包的stats.mannwhitneyu() 函数来实现秩和检验
from scipy import stats
def wilcoxon_rank_sum_test(x, y):
    res = stats.mannwhitneyu(x ,y)
    print(res)

x=[9,5,8,7,10,6,7]
y=[7,4,5,6,3,6,4,4]
wilcoxon_rank_sum_test(x,y)
## MannwhitneyuResult(statistic=6.5, pvalue=0.006966479792405637)
得到的统计量，就是我们的U1值。 
结论：p<0.05,拒绝零假设，有显著差异。



(2) R语言版本:
x=c(9,5,8,7,10,6,7)
y=c(7,4,5,6,3,6,4,4)
wilcox.test(x,y)
## 
# Wilcoxon rank sum test with continuity correction
# data:  x and y
# W = 49.5, p-value = 0.01393
#alternative hypothesis: true location shift is not equal to 0
#
## 怎么做连续性矫正？ //todo
#
wilcox.test(x,y, correct=F)
## Wilcoxon rank sum test
## data:  x and y
## W = 49.5, p-value = 0.01182
## alternative hypothesis: true location shift is not equal to 0









2. Wilcoxon 符号秩检验, 配对数据。最好20组数据以上。
根据 wikipedia 解释， Wilcoxon signed-rank test 定义如下，

A Wilcoxon signed-rank test is a nonparametric test that can be used to determine whether two dependent samples were selected from populations having the same distribution. 

概念： Wilcoxon signed-rank test（威尔科克森符号秩检验）也是一种非参的假设检验方法，它成对的检查 2 个数据集中的数据（即 paired difference test）来判断 2 个数据集是否来自相同分布的总体。

ID	y1  y2 sign abs rank
0	125	110	+1	15	7
1	115	122	-1	7	3
2	130	125	+1	5	1.5
3	140	120	+1	20	9
4	140	140	-	0	-
5	115	124	-1	9	4
6	140	123	+1	17	8
7	125	137	-1	12	6
8	140	135	+1	5	1.5
9	135	145	-1	10	5

step1: 配对数据求差，求绝对值abs，按照abs排序得到rank列。
对于abs=0的，舍弃，如ID=4的行。因为零假设的差异是0为中心的，观察值恰好是0不能提供决绝零假设的信息。过多，则降低统计功效。
对于abs相同的，取rank的平均值，如ID=2和8的行，(1+2)/2

step2: 根据sign列和rank列，分别计算大于0的秩和Wplus，和小于0的秩和Wminus。
Wplus=7+1.5+9+8+1.5=27
Wminus=3+4+6+5=18
## 感觉这个不准： 最终的秩 W=abs(Wplus - Wminus)=9
## 这个靠谱：在零假设下，W+和W-应差不多。因而，当其中之一很小时，应怀疑零假设。在此，取检验统计量W=min(W+,W-)=18


step3: 根据W，查表，alpha=0.05, n=9时的临界值是5，而我们计算出的W=9>5，因此不能拒绝原假设。//why?需要看概率分布图
结论：y1和 y2无显著性差异，他们来自于分布相同的总体。




(1)在 python 中我们调用 scipy 包来里的 stats.wilcoxon() 函数来实现秩和检验
from scipy import stats
def wilcoxon_signed_rank_test(y1, y2):
    res = stats.wilcoxon(y1, y2)
    print(res)
#
y1=[125, 115, 130, 140, 140, 115, 140, 125, 140, 135]
y2=[110, 122, 125, 120, 140, 124, 123, 137, 135, 145]
wilcoxon_signed_rank_test(y1,y2)
###
#  UserWarning: Warning: sample size too small for normal approximation.
#   warnings.warn("Warning: sample size too small for normal approximation.")
WilcoxonResult(statistic=18.0, pvalue=0.5936305914425295)

给出的统计量18就是min(Wplus, Wminus).
p=0.59>0.05, 无法拒绝原假设，也就是可能无差异。


如果p值较小(比如小于或等于给定的显著性水平，譬如0.05)则可以拒绝零假设。
如果p值较大则没有充分的证据来拒绝零假设，但不意味着接受零假设。


之所以出现 Warning 信息是因为我们的数据量太少，一般来讲大于 20 是比较合适做假设检验的。






(2)R 语言版本：
y1=c(125, 115, 130, 140, 140, 115, 140, 125, 140, 135)
y2=c(110, 122, 125, 120, 140, 124, 123, 137, 135, 145)
wilcox.test(y1, y2, paired = TRUE, alternative = "greater")
###
# Wilcoxon signed rank test with continuity correction
# data:  y1 and y2
# V = 27, p-value = 0.3176
# alternative hypothesis: true location shift is greater than 0
#
wilcox.test(y1 - y2, alternative = "greater", exact = F, correct = F) #不矫正





为什么R和手算、Python版本的P值都不一样呢？


refer
https://blog.csdn.net/chikily_yongfeng/article/details/82255575
Wikipedia. Wilcoxon rank-sum test. link: https://en.wikipedia.org/wiki/Mann-Whitney_U_test
Wikipedia. Wilcoxon signed-rank test. link: https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test
https://blog.csdn.net/weixin_34067980/article/details/85890225






========================================
|-- Kruskal-Wallis Test 单因素方差分析的非参版/ 两样本Wilcoxon检验的多样本版
----------------------------------------
Kruskal-Wallis Test in R
http://www.sthda.com/english/wiki/kruskal-wallis-test-in-r

Kruskal-Wallis test by rank is a non-parametric alternative to one-way ANOVA test, which extends the two-samples Wilcoxon test in the situation where there are more than two groups. It’s recommended when the assumptions of one-way ANOVA test are not met. This tutorial describes how to compute Kruskal-Wallis test in R software.

## Kruskal-Wallis rank sum test?



1. Kruskal-Wallis Test
http://www.r-tutor.com/elementary-statistics/non-parametric-methods/kruskal-wallis-test

A collection of data samples are independent if they come from unrelated populations and the samples do not affect each other. Using the Kruskal-Wallis Test, we can decide whether the population distributions are identical without assuming them to follow the normal distribution.

例子:
在名为 airquality 的内置数据集中，记录了纽约1973年5月至9月的每日空气质量测量数据。臭氧密度在数据框中 Ozone 列。
> head(airquality) 
  Ozone Solar.R Wind Temp Month Day 
1    41     190  7.4   67     5   1 
2    36     118  8.0   72     5   2 
    .....

Problem问题
Without assuming the data to have normal distribution, test at .05 significance level if the monthly ozone density in New York has identical data distributions from May to September 1973.
不用假设数据符合正态分布，检验每月抽样浓度分布是否在0.05显著性水平上一致？

Solution解答
The null hypothesis is that the monthly ozone density are identical populations. To test the hypothesis, we apply the kruskal.test function to compare the independent monthly data. The p-value turns out to be nearly zero (6.901e-06). Hence we reject the null hypothesis.
零假设：每月抽样浓度是相同的总体。
为了检验，使用 kruskal.test 函数，检验每月数据的独立性，p值很小接近于零。所以拒绝零假设。

> kruskal.test(Ozone ~ Month, data = airquality) 
#
#        Kruskal-Wallis rank sum test 
# 
#data:  Ozone by Month 
#Kruskal-Wallis chi-squared = 29.267, df = 4, p-value = 6.901e-06

Answer答案
At .05 significance level, we conclude that the monthly ozone density in New York from May to September 1973 are nonidentical populations.
每月的分布不是相同的。






2.Kruskal-Wallis Test
https://www.statisticssolutions.com/kruskal-wallis-test/

The Kruskal-Wallis test is a nonparametric (distribution free) test, and is used when the assumptions of one-way ANOVA are not met.  
非参数检验，适用于 one-way ANOVA 条件达不到的情形。

Both the Kruskal-Wallis test and one-way ANOVA assess for significant differences on a continuous dependent variable by a categorical independent variable (with two or more groups).  
Kruskal-Wallis test and 单因素方差分析用来评估在一个分类独立变量(2组或更多组)时，一个连续的因变量的显著差异，

In the ANOVA, we assume that the dependent variable is normally distributed and there is approximately equal variance on the scores across groups. However, when using the Kruskal-Wallis Test, we do not have to make any of these assumptions.  
ANOVA 假设因变量是正态分布的，组间变异程度近似。而Kruskal-Wallis检验不需要这些假设。

Therefore, the Kruskal-Wallis test can be used for both continuous and ordinal-level dependent variables.  However, like most non-parametric tests, the Kruskal-Wallis Test is not as powerful as the ANOVA.
所以，Kruskal-Wallis test 可以用于连续性或者排序型因变量。然而，和大多数非参数检验一样，效力比不上ANOVA。


Null hypothesis: Null hypothesis assumes that the samples (groups) are from identical populations.
零假设：每组样品都来自同一个总体。

Alternative hypothesis: Alternative hypothesis assumes that at least one of the samples (groups) comes from a different population than the others.


Example questions answered:
i)How do test scores differ between the different grade levels in elementary school?
ii)Do job satisfaction scores differ by race?

The distribution of the Kruskal-Wallis test statistic approximates a chi-square distribution, with k-1 degrees of freedom, if the number of observations in each group is 5 or more.  If the calculated value of the Kruskal-Wallis test is less than the critical chi-square value, then the null hypothesis cannot be rejected.  If the calculated value of Kruskal-Wallis test is greater than the critical chi-square value, then we can reject the null hypothesis and say that at least one of the samples comes from a different population.
和自由度为1的卡方检验近似，如果每组观测值>=5。
如果p很小，否定原假设，就是至少一个组来自另一个总体。

Assumptions
1. We assume that the samples drawn from the population are random.
2. We also assume that the observations are independent of each other.
3. The measurement scale for the dependent variable should be at least ordinal.







3.Kruskal-Wallis test (H-test) 是 Wilcoxon test 的延伸，用于检验一系列非配对数据是否来自于同一个总体。
The Kruskal-Wallis test (H-test) is an extension of the Wilcoxon test and can be used to test the hypothesis that a number of unpaired samples originate from the same population. 

In MedCalc, Factor codes are used to break-up the (ordinal) data in one variable into different sample subgroups. If the null-hypothesis, being the hypothesis that the samples originate from the same population, is rejected (P<0.05), then the conclusion is that there is a statistically significant difference between at least two of the subgroups.

https://www.medcalc.org/manual/kruskal-wallis_test.php







========================================
Performing a binomial test in R 二项分布检验
----------------------------------------
paper说："one-tailed binomial test"?
The global tendency for 3′ UTR shortening or lengthening in one cell cluster relative to another was tested using a one-tailed binomial test.

1. Binomial test
A binomial test compares the number of successes observed in a given number of trials with a hypothesised probability of success. The test has the null hypothesis that the real probability of success is equal to some value denoted p, and the alternative hypothesis that it is not equal to p. The test can also be performed with a one-sided alternative hypothesis that the real probability of success is either greater than p or that it is less than p.

二项检验将在给定数量的试验中观察到的成功数量与假设的成功概率进行比较。
零假设是：观察值的真实概率等于一个给定的p，备择假设是不等于p。
该检验也可以进行单边备择检验，看p是大于或者小于p。

(1)
> binom.test(nsuccesses, ntrials, p) # 成功的观察数, 实验次数, 假设的p值
where nsuccesses is the number of successes observed, 
ntrials is the total number of trials 
and p is the hypothesised probability of success.

(2)
Alternatively you can give the number of successes and the number of failures observed, as shown below.
> binom.test(c(nsuccesses, nfailures), p) #(c(成功数, 失败数), 概率)

(3)To perform a one-sided test, set the alternative argument to "less" or "greater" as required.
> binom.test(nsuccesses, ntrials, p, alternative="greater") #单边检验


(4)The output includes a 95% confidence interval for the true probability. To adjust the size of this interval, use the conf.level argument as shown.

> binom.test(nsuccesses, ntrials, p, conf.level=0.99) #指定阈值






2. 实例 Example: Binomial test for die(色子) rolls
In a game, you suspect your opponent is using a die which is biased to roll a six greater than 1/6 of the time. Suppose you want to prove this by rolling the die 300 times and using a binomial test to determine whether the probability of rolling a six is equal to 1/6. A one-tailed test with a significance level of 0.05 will be used.

你怀疑对手用的色子投出6的概率超过1/6。
你做了一个实验，投300次，看出现6的概率是否等于1/6。
在0.05水平，单尾检验。

You roll the die 300 times and throw a total of 60 sixes. To perform the test, use the command:

> binom.test(60, 300, 1/6, alternative="greater")

## Exact binomial test
## 
## data:  60 and 300
## number of successes = 60, number of trials = 300, p-value = 0.07299
## alternative hypothesis: true probability of success is greater than 0.1666667
## 95 percent confidence interval:
##  0.1626847 1.0000000
## sample estimates:
## probability of success 
##                    0.2

From the output you can see that the p-value is 0.07299. As this is not less that the significance level of 0.05, we cannot reject the null hypothesis that the probability of rolling a six is 1/6. This means that there is no evidence to prove that the die is not fair.
p>0.05，无法拒绝原假设。也就是没有证据表明色子不公平。



http://www.instantr.com/2012/11/06/performing-a-binomial-test/



========================================
卡方检验 chi-squared tests: 列联表也称为 contingency table
----------------------------------------

1.有两类：
There are two types of chi-square tests. Both use the chi-square statistic and distribution for different purposes:

(1)卡方拟合优度检验 chi-square goodness of fit test determines if a sample data matches a population. For more details on this type, see: Goodness of Fit Test.

(2)卡方独立性检验 A chi-square test for independence compares two variables in a contingency table to see if they are related. In a more general sense, it tests to see whether distributions of categorical variables differ from each another.

- A very small chi square test statistic means that your observed data fits your expected data extremely well. In other words, there is a relationship.
- A very large chi square test statistic means that the data does not fit very well. In other words, there isn’t a relationship.

The formula for the chi-square statistic used in the chi square test is:
卡方和 = 求和(i=1 to n) (O-E)**2 /E
- “O” is your observed value and 
- E is your expected value. 

检查自由度df=(row-1)*(col-1),p=0.05的临界值。

https://blog.csdn.net/flowingflying/article/details/8076296
实际观察次数O与某理论次数(E又称期望次数)之差的平方再除以理论次数乃是一个与抽样分布之一的χ2分布非常近似的次数分布。

如同n足够大是，二项分布和正态分布非常吻合一样，这里也不做理解证明，由法国数学家Pearson给出，就当给了个工具，我们相信工具有效，来使用工具，常用于检查出现频率。





2. 实例: 独立性检验
数据: 夫妻家务劳动分工
	Wife	Alternating	Husband	Jointly
Laundry	156	14	2	4
Main_meal	124	20	5	4
Dinner	77	11	7	13
Breakfeast	82	36	15	7
Tidying	53	11	1	57
Dishes	32	24	4	53
Shopping	33	23	9	55
Official	12	46	23	15
Driving	10	51	75	3
Finances	13	13	21	66
Insurance	8	1	53	77
Repairs	0	3	160	2
Holidays	0	1	6	153

# Import the data
file_path <- "http://www.sthda.com/sthda/RDoc/data/housetasks.txt"
housetasks <- read.delim(file_path, row.names = 1)
# head(housetasks)

#1画图
#install.packages("gplots")
library("gplots")
# 1. convert the data as a table
dt <- as.table(as.matrix(housetasks))
# 2. Graph
balloonplot(t(dt), main ="housetasks", xlab ="", ylab="",
            label = FALSE, show.margins = FALSE)
#2马赛克图
library("graphics")
mosaicplot(dt, shade = TRUE, las=2, main = "housetasks")
#3又一个可视化
# install.packages("vcd")
library("vcd")
# plot just a subset of the table
assoc(head(dt, 5), shade = TRUE, las=3)


#做卡方检验，只需要一句
chisq <- chisq.test(housetasks)
chisq
## 	Pearson's Chi-squared test
## 
## data:  housetasks
## X-squared = 1944.5, df = 36, p-value < 2.2e-16
结论： p<0.05，拒绝零假设，也就是行和列相关，夫妻和做的家务有明确对应关系。





探究哪些因素对卡方的贡献：
str(chisq)
chisq$observed #观察值
round(chisq$expected,2) #期望值

#
# Pearson residuals (r): r=(o-e)/sqrt(e)
round(chisq$residuals, 3)

#
# 残差图: 正相关blue，表示行和列有正关联。负相关red
library(corrplot)
corrplot(chisq$residuals, is.cor = FALSE)
## For a given cell, the size of the circle is proportional to the amount of the cell contribution.


#每个cell对卡方值的贡献 contrib=r**2/卡方
# Contibution in percentage (%)
contrib <- 100*chisq$residuals^2/chisq$statistic
round(contrib, 3)
# Visualize the contribution
corrplot(contrib, is.cor = FALSE)





3. 实例： 拟合优度检验
http://www.sthda.com/english/wiki/chi-square-goodness-of-fit-test-in-r

The chi-square goodness of fit test is used to compare the observed distribution to an expected distribution, in a situation where we have two or more categories in a discrete data. In other words, it compares multiple observed proportions to expected probabilities.
比较每一份的比例，是否和期望的概率一致。


Suppose that, in the region where you collected the data, the ratio of red, yellow and white tulip is 3:2:1 (3+2+1 = 6). This means that the expected proportion is:
3/6 (= 1/2) for red
2/6 ( = 1/3) for yellow
1/6 for white


R语言：
tulip <- c(81, 50, 27) #实际抽样的结果
res <- chisq.test(tulip, p = c(1/2, 1/3, 1/6))
res

## 	Chi-squared test for given probabilities
## 
## data:  tulip
## X-squared = 0.20253, df = 2, p-value = 0.9037
p>0.05，无法拒绝零假设。也就是认为采样符合期望的比例。


#拿到p值
res$p.value #[1] 0.9036928




描述： https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/chi-square/
R语言： http://www.sthda.com/english/wiki/chi-square-test-of-independence-in-r


========================================
转录组差异表达筛选的真相
----------------------------------------
可惜，TPM、FPKM等方法已经对测序深度进行了均一化，所以生来就是用来比较样品内不同基因表达差异的，用于不同样品间同一基因的差异表达分析并不合适，很多信息已经被抹去了。


其实统计学家也很无奈啊，看看我们转录组实验得到的这些数据吧：我们的实验只进行少得可怜的生物学重复（n<10），而且，任何基因的表达量都不能是负数，这些数据并不符合正态分布，用于表征表达量的counts是非连续的（芯片信号是连续的），RNA-seq数据的离散通常是高度扭曲的，方差往往会大于均值……，就这些奇怪的特征，使得准确估计方差并没有想象的那么容易。


我们面临两个核心问题：
基因表达数据适合用什么统计学分布进行差异显著性检验？
如何利用少量生物学重复数据估算基因表达的标准差？



我们不去抖旧包袱，反正经过各种较量，大家普遍接受生物学重复这么少的情况下，RNA-seq数据用负二项分布（Negative binomialdistribution，通常写作NB）进行显著性检验是较合适的。

但，在生物学重复很少时，我们是很难准确计算每个基因表达的标准差的（相当于这个数据集的离散程度）。我们很可能会低估数据的离散程度。

被逼无奈的科学家提出了一个假设：表达丰度相似的基因，在总体上标准差应该也是相似的。我们把不同生物学重复中表达丰度相同的基因的总标准差取个平均值，低于这个值的都用这个值，高于这个值的就用算出来的值。







refer:
生信百科 2017-06-02 https://mp.weixin.qq.com/s/VcjnvI5FqwOFEC9wSUfdSw



========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------


========================================
----------------------------------------



========================================
----------------------------------------




========================================
----------------------------------------



========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------


========================================
----------------------------------------

