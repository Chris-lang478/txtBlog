ATAC-seq




========================================
ATAC-seq 简介 及教程
----------------------------------------

0. ATAC-seq经典之作
论文标题：Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position

表观测序领域大牛William J Greenleaf和Howard Y Chang的经典之作，引用上千次的ATAC经典原文
翻译: https://mp.weixin.qq.com/s?__biz=MzA4NTIyMzk4Mg%3D%3D&mid=2247483678&idx=1&sn=de7b6bcbf76c2a9051d0db7a4d9cd074



(2) harvard ATAC 分析流程
https://informatics.fas.harvard.edu/atac-seq-guidelines.html
https://informatics.fas.harvard.edu/atac-seq-guidelines-old-version.html
https://informatics.fas.harvard.edu/category/software.html



(3) ATAC 个性化分析思路
https://www.cnblogs.com/leezx/p/12953732.html


ChIP-seq流程(snakemake) https://zhuanlan.zhihu.com/p/48320500







2. 基础
(1).复习核小体知识：https://en.wikipedia.org/wiki/ATAC-seq
核小体有间距，则间距部分会被Tn5酶插入测序接头，也就能看到reads 峰。
而核小体密集区域，则几乎没有reads，也就看不到任何峰。

如果一个基因处于开放区域，就是测到很多ATAC reads，则该基因一般就是高表达的。
如果一个promoter在开放区域，则其下游基因一般高表达。
如果一个enhancer 处在比较弱(少ATAC reads)的区域，则该 enhancer 不太容易发生近端效应。


(2) ATAC-seq 就是越松散的genome区域，测得的reads越多。该区域基因表达量比较多。
测序reads分布示意图 https://github.com/crazyhottommy/pyflow-ATACseq/blob/master/ATAC.jpg
https://blog.csdn.net/u012110870/article/details/102804164
https://www.jianshu.com/p/eb02b95cf049

ATAC文库构建通常借助Illumina的Nextera®（Illumina）试剂盒，然而Nextera文库涉及的序列不同于其他形式的文库。

### Tn5转座酶切割开放DNA
Tn5转座子切割相同的DNA片段并在片段两端添加如下序列，其中加粗斜体部分紧挨着文库的插入片段序列
序列如下:
Read 1 ——>  5’ TCGTCGGCAGCGTC[AGATGTGTATAAGAGACAG] 
Read 2 ——>  5’ GTCTCGTGGGCTCGG[AGATGTGTATAAGAGACAG] 
可以发现Read1、Read2部分序列一致： AGATGTGTATAAGAGACAG

### 随后PCR扩增连接P5、P7接头
连接测序接头以锚定在flowcell芯片上的接头以供测序反应：

序列如下：
[P5--index5-R1]  5’ AATGATACGGCGACCACCGAGATCTACAC[i5]TCGTCGGCAGCGTC 
[P7--index7-R2]  5’ CAAGCAGAAGACGGCATACGAGAT[i7]GTCTCGTGGGCTCGG

### 完整文库结构
Index 2 (i5)5’-[AATGATACGGCGACCACCGAGATCTACAC]IIIIIIII[TCGTCGGCAGCGTC->AGATGTGTATAAGAGACAG]-NNNNNN-[CTGTCTCTTATACACATCT<-CCGAGCCCACGAGAC]IIIIIIII[ATCTCGTATGCCGTCTTCTGCTTG]-3’ Index 1 (i7)

IIIIIIII: Index 2 (i5), 8 bases 
IIIIIIII: Index 1 (i7), 8 bases 
-NNNNNN-: 插入序列
ref:http://bioinformatics.cvr.ac.uk/blog/illumina-adapter-and-primer-sequences/

这个图很奇怪，
左边: P5,N5, index2(i5), 最后来个Read 1.
右边: P7,N7, index1(i7), 最后来个Read 2.
index内 14+19 + 19+15=67 形式上浪费这么多序列
	假设测150，还剩余 150-67=83
	假设测100，还剩余 150-67=33

如何过滤去接头？
如果截去接头序列需要在 CTGTCTCTTATACACATCT 位置截取，工具可以是cutadapt、trim_galore等类似可以自定义截去接头的软件。






(3) 分析过程： 五个大步骤
raw FASTQ cut adapter
mapping to the reference with aligner like bwa, bowtie2
sort alignment result (BAM files)
remove BAM file duplications
peak-calling with MACS2


测序数据文件是两个重复的双端测序：
ATAC_seq_rep1_R1.fq.gz ATAC_seq_rep1_R2.fq.gz 
ATAC_seq_rep2_R1.fq.gz ATAC_seq_rep2_R2.fq.gz 
ATAC_seq_rep3_R1.fq.gz ATAC_seq_rep3_R2.fq.gz 



ENCODE 项目公开了ATAC数据、标准和分析过程（基于wdl的），值得参考。
提供了从原始的fastq数据开到，到peak caling结束的基础分析功能，尽管缺少了下游的差异分析和motfi分析，这套流程依然值得推荐。
https://github.com/ENCODE-DCC/atac-seq-pipeline

trim, mapping, peak calling三部曲：通过cutadapt软件去除adapter和低质量序列，然后是bowitie2比对参考基因组，最后调用MACS2进行peak calling。






========================================
ATAC-seq分析走流程：基础分析 (测试数据)
----------------------------------------

1. 准备数据：用哪一套数据？
https://blog.csdn.net/weixin_43569478/article/details/108079790

(1) 检索 GEO
all: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE97669
ATAC-seq for HeLa cell line(n=2) PMID: 29731168
https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE106145


ATAC-seq for MDA-MB-231, ctrl vs KO(n=6, 2ctrl, 2KO*2)
https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE97583


HeLa ATAC-Seq, address the effect of TLK loss on chromatin accessibility(n=6, 2ctrl, 2KO*2)
https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE131022


(2) 选中这个，并下载
ATAC-seq of MCF-7 cells post ligand treatment(n=18) 这个数据不错。


文章: https://www.ncbi.nlm.nih.gov/pubmed/31353221
Guan J, Zhou W, Hafner M, Blake RA et al. Therapeutic Ligands Antagonize Estrogen Receptor Function by Impairing Its Mobility. 
Cell 2019 Aug 8;178(4):949-963.e18. PMID: 31353221


Results: 
Ligand 4-OH tamoxifen, a selective ER modulator (SERM), significantly alters chromatin accessibility and partially mimics the effect of natural ligand E2 on chromatin accessibility in MCF-7 breast cells. 
Selective ER degraders (SERD) fulvestrant and GDC-0927 on the other hand have very little impact on chromatin accessibility.

https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE117940
GSM3315603	Vehicle Rep 1 SRR7629152
GSM3315604	Vehicle Rep 3
GSM3315605	Vehicle Rep 2

GSM3315612	4-OH tamoxifen Rep 3  SRR7629161
GSM3315613	4-OH tamoxifen Rep 2
GSM3315614	4-OH tamoxifen Rep 1


https://www.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA483774
$ cd /home/wangjl/data/ATAC/raw
$ cat SRR_Acc_List.txt
SRR7629152
SRR7629153
SRR7629154
SRR7629161
SRR7629162
SRR7629163

$ cat SRR_Acc_List.txt | head -n 3 | while read id; do echo $id; 
fasterq-dump --split-files -e 10 $id;
done;


$ cat SRR_Acc_List.txt | tail -n 3 | while read id; do echo $id; 
fasterq-dump --split-files -e 10 $id;
done;

# 22:36 --> 0:09, 1.5h 66G,
$ ls -lh
total 66G
-rw-rw-r-- 1 wangjl wangjl 4.3G Jun 17 22:48 SRR7629152_1.fastq
-rw-rw-r-- 1 wangjl wangjl 4.3G Jun 17 22:48 SRR7629152_2.fastq
-rw-rw-r-- 1 wangjl wangjl 5.9G Jun 17 23:27 SRR7629153_1.fastq
-rw-rw-r-- 1 wangjl wangjl 5.9G Jun 17 23:27 SRR7629153_2.fastq
-rw-rw-r-- 1 wangjl wangjl 5.3G Jun 18 00:01 SRR7629154_1.fastq
-rw-rw-r-- 1 wangjl wangjl 5.3G Jun 18 00:01 SRR7629154_2.fastq

-rw-rw-r-- 1 wangjl wangjl 4.8G Jun 17 22:51 SRR7629161_1.fastq
-rw-rw-r-- 1 wangjl wangjl 4.8G Jun 17 22:50 SRR7629161_2.fastq
-rw-rw-r-- 1 wangjl wangjl 6.3G Jun 17 23:32 SRR7629162_1.fastq
-rw-rw-r-- 1 wangjl wangjl 6.3G Jun 17 23:32 SRR7629162_2.fastq
-rw-rw-r-- 1 wangjl wangjl 6.5G Jun 18 00:09 SRR7629163_1.fastq
-rw-rw-r-- 1 wangjl wangjl 6.5G Jun 18 00:09 SRR7629163_2.fastq


Reads很短，就40bp?
$ head SRR7629152_1.fastq 
@SRR7629152.1 1 length=41
CACCANTGGCAGCCTAGCATTAGCAGGAATACCTTTCCTCA
+SRR7629152.1 1 length=41
A/AAA#AEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE/


(3) 先压缩一下，减少磁盘占用
$ cat SRR_Acc_List.txt | tail -n 3 | while read id; do echo $id; 
gzip ${id}_1.fastq;
done;

变换 _1 为 _2, tail 为 head，共4种组合。
9:40 --> 10:28 可能之前就结束了。缩小为原来的 20%。

$ ls -lth
total 13G
-rw-rw-r-- 1 wangjl wangjl 1.3G Jun 18 00:09 SRR7629163_2.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 1.3G Jun 18 00:09 SRR7629163_1.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 1.1G Jun 18 00:01 SRR7629154_2.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 1.1G Jun 18 00:01 SRR7629154_1.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 1.2G Jun 17 23:32 SRR7629162_1.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 1.2G Jun 17 23:32 SRR7629162_2.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 1.2G Jun 17 23:27 SRR7629153_2.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 1.1G Jun 17 23:27 SRR7629153_1.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 909M Jun 17 22:51 SRR7629161_1.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 935M Jun 17 22:50 SRR7629161_2.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 826M Jun 17 22:48 SRR7629152_1.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 863M Jun 17 22:48 SRR7629152_2.fastq.gz

(4) 先抽取部分测试
$ zcat SRR7629152_1.fastq.gz | wc
111588868 223177736 4533824964
111/4 Million reads /sample. 抽取 1e5 reads/sample.

$ mkdir ../fq
$ cat SRR_Acc_List.txt | while read id; do echo $id; 
zcat ${id}_1.fastq.gz | head -n 400000 | gzip > ../fq/s_${id}_1.fastq.gz;
zcat ${id}_2.fastq.gz | head -n 400000 | gzip > ../fq/s_${id}_2.fastq.gz;
done;
# 几秒结束。

$ cd ../fq/
$ zcat s_SRR7629163_2.fastq.gz  | wc
 400000  800000 15147256















========================================
|-- QC: raw fastq 
----------------------------------------
先用抽样数据走流程
$ cd /data/wangjl/ATAC/fq/

(1) 质控
$ mkdir QC_raw
$ fastqc -t 10 *.fastq.gz -o QC_raw/


$ sudo pip3 install multiqc
$ multiqc --version
multiqc, version 1.10.1

$ mkdir QC_raw/multiqc/
$ multiqc QC_raw/*fastqc.zip -o QC_raw/multiqc/

检查: 
$ http-server -p 12345
多数40bp长度，没有其他异常，连adapter都没有。



========================================
|-- 去接头
----------------------------------------
(2) 去接头
https://github.com/ENCODE-DCC/atac-seq-pipeline/blob/master/src/detect_adapter.py
'Nextera ': b'CTGTCTCTTATA', #经过grep检测，这个接头最多，其他2个没有发现。


$ id="SRR7629163" && cutadapt -j 4 --time 1 -e 0.1 -O 3 --quality-cutoff 25 \
-m 15 -a CTGTCTCTTATA \
-A AGACGGGAAGAGCGTCGTGAGGGAAGAGTGTAGATCTCGGTGGTCGCGTATCATT \
-o clean/${id}_1.fastq.gz -p clean/${id}_2.fastq.gz s_${id}_1.fastq.gz s_${id}_2.fastq.gz > clean/cut.log 2>&1
## 98.1% rewrite.

$ ls *1.fastq.gz | sed -e 's/s_//' -e 's/_1.fastq.gz//'
SRR7629152
SRR7629153
SRR7629154
SRR7629161
SRR7629162
SRR7629163

$ ls *1.fastq.gz | sed -e 's/s_//' -e 's/_1.fastq.gz//' | while read id; do echo $id; 
cutadapt -j 4 --time 1 -e 0.1 -O 3 --quality-cutoff 25 \
-m 15 -a CTGTCTCTTATA \
-A AGACGGGAAGAGCGTCGTGAGGGAAGAGTGTAGATCTCGGTGGTCGCGTATCATT \
-o clean/${id}_1.fastq.gz -p clean/${id}_2.fastq.gz s_${id}_1.fastq.gz s_${id}_2.fastq.gz >> clean/cut.log 2>&1;
done;



========================================
|-- mapping with BWA
----------------------------------------
(3). mapping with BWA
因为reads太短了，决定使用 bwa。
$ bwa 
Program: bwa (alignment via Burrows-Wheeler transformation)
Version: 0.7.17-r1188

#########################
# 构建索引
#########################
UCSC GRCh38
$ cd /home/wangjl/data/ref/human/UCSC/
$ bwa index -a bwtsw -p bwa/hg38_fa hg38.fa.gz
其中 -p bwa/hg38_ 是指定前缀
939M Jan 16  2014 hg38.fa.gz
[main] Real time: 2974.649 sec(49min); CPU: 2929.810 sec

$ ls /home/wangjl/data/ref/human/UCSC/bwa -lth
total 5.3G
-rw-rw-r-- 1 wangjl wangjl 1.5G Jun 18 15:39 hg38_fa.sa
-rw-rw-r-- 1 wangjl wangjl  21K Jun 18 15:24 hg38_fa.amb
-rw-rw-r-- 1 wangjl wangjl  22K Jun 18 15:24 hg38_fa.ann
-rw-rw-r-- 1 wangjl wangjl 766M Jun 18 15:24 hg38_fa.pac
-rw-rw-r-- 1 wangjl wangjl 3.0G Jun 18 15:23 hg38_fa.bwt


#########################
# 比对 & sort
#########################
bwa mem genome.fa  A1_clean_1.fq.gz A1_clean_2.fq.gz | samtools sort -O bam -T A1 > A1.bam

$ cd /data/wangjl/ATAC/fq
$ mkdir map

$ id="SRR7629163"
$ bwa mem -t 10 -R "@RG\tID:${id}\tSM:${id}" /home/wangjl/data/ref/human/UCSC/bwa/hg38_fa  clean/${id}_1.fastq.gz clean/${id}_2.fastq.gz -o map/${id}.sam
##[main] Real time: 6.269 sec; CPU: 34.911 sec
## -t 10 线程数

$ grep -v '^[#@]' map/SRR7629163.sam |wc
 196244 3373449 38998448

$ samtools sort -O bam -T ${id}_tmp map/${id}.sam > map/${id}.sort.bam
## -T 是临时文件夹
$ ls -lth map/
total 45M
-rw-rw-r-- 1 wangjl wangjl 7.6M Jun 18 16:18 SRR7629163.sort.bam  #体积缩小为原来的19%。
-rw-rw-r-- 1 wangjl wangjl  38M Jun 18 16:15 SRR7629163.sam


二合一，批量（注意：使用双引号，变量才能替换）
$ cat ../raw/SRR_Acc_List.txt | while read id; do echo $id;
bwa mem -t 10 -R "@RG\tID:${id}\tSM:${id}" /home/wangjl/data/ref/human/UCSC/bwa/hg38_fa  clean/${id}_1.fastq.gz clean/${id}_2.fastq.gz | samtools sort -O bam -T ${id}_tmp > map/${id}.sort.bam;
done;

$ ls -lth map/
total 44M
-rw-rw-r-- 1 wangjl wangjl 7.6M Jun 18 16:21 SRR7629163.sort.bam
-rw-rw-r-- 1 wangjl wangjl 7.0M Jun 18 16:21 SRR7629162.sort.bam
-rw-rw-r-- 1 wangjl wangjl 7.0M Jun 18 16:21 SRR7629161.sort.bam
-rw-rw-r-- 1 wangjl wangjl 7.9M Jun 18 16:21 SRR7629154.sort.bam
-rw-rw-r-- 1 wangjl wangjl 7.0M Jun 18 16:21 SRR7629153.sort.bam
-rw-rw-r-- 1 wangjl wangjl 7.6M Jun 18 16:21 SRR7629152.sort.bam

$ samtools view map/SRR7629154.sort.bam | wc
 197452 3398838 39337777




#########################
# index
#########################
$ cat ../raw/SRR_Acc_List.txt | while read id; do echo $id;
samtools index map/${id}.sort.bam;
done;







========================================
|-- 去除线粒体上的reads，去重复 (推荐使用 sambamba，其次 picard，最不推荐 samtools)
----------------------------------------
由于细胞器DNA蛋白结合少，所以显然更容易被Tn5 转座酶切割，普通的ATAC-Seq的read就会有大量是细胞器的DNA，这就是为啥需要用INTACT技术。

此外如果不是PCR-free的建库方法，会有大量重复的read，也就需要标记或去除重复。



1. 去掉线粒体上的reads。
首先将不含质体的染色体名称写到一个chrlist文件中，染色体名称之间用空格隔开，然后执行如下命令即可得到去除质体的bam
$ samtools view -b A1.bam `cat chrlist` > A1.del_MT_PT.bam


执行
$ samtools view  map/SRR7629153.sort.bam| grep -v "^#"| awk '{print $3}' | sort | uniq -c| grep -E -v "GL|KI|JH|KB|chrM"
    678 *
  16554 chr1
   5261 chr10
   5175 chr11
   5527 chr12
   2483 chr13
   4475 chr14
   3155 chr15
   3655 chr16
   6137 chr17
   1604 chr18
   2189 chr19
   9700 chr2
   5257 chr20
   1694 chr21
   1163 chr22
   8552 chr3
   5334 chr4
   8615 chr5
   6031 chr6
   7196 chr7
   7400 chr8
   4485 chr9
   3427 chrX
    215 chrY

$ cat map/chrlist
chr1 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr2 chr20 chr21 chr22 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chrX chrY


$ cat ../raw/SRR_Acc_List.txt | while read id; do echo $id; 
samtools view -b map/${id}.sort.bam `cat map/chrlist` > map/${id}.del_MT.sort.bam;
done;






2. 去重复
用于后续分析的reads需要是唯一比对且去重复的，bwa比对结果可以通过MAPQ值来提取唯一比对reads，可以用picard、sambamba等软件去除dup，最终得到唯一比对且去重复的bam文件。

samtools rmdup 是如何行使去除PCR重复reads功能的？和 picard MarkDuplicates 现在改名为 GATK MarkDuplicates 有什么区别？

(1) The Genome Analysis Toolkit (GATK) v4.1.9.0
HTSJDK Version: 2.23.0
Picard Version: 2.23.3

$ gatk MarkDuplicates
Using GATK jar /data/wangjl/soft/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar
Running:
    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /data/wangjl/soft/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar MarkDuplicates
USAGE: MarkDuplicates [arguments]

命令行给出的例子
java -jar picard.jar MarkDuplicates \
I=input.bam \
O=marked_duplicates.bam \
M=marked_dup_metrics.txt



## 命令方式1: 新语法，官方推荐
$ id="SRR7629152"
$ gatk MarkDuplicates -I map/${id}.del_MT.sort.bam -O map/${id}.rmdup.bam -M map/${id}.rmdup.matrix -ASO coordinate -REMOVE_DUPLICATES true

$ samtools view map/SRR7629152.rmdup.bam | wc  #确实删掉了些行
 143879 2604778 31278683
$ samtools view map/SRR7629152.del_MT.sort.bam | wc
 145083 2481870 28650942


## 命令方式2: 控制内存和CPU占用，更安全的用法。
$ PICARD="/data/wangjl/soft/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar"
$ java -Xms5g -Xmx10g -XX:ParallelGCThreads=4 \
    -jar ${PICARD} MarkDuplicates \
    I=map/${id}.del_MT.sort.bam O=map/${id}.rmdup.bam M=map/${id}.rmdup.matrix \
    ASO=coordinate REMOVE_DUPLICATES=true 2>map/rmdup.log

$ samtools view map/SRR7629152.rmdup.bam | wc
 143879 2604778 31278683
和 方式1 结果一样。


批量运行，使用新语法
$ cat ../raw/SRR_Acc_List.txt | while read id; do echo $id; 
gatk MarkDuplicates -I map/${id}.del_MT.sort.bam -O map/${id}.rmdup.bam -M map/${id}.rmdup.matrix -ASO coordinate -REMOVE_DUPLICATES true;
done;



$ ls -lth map
total 147M
-rw-rw-r-- 1 wangjl wangjl 3.4K Jun 18 21:38 SRR7629163.rmdup.matrix
-rw-rw-r-- 1 wangjl wangjl 8.5M Jun 18 21:38 SRR7629163.rmdup.bam
-rw-rw-r-- 1 wangjl wangjl 3.4K Jun 18 21:38 SRR7629162.rmdup.matrix
-rw-rw-r-- 1 wangjl wangjl 7.3M Jun 18 21:38 SRR7629162.rmdup.bam
-rw-rw-r-- 1 wangjl wangjl 3.4K Jun 18 21:38 SRR7629161.rmdup.matrix
-rw-rw-r-- 1 wangjl wangjl 7.2M Jun 18 21:38 SRR7629161.rmdup.bam
-rw-rw-r-- 1 wangjl wangjl 3.4K Jun 18 21:38 SRR7629154.rmdup.matrix
-rw-rw-r-- 1 wangjl wangjl 8.5M Jun 18 21:38 SRR7629154.rmdup.bam
-rw-rw-r-- 1 wangjl wangjl 3.4K Jun 18 21:38 SRR7629153.rmdup.matrix
-rw-rw-r-- 1 wangjl wangjl 7.0M Jun 18 21:38 SRR7629153.rmdup.bam
-rw-rw-r-- 1 wangjl wangjl 3.4K Jun 18 21:37 SRR7629152.rmdup.matrix
-rw-rw-r-- 1 wangjl wangjl 8.4M Jun 18 21:37 SRR7629152.rmdup.bam






(2) 使用 samtools rmdup 去重复 (去的太多了，不建议用)
Usage:  samtools rmdup [-sS] <input.srt.bam> <output.bam>
-s    rmdup for SE reads
-S    treat PE reads as SE in rmdup (force -s)

$ samtools rmdup -S map/${id}.del_MT.sort.bam map/${id}.samtools_rmdup.bam
[bam_rmdupse_core] 4139 / 144722 = 0.0286 in library '	'

$ samtools view map/SRR7629152.samtools_rmdup.bam | wc
 140944 2408371 27736668
这个删除的有点多啊，
samtools 140944 (保留97.14%)，对比着 picard 的 143879 (保留99.17%)





(3) 用samblaster和sambamba来代替picard做sam文件的去重复，这两款软件比picard快30倍 (保留reads数和picard一样)
https://www.it610.com/article/1228439887515062272.htm

要注意的是picard Markduplicates 和sambamba markdup的输入文件是bam格式，samblaster是sam格式。这里只测试 sambamba。
sambamba 主要有filter，merge,slice和duplicate等七个功能来处理sam/bam文件。


## 安装
https://github.com/lomereiter/sambamba/releases
$ wget https://github.com/biod/sambamba/releases/download/v0.8.0/sambamba-0.8.0-linux-amd64-static.gz
$ gunzip sambamba-0.8.0-linux-amd64-static.gz
$ chmod +x sambamba-0.8.0-linux-amd64-static
$ ln -s /home/wangjl/soft/sambamba-0.8.0-linux-amd64-static ~/bin/sambamba


## 查看版本号
$ sambamba --version
sambamba 0.8.0
 by Artem Tarasov and Pjotr Prins (C) 2012-2020
    LDC 1.10.0 / DMD v2.080.1 / LLVM6.0.1 / bootstrap LDC - the LLVM D compiler (0.17.4)

$ sambamba markdup --help
Usage: sambamba-markdup [options] <input.bam> [<input2.bam> [...]] <output.bam>
       By default, marks the duplicates without removing them
-r, --remove-duplicates  remove duplicates instead of just marking them
-t, --nthreads=NTHREADS  number of threads to use
--tmpdir=TMPDIR    specify directory for temporary files



##--> 去重
$ sambamba markdup -r -t 5 --tmpdir map/tmp/${id} map/${id}.del_MT.sort.bam map/${id}.sambamba_rmdup.bam

$ ls -lth map/
total 155M
-rw-rw-r-- 1 wangjl wangjl 2.7M Jun 18 22:00 SRR7629152.sambamba_rmdup.bam.bai
-rw-rw-r-- 1 wangjl wangjl 6.1M Jun 18 22:00 SRR7629152.sambamba_rmdup.bam
drwxrwxr-x 2 wangjl wangjl 4.0K Jun 18 22:00 SRR7629152_tmp
同时生成一个bai文件。注意临时文件夹没删

$ samtools view map/SRR7629152.sambamba_rmdup.bam | wc
 143879 2460899 28401109

reads数和 picard 一模一样，速度更快，且文件更小。


批量运行
$ cat ../raw/SRR_Acc_List.txt | while read id; do echo $id; 
sambamba markdup -r -t 5 --tmpdir map/tmp/${id} map/${id}.del_MT.sort.bam map/${id}.sambamba_rmdup.bam;
done;


$ ls -lth map/
total 196M
-rw-rw-r-- 1 wangjl wangjl 2.7M Jun 18 22:04 SRR7629163.sambamba_rmdup.bam.bai
-rw-rw-r-- 1 wangjl wangjl 6.2M Jun 18 22:04 SRR7629163.sambamba_rmdup.bam
drwxrwxr-x 8 wangjl wangjl 4.0K Jun 18 22:04 tmp
-rw-rw-r-- 1 wangjl wangjl 2.5M Jun 18 22:04 SRR7629162.sambamba_rmdup.bam.bai
-rw-rw-r-- 1 wangjl wangjl 5.4M Jun 18 22:04 SRR7629162.sambamba_rmdup.bam
-rw-rw-r-- 1 wangjl wangjl 5.2M Jun 18 22:04 SRR7629161.sambamba_rmdup.bam
-rw-rw-r-- 1 wangjl wangjl 2.5M Jun 18 22:04 SRR7629161.sambamba_rmdup.bam.bai
-rw-rw-r-- 1 wangjl wangjl 2.6M Jun 18 22:04 SRR7629154.sambamba_rmdup.bam.bai
-rw-rw-r-- 1 wangjl wangjl 6.3M Jun 18 22:04 SRR7629154.sambamba_rmdup.bam
-rw-rw-r-- 1 wangjl wangjl 5.1M Jun 18 22:04 SRR7629153.sambamba_rmdup.bam
-rw-rw-r-- 1 wangjl wangjl 2.5M Jun 18 22:04 SRR7629153.sambamba_rmdup.bam.bai
-rw-rw-r-- 1 wangjl wangjl 2.7M Jun 18 22:04 SRR7629152.sambamba_rmdup.bam.bai
-rw-rw-r-- 1 wangjl wangjl 6.1M Jun 18 22:04 SRR7629152.sambamba_rmdup.bam






========================================
|-- QC: 比对结果质控 (TSS 热图 、插入片段长度分布图)
----------------------------------------
比对后，去掉线粒体、去重后的bam，再index后用于下游分析。


1.Reads在染色体上分布的可视化

比对后得到的bam文件可以转化为bigWig（bw）格式，可通过可视化软件进行展示。deeptools软件可以实现bw格式转化和可视化展示。

1) 首先需要在linux环境中安装deeptools软件，可以用以下命令实现bam向bw格式的转换：
$ id="SRR7629163"
## sambamba index -t 6 ${id}.sambamba_rmdup.bam ## 之前rmdup时已经自动生成过了
$ bamCoverage -b map/${id}.sambamba_rmdup.bam -o QC_map/${id}.bw;  ##必须提前index


## 批量化
$ cat ../raw/SRR_Acc_List.txt | while read id; do echo $id;
bamCoverage -b map/${id}.sambamba_rmdup.bam -o QC_map/${id}.bw;
done;


二进制文件，也没法直接看文件内容。不报错就认为没问题吧。

得到的BW文件可以用 IGV 进行可视化





2) 可以使用deeptools软件展示reads在特定区域的分布，如：
computeMatrix reference-point   \ # reference-pioint表示计算一个参照点附近的reads分布，与之相对的是scale-regions，计算一个区域附近的reads分布
       --referencePoint TSS   \#以输入的bed文件的起始位置作为参照点
       -S  A1.bw \ #可以是一个或多个bw文件
       -R  gene.bed \ #基因组位置文件
       -b 3000   \ #计算边界为参考点上游3000bp
       -a 3000   \ #计算边界为参考点下游3000bp，与-b合起来就是绘制参考点上下游3000bp以内的reads分布
       -o  A1.matrix.mat.gz \ #输出作图数据名称
#图形绘制
plotHeatmap \
 -m  A1.matrix.mat.gz\ #上一步生成的作图数据
 -out A1.pdf \ # 输出图片名称


computeMatrix 有两种模式可以选择，这里我们用的是reference-point，另外还有scale-regions，
- 前者适合看一个点附近的信号，后者则适合看指定的不同长度的区域。
- 当我们选用reference-point模式时，会默认用bed文件的第二列作为中心扩展。
- 工作原理 https://www.jianshu.com/p/ab2bb3f55d6f





## (i)下载bed格式的基因组位置文件(The BED file of the gene model can be downloaded from UCSC Table Browser.)
http://genome.ucsc.edu/cgi-bin/hgTables?command=start

genome: human
assembly: Dec. 2013 (GRCh38/hg38)
group: Genes and Gene Predictions
track: NCBI RefSeq
table: RefSeq All(ncbiRefSeq)
region: genome
output format: BED - browser extensible data
output file: hg38_refseq_whole_gene.bed

Click ‘get output’ button, and in the next page ‘Output refGene as BED’ click ‘get BED’ button.




##(ii) 统计
单个测试
$ computeMatrix reference-point   \
       --referencePoint TSS   \
       -S  QC_map/${id}.bw \
       -R  /home/wangjl/data/ref/human/UCSC/hg38_refseq_whole_gene.bed \
       -b 3000   \
       -a 3000   \
       -o  QC_map/matrix/${id}.matrix.mat.gz
很慢: 17:02-> 18:07


批量化，放后台运行。
$ cat ../raw/SRR_Acc_List.txt | while read id; do echo $id;
computeMatrix reference-point   \
       --referencePoint TSS   \
       -S QC_map/${id}.bw \
       -R /home/wangjl/data/ref/human/UCSC/hg38_refseq_whole_gene.bed \
       -b 1000 \
       -a 1000 \
       -o QC_map/matrix/${id}.mat.gz &
done;
## 检查后台 $ ps -aux | grep computeMatrix
风扇声音很大。

https://deeptools.readthedocs.io/en/latest/content/tools/plotHeatmap.html
https://deeptools.readthedocs.io/en/latest/content/tools/plotProfile.html
$ plotHeatmap -m $matrix -out $heatmap
$ plotProfile -m $matrix -out $profile





## (iii) 画图
单个测试
$ mkdir QC_map/pdf
$ plotHeatmap -m QC_map/matrix/${id}.mat.gz -out QC_map/pdf/${id}.pdf

批量化
$ cat ../raw/SRR_Acc_List.txt | while read id; do echo $id;
plotHeatmap -m QC_map/matrix/${id}.mat.gz -out QC_map/pdf/${id}_.pdf;
done;


目测：峰图和热图都出来了，5/6看着正常。其中一个热图不正常，没颜色变化。







2. 片段长度周期性分布图
https://www.jianshu.com/p/0a8d57dbfc3c

insert size与 fragment length 差别 http://tiramisutes.github.io/2016/09/19/Insert-Size.html

(1) 获取insert fragment 长度数据
$ echo $id  #SRR7629163

$ samtools view map/${id}.sambamba_rmdup.bam | \
awk -F'\t' 'function abs(x){return ((x < 0.0) ? -x : x)} {print $1"\t"abs($9)}' | \
sort | uniq | cut -f2 > map/${id}.fragment.length.txt
解释: 
awk中
	-F"\t" 按照tab分割
	然后定义一个函数 function abs(x){return ((x < 0.0) ? -x : x)} 表示返回绝对值。
	{print $1"\t"abs($9)} 打印第一列、第9列的绝对值
	
	
感觉不该使用uniq，因为不需要删重复？
$ samtools view map/${id}.sambamba_rmdup.bam | awk -F'\t' 'function abs(x){return ((x < 0.0) ? -x : x)} {print $1"\t"abs($9)}' |  sort | uniq -c | sort -k1n | head -n 80| tail
 1 SRR7629163.94576	0
      1 SRR7629163.97738	0
      1 SRR7629163.979	0
      1 SRR7629163.98342	0
      1 SRR7629163.98752	0
      1 SRR7629163.99702	0
      2 SRR7629163.100000	66
      2 SRR7629163.10001	45
      2 SRR7629163.10003	53
      2 SRR7629163.10004	61
目测除了0是出现1次，其他都是2次出现。
着重复是怎么来的呢？嗯，理解了，就是双端测序，每一端一行，一对reads是2行，分别记录本行信息和另一行的坐标，插入长度正负号不同。
$ samtools view map/${id}.sambamba_rmdup.bam | grep -P "SRR7629163.10004"
SRR7629163.10004	163	chr3	73049179	60	41M	=	73049200	61	AACTAAATGAATACATTCAAGATTAGAATACTTCTCGGGGC	AAAAAEEAEEE6EEEEEEEEEEEEEEEEAEEEEEAEEEEEE	NM:i:0	MD:Z:41	MC:Z:40M	AS:i:41	XS:i:19	RG:Z:${id}
SRR7629163.10004	83	chr3	73049200	60	40M	=	73049179	-61	ATTAGAATACTTCTCGGGGCCAGGTGTGGTGGCTCACGCC	AEEEEEEEEEAEEEEEEEEEE6EE/EEEE/EEE/EAAAAA	NM:i:0	MD:Z:40	MC:Z:41M	AS:i:40	XS:i:27	RG:Z:${id}








(2) 画图
hist 函数可以直接绘图，但是不太好看，可以用plot函数来画；同样density 函数也可以画图，但是也可以导出list,再进行plot 或者 ggplot 画图.

################
# R 包直接绘图
################
#BiocManager::install("ATACseqQC")
library(ATACseqQC)
fragSize <- fragSizeDist("map/SRR7629163.sambamba_rmdup.bam", "treat3")



################
# 原生R绘制
################

setwd("/data/wangjl/ATAC/fq")
getwd()

library(tidyverse)
data <- read.table("map/SRR7629163.fragment.length.txt")
dim(data) #73718     1
head(data)

######
# 过滤
######
# 去除0行
d2=data[data$V1>0,]
length(d2)
# 去掉太长的
d2=d2[d2<1200]
length(d2)

fragment=d2
length(fragment)


######
##Part1：基础语法画图
######
# 利用直方图统计频数分布，设置柱子个数
breaks_num <- 500
res <- hist(fragment, breaks = breaks_num, plot = FALSE)

# 添加坐标原点
plot(x = c(0, res$breaks),
     y = c(0, 0, res$counts) / 10^2,
     type = "l", col = "red",full="red",
     xlab = "Fragment length(bp)",
     ylab = expression(Normalized ~ read ~ density ~ 10^2),
     main = "Sample Fragment sizes")



######
##Part2：ggplot2 画图及其拼图
######
## 不同数据分布
df1 <- data.frame(x1 = c(0, res$breaks),y1=c(0, 0, res$counts) / 10^2)
p1 <- ggplot(df1,aes(x =x1,y = y1 ))+
  geom_line(col="red")+
  xlab("Fragment length(bp)")+
  ylab(expression(Normalized ~ read ~ count ~ 10^2))+
  ggtitle("Sample Fragment sizes")+
  theme_classic()
p1

## 画小图
df2 <- data.frame(x1 = c(0, res$breaks),y1=log10(c(0, 0, res$counts) / 10^2)+1)
p2 <- ggplot(df2,aes(x =x1,y = y1 ))+
  geom_line(col="red")+
  xlab("Fragment length(bp)")+
  ylab(expression(Normalized ~ read ~ count ~ (log)))+
  ggtitle("Sample Fragment sizes")+
  theme_classic()
p2

## 小图插入右上角
library(cowplot)
ggdraw() +
  draw_plot(p1, 0, 0, 1, 1) +
  draw_plot(p2, 0.5, 0.52, 0.5, 0.4) +
  draw_plot_label(c("A", "B"), c(0, 0.5), c(1, 0.92), size = 15)


######
##Part3：其他（密度图）
######
P3 <- ggplot(as.data.frame(fragment))+
  geom_density(aes(x=fragment),bw=3,color = "red")+
  xlim(0,NA)+
  scale_y_continuous(breaks = c(seq(0,0.004,0.001)),
                     labels=c(seq(0,4)),
                     name = expression(Normalized ~ read ~ density ~ 10^-3))+
  theme_classic()
P3








========================================
|-- Peak calling
----------------------------------------
(4) MACS2 找 peak 
MACS2能够检测DNA片断的富集区域，是ATAC-seq数据call peak的主流软件。

$ macs2 --version
macs2 2.2.7.1

峰检出的原理如下：
首先将所有的reads都向3'方向延伸插入片段长度，然后将基因组进行滑窗，计算该窗口的dynamic λ，
λ的计算公式为：λlocal = λBG（λBG是指背景区域上的reads数目），
然后利用泊松分布模型的公式计算该窗口的显著性P值，最后对每一个窗口的显著性P值进行FDR校正。
默认校正后的P值（即qvalue）小于或者等于0.05的区域为peak区域。


(i)需要在linux环境中安装macs2软件，然后执行以下命令：
macs2 callpeak \
	-t A1.uni.dedup.bam \ #bam文件
	-n A1 \ # 输出文件前缀名
	--shift -100 \ #extsize的一半乘以-1
	--extsize 200 \ #一般是核小体大小
	--call-summits #检测峰顶信息
注：以上参数参考文献（Jie Wang，et.al.2018.“ATAC-Seq analysis reveals a widespread decrease of chromatin accessibility in age-related macular degeneration.” Nature Communications）


==> 尝试1: 报错
$ macs2 callpeak \
	-f BAM -g hs \
	-t map/${id}.sambamba_rmdup.bam \
	-n macs2_test/${id} \
	--shift -100 \
	--extsize 200 \
	--call-summits
报错
INFO  @ Fri, 18 Jun 2021 22:52:18: #2 looking for paired plus/minus strand peaks...
INFO  @ Fri, 18 Jun 2021 22:52:18: #2 number of paired peaks: 0
WARNING @ Fri, 18 Jun 2021 22:52:18: Too few paired peaks (0) so I can not build the model! Broader your MFOLD range parameter may erase this error. If it still can't build the model, we suggest to use --nomodel and --extsize 147 or other fixed number instead.
WARNING @ Fri, 18 Jun 2021 22:52:18: Process for pairing-model is terminated!



==> 尝试2: 不知道怎么改。试试软件给的建议: --nomodel and --extsize 147
$ mkdir macs2_test
$ macs2 callpeak \
	-f BAM -g hs \
	-t map/${id}.sambamba_rmdup.bam \
	-n macs2_test/${id}_73 \
	--nomodel --shift -73 --extsize 147 \
	--call-summits
## Shift 模型参数：
--nomodel	这个参数和extsize、shift是配套使用的，有这个参数才可以设置 extsize 和 shift 。
--extsize	当设置了 nomodel 时，MACS会用--extsize这个参数从5'->3'方向扩展reads修复fragments。比如说你的转录因子结合范围200bp，就设置这个参数是200。
--shift	当设置了--nomodel，MACS用这个参数从5'端移动剪切，然后用--extsize延伸，如果--shift是负值表示从3'端方向移动。
	建议ChIP-seq数据集这个值保持默认值为0，对于检测富集剪切位点如DNAsel数据集设置为EXTSIZE的一半。
	那ATAC怎么设置? ATAC-seq关心的是在哪切断，断点才是peak的中心，所以使用shift模型，--shift -75或-100

MACS2输出文件解
$ ls -lth macs2_test/
total 32K
-rw-rw-r-- 1 wangjl wangjl 3.7K Jun 19 09:54 SRR7629163_73_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 2.7K Jun 19 09:54 SRR7629163_73_summits.bed
-rw-rw-r-- 1 wangjl wangjl 5.1K Jun 19 09:54 SRR7629163_73_peaks.xls

$ head macs2_test/SRR7629163_73_peaks.narrowPeak
chr1    629325  629494  macs2_test/SRR7629163_73_peak_1         54      .       2.96016 11.3533 5.45488 71
chr1    629602  629967  macs2_test/SRR7629163_73_peak_2a        126     .       3.67855 19.1081 12.6363 100
chr1    629602  629967  macs2_test/SRR7629163_73_peak_2b        41      .       2.70196 9.90816 4.16214 318
chr1    631059  631344  macs2_test/SRR7629163_73_peak_3a        58      .       2.91161 11.8142 5.88874 78
chr1    631059  631344  macs2_test/SRR7629163_73_peak_3b        87      .       3.22924 14.9192 8.73225 208




==> 尝试3: 人细胞系ATAC-seq 数据call peak的参数设置如下：
$ macs2 callpeak -t map/${id}.sambamba_rmdup.bam --outdir macs2_test -n ${id}_shift100 \
	-f BAM -g hs --shift -100 --extsize 200 --nomodel \
	-B --SPMR --call-summits 2>macs2_test/sample.macs2.log
参数解释
-B, --bdg  Whether or not to save extended fragment pileup, and local lambda tracks (two files) at every bp into a bedGraph file. DEFAULT: False
	是否保存2个文件(默认: 否): extended fragment pileup, and local lambda tracks to bedGraph file.
-B --SPMR 会多2个输出文件。

$ ls macs2_test/ -lth
total 8.8M
-rw-rw-r-- 1 wangjl wangjl 3.1K Jun 19 10:10 sample.macs2.log
-rw-rw-r-- 1 wangjl wangjl 4.4M Jun 19 10:10 SRR7629163_shift100_control_lambda.bdg  ##额外多的文件1
-rw-rw-r-- 1 wangjl wangjl 2.8K Jun 19 10:10 SRR7629163_shift100_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 4.2K Jun 19 10:10 SRR7629163_shift100_peaks.xls
-rw-rw-r-- 1 wangjl wangjl 2.0K Jun 19 10:10 SRR7629163_shift100_summits.bed
-rw-rw-r-- 1 wangjl wangjl 4.4M Jun 19 10:10 SRR7629163_shift100_treat_pileup.bdg ##额外多的文件2


## 批量化 
$ cat ../raw/SRR_Acc_List.txt | while read id; do echo $id;
macs2 callpeak -t map/${id}.sambamba_rmdup.bam --outdir macs2 -n ${id}_shift100 \
	-f BAM -g hs --shift -100 --extsize 200 --nomodel \
	-B --SPMR --call-summits 2>macs2/${id}.macs2.log;
done;


$ ls macs2/*narrowPeak -lth
-rw-rw-r-- 1 wangjl wangjl 2.9K Jun 19 14:52 macs2/SRR7629163_shift100_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 2.2K Jun 19 14:52 macs2/SRR7629162_shift100_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 2.7K Jun 19 14:52 macs2/SRR7629161_shift100_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 2.7K Jun 19 14:52 macs2/SRR7629154_shift100_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 2.5K Jun 19 14:52 macs2/SRR7629153_shift100_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 1.7K Jun 19 14:52 macs2/SRR7629152_shift100_peaks.narrowPeak















(ii) 按照另一个教程的参数
$ macs2 callpeak -t map/${id}.sambamba_rmdup.bam -f BAM -g hs -n macs2_/${id} -m 2 100
参数 [-m MFOLD MFOLD]

## 批量化
$ makir macs2_/
$ cat ../raw/SRR_Acc_List.txt | while read id; do echo $id;
macs2 callpeak -t map/${id}.sambamba_rmdup.bam -f BAM -g hs -n macs2_/${id} -m 2 100;
done;


$ ls -lth macs2_/*narrowPeak
-rw-rw-r-- 1 wangjl wangjl 3.6K Jun 19 14:54 macs2_/SRR7629163_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 3.2K Jun 19 14:54 macs2_/SRR7629162_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 3.1K Jun 19 14:54 macs2_/SRR7629161_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 2.2K Jun 19 14:54 macs2_/SRR7629154_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 3.2K Jun 19 14:54 macs2_/SRR7629153_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 1.5K Jun 19 14:54 macs2_/SRR7629152_peaks.narrowPeak



(iii) 另一个教程推荐使用 -f BAMPE
macs2 callpeak  -t <BED>  -f BEDPE  -n NAME  -g ce  --keep-dup all

Analyze only properly paired alignments with -f BAMPE. Here, the fragments are defined by the paired alignments' ends, and there is no modeling or artificial extension. Singleton alignments are ignored. This is the preferred option for using only properly paired alignments.

仅使用配对数据，单端被忽略。

$ macs2 callpeak -t map/${id}.sambamba_rmdup.bam  -f BAMPE --outdir macs2_/  -n ${id}_BAMPE  -g hs

$ ls -lth macs2_ | grep SRR7629163
-rw-rw-r-- 1 wangjl wangjl 3.4K Jun 22 20:06 SRR7629163_BAMPE_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 2.4K Jun 22 20:06 SRR7629163_BAMPE_summits.bed
-rw-rw-r-- 1 wangjl wangjl 4.7K Jun 22 20:06 SRR7629163_BAMPE_peaks.xls
-rw-rw-r-- 1 wangjl wangjl 2.5K Jun 19 14:54 SRR7629163_summits.bed
-rw-rw-r-- 1 wangjl wangjl 3.6K Jun 19 14:54 SRR7629163_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 5.0K Jun 19 14:54 SRR7629163_peaks.xls
-rw-rw-r-- 1 wangjl wangjl  74K Jun 19 14:54 SRR7629163_model.r

比 -f BAM 少了2行。



















#############
# treat vs control 可以跳过下面这一段 macs分析
#############

比较两组间的呢？

$ macs2 callpeak -c map/SRR7629152.sambamba_rmdup.bam map/SRR7629153.sambamba_rmdup.bam \
	-t map/SRR7629161.sambamba_rmdup.bam map/SRR7629162.sambamba_rmdup.bam map/SRR7629163.sambamba_rmdup.bam \
	-f BAM -g hs -n macs2/treat_vs_control -m 2 100;

$ ls -lth macs2/ | grep vs
-rw-rw-r-- 1 wangjl wangjl    0 Jun 18 23:06 treat_vs_control_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 1.5K Jun 18 23:06 treat_vs_control_peaks.xls
-rw-rw-r-- 1 wangjl wangjl    0 Jun 18 23:06 treat_vs_control_summits.bed
-rw-rw-r-- 1 wangjl wangjl  95K Jun 18 23:06 treat_vs_control_model.r

这里没有 narrowPeak 文件，长度是0, why?


#==> 去掉一个处理组，保持处理和对照样本数一致(n=2:2):
$ macs2 callpeak \
	-c map/SRR7629152.sambamba_rmdup.bam map/SRR7629153.sambamba_rmdup.bam \
	-t map/SRR7629161.sambamba_rmdup.bam map/SRR7629162.sambamba_rmdup.bam \
	-f BAM -g hs -n macs2/treat_vs_control -m 2 100;

$ ls -lth macs2/ | grep vs
-rw-rw-r-- 1 wangjl wangjl  24K Jun 18 23:12 treat_vs_control_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl  27K Jun 18 23:12 treat_vs_control_peaks.xls
-rw-rw-r-- 1 wangjl wangjl  18K Jun 18 23:12 treat_vs_control_summits.bed
-rw-rw-r-- 1 wangjl wangjl  82K Jun 18 23:12 treat_vs_control_model.r

$ Rscript macs2/treat_vs_control_model.r
能看到 Peak Model 图。
Cross−Correlation 图2条竖线。




#==> 使用三组，处理和对照样本数一致(n=3:3):
$ macs2 callpeak \
	-c map/SRR7629152.sambamba_rmdup.bam map/SRR7629153.sambamba_rmdup.bam map/SRR7629154.sambamba_rmdup.bam \
	-t map/SRR7629161.sambamba_rmdup.bam map/SRR7629162.sambamba_rmdup.bam map/SRR7629163.sambamba_rmdup.bam \
	-f BAM -g hs -n macs2/treat_vs_control-3 -m 2 100;

$ ls -lth macs2/ | grep -P "\-3"
-rw-rw-r-- 1 wangjl wangjl  47K Jun 19 09:39 treat_vs_control-3_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl  52K Jun 19 09:39 treat_vs_control-3_peaks.xls
-rw-rw-r-- 1 wangjl wangjl  34K Jun 19 09:39 treat_vs_control-3_summits.bed
-rw-rw-r-- 1 wangjl wangjl  95K Jun 19 09:39 treat_vs_control-3_model.r


$ Rscript macs2/treat_vs_control-3_model.r
能看到 Peak Model 图。
Cross−Correlation 图就剩下一条竖线。



==> 使用2组，使用ATAC-seq推荐参数
## 在 macs2/下清理文件 ls -t | tail -n 20 | xargs -i mv {} dustbin/

$ macs2 callpeak \
	-c map/SRR7629152.sambamba_rmdup.bam map/SRR7629153.sambamba_rmdup.bam \
	-t map/SRR7629161.sambamba_rmdup.bam map/SRR7629162.sambamba_rmdup.bam \
	--shift -100 --extsize 200 --nomodel \
	-f BAM -g hs -n macs2/treat_vs_control-shift100 2>macs2/shift100.macs2.log
## 没有 model 图，去掉 --nomodel 再执行一遍有了。

$ macs2 callpeak \
	-c map/SRR7629152.sambamba_rmdup.bam map/SRR7629153.sambamba_rmdup.bam \
	-t map/SRR7629161.sambamba_rmdup.bam map/SRR7629162.sambamba_rmdup.bam \
	--shift -100 --extsize 200 \
	-f BAM -g hs -n macs2/treat_vs_control-shift100-m 2>macs2/shift100-m.macs2.log
$ Rscript macs2/treat_vs_control-shift100-m_model.r

















========================================
ATAC-seq 高级分析（peak注释、差异peak、motif、转录因子的footprint和核小体占位）
----------------------------------------
1. paper
ATAC-seq数据分析工具的比较和推荐（Genome Biology综述）
https://mp.weixin.qq.com/s?__biz=MzA4NTIyMzk4Mg%3D%3D&mid=2247483678&idx=1&sn=de7b6bcbf76c2a9051d0db7a4d9cd074
https://pubmed.ncbi.nlm.nih.gov/32014034/


2. 技巧
https://www.cnblogs.com/leezx/p/12953732.html





========================================
|-- Annotation 峰注释
----------------------------------------
在科研分析中我们往往需要将peak区域与基因联系起来，也就是通过对peak进行注释找到peak相关基因。

It is helpful to know what genomic features are near the peaks called by MACS2. One program that is commonly used to annotate peaks is ChIPseeker. Like MACS2, ChIPseeker was originally designed to be used in the analysis of ChIP-seq, but it works just as well with ATAC-seq.

ChIPseeker requires that the genome of interest be annotated with locations of genes and other features. The ChIPseeker user guide is extremely helpful in using this R/Bioconductor package.


常见的peak注释软件有 ChIPseeker、homer、PeakAnnotator等。



1. 以ChIPseeker为例，需要在R中安装ChIPseeker包和GenomicFeatures包，然后就可以进行分析了。

library(ChIPseeker)
library(GenomicFeatures)
txdb<- makeTxDbFromGFF('gene.gtf') #生成txdb对象，如果研究物种没有已知的TxDb,可以用GenomicFeatures中的函数生成
peakfile <-readPeakFile('A1_peaks.narrowPeak') #导入需要注释的peak文件
peakAnno <- annotatePeak(peakfile,tssRegion=c(-2000, 2000), TxDb=txdb)
## 用peak文件和txdb进行peak注释，这里可以通过tssRegion定义TSS区域的区间


对于peak注释的结果，也可以进行可视化展示，如：
p <- plotAnnoPie(peakAnno)

一个饼图。










2. homer 注释峰
$ annotatePeaks.pl H3K4Me3.bed hg19 1>ChIP-Seq_H3K4Me3_1_peakAnn.xls 2>H3K4Me3_annLog.txt

Usage: annotatePeaks.pl <peak file | tss> <genome version>  [additional options...]


## 实例
$ annotatePeaks.pl macs2/SRR7629152_shift100_peaks.narrowPeak hg38 1>macs2/ann/SRR7629152_peakAnn.xls #2>macs2/ann/SRR7629152_ann.log

##==> 报错:
!!!!Genome hg38 not found in /home/wangjl/soft/homer/.//config.txt
        To check if is available, run "perl /home/wangjl/soft/homer/.//configureHomer.pl -list"
        If so, add it by typing "perl /home/wangjl/soft/homer/.//configureHomer.pl -install hg38"
查了一下，发现有 hg38
$ perl /home/wangjl/soft/homer/.//configureHomer.pl -list
下载安装这个，下载很慢！！
$ perl /home/wangjl/soft/homer/.//configureHomer.pl -install hg38
## Current base directory for HOMER is /home/wangjl/soft/homer/.//
安装很慢，主要是网速慢。


再次执行，还是成功。

$ head  macs2/ann/SRR7629152_peakAnn.xls
PeakID (cmd=annotatePeaks.pl macs2/SRR7629152_shift100_peaks.narrowPeak hg38)   Chr     Start   End     Strand  Peak Score      Focus Ratio/Region Size Annotation      Detailed Annotation     Distance to TSS Nearest PromoterID      Entrez ID       Nearest Unigene Nearest Refseq Nearest Ensembl Gene Name       Gene Alias      Gene Description        Gene Type
SRR7629152_shift100_peak_8      chr13   109424078       109424389       +       669     NA      Intergenic      Intergenic      23537   NR_126361       104326054       Hs.569298       NR_126361       ENSG00000229792 LINC00399       TCONS_00021596  long intergenic non-protein coding RNA 399     ncRNA
SRR7629152_shift100_peak_6      chr11   10509241        10509764        +       286     NA      promoter-TSS (NM_001190702)     promoter-TSS (NM_001190702)     -316    NM_001190702    100463486               NM_001190702    ENSG00000255823 MTRNR2L8        HN8     MT-RNR2 like 8 protein-coding
SRR7629152_shift100_peak_18     chr5    80651408        80651656        +       281     NA      promoter-TSS (NM_001190470)     promoter-TSS (NM_001190470)     -524    NM_001190470    100462981               NM_001190470            MTRNR2L2        HN2     MT-RNR2 like 2protein-coding
# 我加的列编号
# 1                             2       3               4               5       6       7       8                                9                               10     11              12                      13                       14              16       17            


1 PeakID (cmd=annotatePeaks.pl macs2/SRR7629152_shift100_peaks.narrowPeak hg38)   
2 Chr     
3 Start   
4 End     
5 Strand  

6 Peak Score      
7 Focus Ratio/Region Size
8 Annotation      
9 Detailed Annotation     
10 Distance to TSS 
11 Nearest PromoterID      
12 Entrez ID       
13 Nearest Unigene 
14 Nearest Refseq 
15 Nearest Ensembl 
16 Gene Name       
17 Gene Alias      
18 Gene Description        
19 Gene Type

看注释的效果，就是看第8和9列的分布，然后用R回个饼图。
$ head  macs2/ann/SRR7629152_peakAnn.xls| awk -F "\t" '{print $8}'




(2) 批量化
$ makir macs2/ann/
$ cat ../raw/SRR_Acc_List.txt | while read id; do echo $id;
annotatePeaks.pl macs2/${id}_shift100_peaks.narrowPeak hg38 1>macs2/ann/${id}_peakAnn.txt 2>macs2/ann/${id}_ann.log;
done;














========================================
|-- 差异分析: R包 DiffBind /  bedtools subtract //todo
----------------------------------------

1. 差异peak代表着比较组合染色质开放性有差异的位点，ChIP-seq和ATAC-seq都可以用 DiffBind 进行差异分析。DiffBind通过bam文件和peak的bed文件计算出peak区域标准化的readcount，可以选择edgeR、DESeq2等模型进行差异分析。

DiffBind是鉴定两个样本间差异结合位点的一个R包。
主要用于peak数据集，包括对peaks的重叠和合并的处理，计算peaks重复间隔的测序reads数，并基于结合亲和力鉴定具有统计显著性的差异结合位点。适用的统计模型有DESeq、DESeq2、edgeR。

library("DiffBind")


准备输入文件
需要准备一个SampleSheet文件，与ChIPQC的方法一样。SampleSheet文件是根据实验设计和数据存储地址等信息创建的一个csv格式文件，包含的表头信息有"SampleID"、 "Tissue"、 "Factor"、 "Condition" 、"Treatment"、"Replicate" 、"bamReads" 、"ControlID"、 "bamControl" "Peaks"、 "PeakCaller"（bam,peak文件分别在比对和call peak的步骤产生）。

""、 ""、 ""、 "" 、""、"" 、"" 、""、 "bamControl" "Peaks"、 "PeakCaller"

SampleID	Treatment	bamReads	ControlID
ctrl1	ctrl	c1.bam 	
ctrl2	ctrl	c2.bam 	
treat1	treat	t1.bam 	
treat2	treat	t2.bam 	



dbObj <- dba(sampleSheet="SampleSheet.csv")








2. Comparing peak files
Determining genomic regions that are common or different to a set of peak files is best accomplished with BEDTools, a suite of software tools that enables "genome arithmetic."

(1) 重复内共有的峰 bedtools intersect
For example, bedtools intersect determines regions that are common to two peak files, such as replicates of the same experimental group.


(2) 实验-对照特有的峰 bedtools subtract
Finding differences between two peak files, such as control vs. experimental groups, is accomplished via bedtools subtract.






ref:
https://www.jianshu.com/p/f849bd55ac27







========================================
|-- Motif 分析 ( homer )
----------------------------------------
1.Motif富集分析

活性开放的染色质区域通过结合特定的转录因子影响转录，转录因子结合识别的DNA序列成为motif，人体中大约有1600转录因子，其中一半多已经有明确的motif。对motif的分析包括motif富集分析和转录因子的footprint。

目前有很多Motif数据库，其中最普遍的JASPAR数据库，包含了很多物种的数据，可以很容易地通过APIs或Bioconductor的R包获得相关数据。除此之外，CIS-BP和TRANSFAC包含真核转录因子的motif；HOCOMOCO专注于人和小鼠；RegulonDB是E.coli数据。

Motif信息主要以txt文件格式保存，比如位置权重矩阵（as a position weight matrix , PWM）。HOMER、Bioconductor中的TFBSTools和motifmatchr包可以利用PWM搜索特定序列中的motif。PWMScan可以通过网页快速搜索motif。MEME suit里面的FIMO、MAST和MCAST在motif搜索上有不同的应用。MEME suit和PWMScan有网页版本，更容易使用。

得到每个peak region里motif的位置和频率，再和随机背景或其它条件比较，就可以做motif的富集分析。HOMER、MEME-AME、MEME-CentriMo和DAStk分别采用不同的统计检验比较peak和背景区域motif频率的差异。ChromVAR是为单细胞ATAC-seq开发的motif分析工具，把每个细胞当作一个重复。

需要注意的是并时不时所有的TFs都有鉴定好的motif，而同一个家族TFs有类似的motif。在软件选择上，MEME-CentriMo是用的比较多的一个网页应用，可以产生可视化的报告，单细胞ATAC-seq可以选择chromVAR软件。




2. homer 

HOMER is a suite of software designed for motif discovery. It takes a peak file as input and checks for the enrichment of both known sequence motifs and de novo motifs.

http://homer.ucsd.edu/homer/ngs/peakMotifs.html



ATAC分析得到的peak是染色质上的开放区域，这些染色质开放区域常常预示着转录因子的结合，因此对peak区域进行motif分析很有意义。常见的motif分析软件有homer和MEME。以homer软件为例，首先在linux环境中安装homer，然后用以下命令进行motif分析：

findMotifsGenome.pl \
  A1_peaks.bed \ #用于进行motif分析的bed文件
  genome.fa  \ #参考基因组fa文件
  A1  \ #输出文件前缀
  -size  given \ #使用给定的bed区域位置进行分析，如果填-size -100,50则是用给定bed中间位置的上游100bp到下游50bp的区域进行分析


$ findMotifsGenome.pl
	Program will find de novo and known motifs in regions in the genome
	Usage: findMotifsGenome.pl <pos file> <genome> <output directory> [additional options]
	Example: findMotifsGenome.pl peaks.txt mm8r peakAnalysis -size 200 -len 8

homer分析motif的原理及结果参见 http://homer.ucsd.edu/homer/motif/index.html
homer 找motif的原理: https://www.jianshu.com/p/9a31f5f01e7b


示例2: 
findMotifsGenome.pl H3K4Me3.bed hg19 H3K4Me3_motif -len 8,10,12
# peak文件：ChIP-Seq_H3K4Me3_1_homer.bed
# 基因组版本：hg19
# 输出路径：ChIP-Seq_H3K4Me3_1_motifDir
# motif长度：-len 8,10,12 
# motif的软件默认长度为8，10，12
​
-p <#> (Number of processors to use, default: 1) 设置线程数
-S <#> (Number of motifs to optimize, default: 25) 所寻找的motif数目，默认为25。25已经不算少了，如果自定义数目，推荐设置更少而不是更多。








1. 按照bed文件范围分析(start to end)

$ findMotifsGenome.pl \
  macs2/treat_vs_control-shift100-m_peaks.narrowPeak \
  /home/wangjl/data/ref/human/UCSC/hg38.fa  \
  homer/treat_vs_control-bed  \
  -size given


## 报错：
        Peak file looks good!                                 

        Background files for 150 bp fragments found.
!!!! Might have something wrong with preparsed files
!!!! Rerun and add "-preparse" to the command line to force recreation of the files
        Custom genome sequence file: /home/wangjl/data/ref/human/UCSC/hg38.fa.gz

        Scanning input files...
!!! Something is wrong... are you sure you chose the right length for motif finding?
!!! i.e. also check your sequence file!!!


是不是必须解压fasta文件?
## /home/wangjl/data/ref/human/UCSC
$ gunzip -c hg38.fa.gz >hg38.fa
删除刚建立的文件夹 preparsed/
重新运行。
这一次很慢，估计能出结果。
$ ls -lth preparsed/
total 896M
-rw-rw-r-- 1 wangjl wangjl  80M Jun 19 12:07 hg38.fa.93.gcbins
-rw-rw-r-- 1 wangjl wangjl  80M Jun 19 12:07 hg38.fa.93.cgbins
-rw-rw-r-- 1 wangjl wangjl 199M Jun 19 12:07 hg38.fa.93.cgfreq
-rw-rw-r-- 1 wangjl wangjl 375M Jun 19 12:07 hg38.fa.93.seq
-rw-rw-r-- 1 wangjl wangjl 165M Jun 19 12:06 hg38.fa.93.pos



批量化 
$ cat ../raw/SRR_Acc_List.txt | while read id; do echo $id;
findMotifsGenome.pl \
  macs2/${id}_shift100_peaks.narrowPeak \
  /home/wangjl/data/ref/human/UCSC/hg38.fa  \
  homer/${id}  \
  -size given;
done;




测试: 加上参数 -preparse, 后来发现是narrowPeak是空文件时报这个错。
$ findMotifsGenome.pl macs2_result/SRR7629153_peaks.narrowPeak /home/wangjl/data/ref/human/UCSC/hg38.fa homer/SRR7629153_1/ -size given -p 10
## 21:03--> 
$ findMotifsGenome.pl macs2_result/SRR7629153_peaks.narrowPeak /home/wangjl/data/ref/human/UCSC/hg38.fa homer/SRR7629153_1/ -size given -p 10 -preparse
$ findMotifsGenome.pl macs2_result/SRR7629153_peaks.narrowPeak hg38 homer/SRR7629153_2/ -size given -p 10
## 21:07-->





2. 按照 summit 上下游分析(下游100，上游50范围内)

$ findMotifsGenome.pl \
  macs2/treat_vs_control-shift100-m_summits.bed \
  /home/wangjl/data/ref/human/UCSC/hg38.fa  \
  homer_/treat_vs_control-summits  \
  -size  -100,50








3. 可视化

根据motif与已知转录因子的富集情况可以绘制气泡图，从而可以看到样本与已知转录因子的富集显著性。


已知转录因子的富集显著性
x轴为样本标签: A1, A2, B1, B2
Y轴为转录因子名字: JunB, Jun-AP1, Fra2, Fra1, Fosl2, CTCF, Atf3, AP-1
中间是dotplot，直径大小表示 motif enrichment(-logP)






ref:
https://www.jianshu.com/p/4e6b42152694













========================================
|-- 富集分析 //todo
----------------------------------------
通过注释得到的peak相关基因可以使用goseq、topGO等R包进行GO富集分析，用kobas进行kegg富集分析，也可以使用DAVID在线工具来完成富集分析。

可以通过挑选感兴趣的GO term或pathway进一步筛选候选基因。



















========================================
使用snakemake构建 ATAC-seq 分析流程(实例)
----------------------------------------
流程脚本:
https://github.com/crazyhottommy/pyflow-ATACseq

按照include模式写，写成一个就保存一个。



1. 边测试边写，模块化。
(1) fq QC
$ cat main1.sf 
SI=["SRR7629152","SRR7629153"]  

rule all:
	input: 
		"QC_raw/multiqc/multiqc_report.html"

include:"rules/01qc_raw.sf"


####
$ cat rules/01qc_raw.sf 
rule QC_raw_fq:
	input: 
		"raw/s_{sample}_1.fastq.gz",
		"raw/s_{sample}_2.fastq.gz",
	output: 
		"QC_raw/s_{sample}_1_fastqc.html",
		"QC_raw/s_{sample}_2_fastqc.html"
	params:out_dir="QC_raw"
	log: "QC_raw/s_{sample}_fastqc.html.log"
	shell: 
		"fastqc -t 10 {input} -o {params.out_dir} >{log} 2>&1"

rule multi_QC_raw:
	input: expand("QC_raw/s_{sample}_2_fastqc.html", sample=SI)
	output:"QC_raw/multiqc/multiqc_report.html"
	params: 
		in_dir="QC_raw",
		out_dir="QC_raw/multiqc/"
	log: "QC_raw/multiqc/multiqc_report.html.log"
	shell:"multiqc {params.in_dir}/*fastqc.zip -o {params.out_dir} >{log} 2>&1"



$ snakemake -s main1.sf -j3
Job counts:
	count	jobs
	2	QC_raw_fq
	1	all
	1	multi_QC_raw
	4

$ ls QC_raw/ -lth
total 3.8M
drwxrwxr-x 3 wangjl wangjl 4.0K Jun 23 11:24 multiqc
-rw-rw-r-- 1 wangjl wangjl 589K Jun 23 11:24 s_SRR7629152_1_fastqc.html
-rw-rw-r-- 1 wangjl wangjl 582K Jun 23 11:24 s_SRR7629152_2_fastqc.htm




(2) 去接头，然后QC
$ cat main2.sf 
SI=["SRR7629152","SRR7629153"]  

rule all:
	input: 
		"QC_raw/multiqc/multiqc_report.html",
		"QC_clean/multiqc/multiqc_report.html"

include:"rules/01qc_raw.sf"
include:"rules/02cutAdaptor.sf"


$ cat rules/02cutAdaptor.sf
rule cut_adapter:
	input:
		"raw/s_{sample}_1.fastq.gz",
		"raw/s_{sample}_2.fastq.gz",
	output:
		"clean/{sample}_1.fastq.gz",
		"clean/{sample}_2.fastq.gz"
	log:"clean/{sample}_cutapapt.log"
	shell:
		"cutadapt -j 4 --time 1 -e 0.1 -O 3 --quality-cutoff 25 \
		-m 15 -a CTGTCTCTTATA \
		-A AGACGGGAAGAGCGTCGTGAGGGAAGAGTGTAGATCTCGGTGGTCGCGTATCATT \
		-o {output[0]} -p {output[1]} {input[0]} {input[1]} >{log} 2>&1"

rule QC_clean_fq:
	input: 
		"clean/{sample}_1.fastq.gz",
		"clean/{sample}_2.fastq.gz"
	output: 
		"QC_clean/{sample}_1_fastqc.html",
		"QC_clean/{sample}_2_fastqc.html"
	params:out_dir="QC_clean"
	log: "QC_clean/{sample}_fastqc.html.log"
	shell: 
		  "fastqc -t 10 {input} -o {params.out_dir} >{log} 2>&1"

rule multi_QC_clean:
	input: expand("QC_clean/{sample}_2_fastqc.html", sample=SI)
	output:"QC_clean/multiqc/multiqc_report.html"
	params: 
		in_dir="QC_clean",
		out_dir="QC_clean/multiqc/"
	log: "QC_clean/multiqc/multiqc_report.html.log"
	shell:"multiqc {params.in_dir}/*fastqc.zip -o {params.out_dir} >{log} 2>&1"




$ snakemake -s main2.sf -j4
Job counts:
	count	jobs
	2	QC_clean_fq
	1	all
	2	cut_adapter
	1	multi_QC_clean
	6
	
$ ls -lth clean/
total 11M
-rw-rw-r-- 1 wangjl wangjl 2.7M Jun 23 11:25 SRR7629152_1.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 2.7M Jun 23 11:25 SRR7629152_2.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 2.4K Jun 23 11:25 SRR7629152_cutapapt.log






(3) 比对 & sort
$ cat main3.sf 
SI=["SRR7629152","SRR7629153"]  
BWA_INDEX="/home/wangjl/data/ref/human/UCSC/bwa/hg38_fa"

rule all:
	input: 
		"QC_raw/multiqc/multiqc_report.html",
		"QC_clean/multiqc/multiqc_report.html",
		expand("map/{sample}.sort.bam", sample=SI)

include:"rules/01qc_raw.sf"
include:"rules/02cutAdaptor.sf"
include:"rules/03BWA_mapping.sf"


## 仅保存bam，删除sam中间文件。
$ cat rules/03BWA_mapping.sf
rule bwa_mapping:
	input:
		"clean/{sample}_1.fastq.gz",
		"clean/{sample}_2.fastq.gz"
	output:
		temp("map/{sample}_bwa_hg38.sam")
	params: bwa=r"@RG\tID:{sample}\tSM:{sample}"
	threads: 8
	log:"map/{sample}_bwa_hg38.sam.log"
	shell:
		"bwa mem -t {threads} -R '{params.bwa}' -o {output} {BWA_INDEX}  {input} >{log} 2>&1"

rule sort_to_bam:
	input:"map/{sample}_bwa_hg38.sam"
	output:"map/{sample}.sort.bam"
	params: tmp="{sample}_tmp"
	log: "map/{sample}.sort.bam.log"
	shell:"samtools sort -O bam -T {params.tmp} -o {output} {input} >{log} 2>&1"




$ snakemake -s main3.sf -j 4
Job counts:
	count	jobs
	1	all
	2	bwa_mapping
	2	sort_to_bam
	5

$ ls -lth map/
total 15M
-rw-rw-r-- 1 wangjl wangjl 7.0M Jun 23 11:29 SRR7629153.sort.bam
-rw-rw-r-- 1 wangjl wangjl    0 Jun 23 11:29 SRR7629153.sort.bam.log
-rw-rw-r-- 1 wangjl wangjl 1.1K Jun 23 11:29 SRR7629153_bwa_hg38.sam.log
-rw-rw-r-- 1 wangjl wangjl 7.6M Jun 23 11:28 SRR7629152.sort.bam
-rw-rw-r-- 1 wangjl wangjl    0 Jun 23 11:28 SRR7629152.sort.bam.log
-rw-rw-r-- 1 wangjl wangjl 1.1K Jun 23 11:28 SRR7629152_bwa_hg38.sam.log











(4) rm MT, rm dup, rm Low MapQ, then BAM QC (TSS分布图，插入片段长度)
$ cat main4.sf 
SI=["SRR7629152","SRR7629153"]  
BWA_INDEX="/home/wangjl/data/ref/human/UCSC/bwa/hg38_fa"

from snakemake.utils import R

rule all:
	input:
		"QC_raw/multiqc/multiqc_report.html", #fastq QC
		"QC_clean/multiqc/multiqc_report.html",
		
		expand("map_clean/{sample}.final.bam", sample=SI), # 最终的 3次过滤的 bam
		# expand("QC_map/TSS/{sample}.TSS.heatmap.pdf", sample=SI), #BAM QC: TSS (巨慢)
		expand("QC_map/fragment_length/fragment_length_{sample}.pdf", sample=SI) # BAM QC: 片段长度

# 一个小任务有一个输出文件，单线不分叉
include:"rules/01qc_raw.sf"
include:"rules/02cutAdaptor.sf"
include:"rules/03BWA_mapping.sf"
include:"rules/04Bam_filter.sf"
include:"rules/04-2-Bam_QC.sf"



$ cat rules/04Bam_filter.sf
rule index:
	input:"{sample}.bam"
	output:"{sample}.bam.bai"
	shell:"samtools index {input}"

## rm MT
rule get_chrlist:
	input:"map/{sample}.sort.bam"
	output:"map_clean/{sample}.chrlist"
	log:"map_clean/{sample}.chrlist.log"
	shell:"samtools view  {input}| grep -v '^#'| awk '{{print $3}}' \
		| sort | uniq -c| grep -E -v 'GL|KI|JH|KB|chrM' | grep chr | awk '{{print $2}}' | xargs > {output} 2>{log}"

rule del_MT:
	input:"map_clean/{sample}.chrlist", "map/{sample}.sort.bam", "map/{sample}.sort.bam.bai"
	output:"map_clean/{sample}.sort.delMT.bam"
	log:"map_clean/{sample}.sort.delMT.bam.log"
	shell:"samtools view -b {input[1]} `cat {input[0]}` > {output} 2>{log}"

# filter by MAPQ:
# 1 需要不需要按MAPQ过滤？需要，下例bowtie2按照>10过滤的。
# 2 三个过滤怎么排序好？不确定
# 3 怎么设置其他参数?
# https://informatics.fas.harvard.edu/atac-seq-guidelines-old-version.html#alignments
# https://github.com/ENCODE-DCC/atac-seq-pipeline/blob/master/src/encode_task_filter.py
rule rm_low_MAPQ:
	input:"map_clean/{sample}.sort.delMT.bam"
	output:"map_clean/{sample}.sort.delMT.HmapQ.bam"
	shell:"samtools view -bh -q 50 {input} > {output}"

# remove duplicate: 这个放最后的优势是，会自动生成bai文件
rule rm_dup:
	input:"map_clean/{sample}.sort.delMT.HmapQ.bam"
	output:"map_clean/{sample}.final.bam"
	threads: 8
	params:tmp="map_clean/tmp/{sample}"
	log:"map_clean/{sample}.sort.delMT.HmapQ.sambambaRmDup.bam.log"
	shell:"sambamba markdup -r -t {threads} --tmpdir {params.tmp} {input} {output} >{log} 2>&1"



$ cat rules/04-2-Bam_QC.sf
########################
# MAP_QC: 2 target file
########################

## target 1
rule MAP_QC_bamCoverage:
	input: "map_clean/{sample}.final.bam"
	output: "QC_map/{sample}.bw"
	log: "QC_map/{sample}.bw.log"
	shell: "bamCoverage -b {input} -o {output} >{log} 2>&1"

rule MAP_QC_computeMatrix:
	input: "QC_map/{sample}.bw"
	output:"QC_map/matrix/{sample}.mat.gz"
	log: "QC_map/matrix/{sample}.mat.gz.log"
	shell:"computeMatrix reference-point \
       --referencePoint TSS \
       -S {input} \
       -R /home/wangjl/data/ref/human/UCSC/hg38_refseq_whole_gene.bed \
       -b 1000 \
       -a 1000 \
       -o {output} >{log} 2>&1"

rule MAP_QC_plotHeatmap:
	input: "QC_map/matrix/{sample}.mat.gz",
	output:"QC_map/TSS/{sample}.TSS.heatmap.pdf"
	log: "QC_map/TSS/{sample}.TSS.heatmap.pdf.log"
	shell:"plotHeatmap -m {input} -out {output}"

## target 2
rule get_fragment_length:
	input:"map_clean/{sample}.final.bam"
	output:"QC_map/fragment_length/{sample}.fragment.length.txt"
	log:"QC_map/{sample}.fragment.length.txt.log"
	shell:"samtools view {input} | \
		awk -F'\t' 'function abs(x){{return ((x < 0.0) ? -x : x)}} {{print $1\"\t\"abs($9)}}' | \
		sort | uniq | cut -f2 > {output} 2>{log}"

# https://snakemake.readthedocs.io/en/stable/snakefiles/rules.html
root=config["Snk_RootDir"]
rule draw_plot:
	input: 
		"map_clean/{sample}.final.bam",
		"QC_map/fragment_length/{sample}.fragment.length.txt"
	output: "QC_map/fragment_length/fragment_length_{sample}.pdf"
	log: "QC_map/fragment_length/fragment_length_{sample}.pdf.log"
	params: 
		key="{sample}",
		workdir=config["workdir"]
	shell:"Rscript {root}/scripts/plot04_fragment_length.R {input[0]} {output[0]} {params.key} {params.workdir} >{log} 2>&1"

# run 语句如何记录日志? //todo	
#	run: R("""
#		library("ATACseqQC");
#		pdf("{output}", width=5, height=5);
#		fragSizeDist("{input[0]}", "{params.key}")
#		dev.off();
#	""")


## 同时生成pdf和png
$ cat scripts/plot04_fragment_length.R
myArgs<-commandArgs(TRUE)
infile=myArgs[1]
outfile=myArgs[2]
params.key=myArgs[3]

setwd(myArgs[4])

library("ATACseqQC");
pdf(outfile, width=5, height=5);
fragSizeDist(infile, params.key)
dev.off();

outfile2=paste0(substring(outfile, 1, nchar(outfile)-3), "png")
png(outfile2, width=1500, height=1500, res=300);
fragSizeDist(infile, params.key)
dev.off();






$ snakemake -s main4.sf -j 10
Job counts:
        count   jobs
        2       MAP_QC_bamCoverage
        2       MAP_QC_computeMatrix
        2       MAP_QC_plotHeatmap
        1       all
        2       del_MT
        2       draw_plot
        2       get_chrlist
        2       get_fragment_length
        2       index
        2       rm_dup
        2       rm_low_MAPQ
        21
这个很花时间的，可以跳过。
Job counts:
	count	jobs
	1	all
	2	del_MT
	2	draw_plot
	2	get_chrlist
	2	get_fragment_length
	2	index
	2	rm_dup
	2	rm_low_MAPQ
	15










(5) call peak 
$ cat rules/05call_peak.sf
rule call_peak:
	input:
		"map_clean/{sample}.final.bam"
	output:
		"macs2_result/{sample}_peaks.narrowPeak"
	params:
		"{sample}",
		"macs2_result"
	log:
		"macs2_result/{sample}_peaks.narrowPeak.log"
	shell:
		"macs2 callpeak -t {input} -f BAM -g hs \
		--shift -100 --extsize 200 --nomodel \
		-B --SPMR --call-summits \
		--outdir {params[1]} -n {params[0]} >{log} 2>&1"


(6) find motif 
$ cat main6.sf 
SI=["SRR7629152","SRR7629153"]  
BWA_INDEX="/home/wangjl/data/ref/human/UCSC/bwa/hg38_fa"

from snakemake.utils import R

rule all:
	input:
		"QC_raw/multiqc/multiqc_report.html", #fastq QC
		"QC_clean/multiqc/multiqc_report.html",
		
		expand("map_clean/{sample}.final.bam", sample=SI), # 最终的 3次过滤的 bam
		# expand("QC_map/TSS/{sample}.TSS.heatmap.pdf", sample=SI), #BAM QC: TSS (巨慢:40min 1e4 reads)
		expand("QC_map/fragment_length/fragment_length_{sample}.pdf", sample=SI), # BAM QC: 片段长度

		expand("homer/{sample}/knownResults.html", sample=SI)

# 一个小任务有一个输出文件，单线不分叉
include:"rules/01qc_raw.sf"
include:"rules/02cutAdaptor.sf"
include:"rules/03BWA_mapping.sf"
include:"rules/04Bam_filter.sf"
include:"rules/04-2-Bam_QC.sf"

include:"rules/05call_peak.sf"
include:"rules/06homer_find_motif.sf"



$ cat rules/06homer_find_motif.sf
GENOME   ="/home/wangjl/data/ref/human/UCSC/hg38.fa"
## 命令中指定输出目录
rule homer_find_motif: 
	input: "macs2_result/{sample}_peaks.narrowPeak"
	output: "homer/{sample}/knownResults.html"
	params: out_dir="homer/{sample}/"
	log:"homer/{sample}/knownResults.html.log"
	shell:"findMotifsGenome.pl {input} {GENOME} {params.out_dir} -size given >{log} 2>&1"


$ snakemake -s main6.sf -j10
Job counts:
	count	jobs
	1	all
	2	call_peak
	2	homer_find_motif
	5
# 也很慢: 40min
[Wed Jun 23 12:12:15 2021]
[Wed Jun 23 12:52:22 2021]







$ vim test2.sf
GENOME   ="/home/wangjl/data/ref/human/UCSC/hg38.fa"
## 命令中指定输出目录
rule homer_find_motif: 
        input: "macs2_result/{sample}_peaks.narrowPeak"
        output: "homer/{sample}/knownResults.html"
        params: out_dir="homer/{sample}/"
        threads: 4
        log:"homer/{sample}/knownResults.html.log"
        shell:"findMotifsGenome.pl {input} {GENOME} {params.out_dir} -size given -p {threads} -preparse >{log} 2>&1"











$ ls QC_map/fragment_length -lth
total 536K
-rw-rw-r-- 1 wangjl wangjl  12K Jun 23 15:14 fragment_length_SRR7629152.pdf
-rw-rw-r-- 1 wangjl wangjl 1.3K Jun 23 15:14 fragment_length_SRR7629152.pdf.log
-rw-rw-r-- 1 wangjl wangjl  69K Jun 23 15:14 fragment_length_SRR7629152.png



$ ls -lth macs2_result/
total 14M
-rw-rw-r-- 1 wangjl wangjl  213 Jun 23 12:12 SRR7629152_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 3.7M Jun 23 12:12 SRR7629152_control_lambda.bdg
-rw-rw-r-- 1 wangjl wangjl 3.1K Jun 23 12:12 SRR7629152_peaks.narrowPeak.log
-rw-rw-r-- 1 wangjl wangjl 1.5K Jun 23 12:12 SRR7629152_peaks.xls
-rw-rw-r-- 1 wangjl wangjl  145 Jun 23 12:12 SRR7629152_summits.bed
-rw-rw-r-- 1 wangjl wangjl 3.7M Jun 23 12:12 SRR7629152_treat_pileup.bdg
-rw-rw-r-- 1 wangjl wangjl  517 Jun 23 12:12 SRR7629153_peaks.narrowPeak
-rw-rw-r-- 1 wangjl wangjl 3.1K Jun 23 12:12 SRR7629153_peaks.narrowPeak.log
-rw-rw-r-- 1 wangjl wangjl  344 Jun 23 12:12 SRR7629153_summits.bed
-rw-rw-r-- 1 wangjl wangjl 3.0M Jun 23 12:12 SRR7629153_control_lambda.bdg
-rw-rw-r-- 1 wangjl wangjl 1.8K Jun 23 12:12 SRR7629153_peaks.xls
-rw-rw-r-- 1 wangjl wangjl 3.1M Jun 23 12:12 SRR7629153_treat_pileup.bdg















## check
$ cat map_clean/SRR7629152.chrlist
chr1 chr10 chr11 chr12 chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr2 chr20 chr21 chr22 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chrX chrY


$ samtools view  map_clean/SRR7629153.final.bam | awk '{print $5}'  | sort |uniq -c | sort -k1nr
  98375 60
  17016 0
   1586 40
    510 27
    461 57
$ samtools view -q 60 map_clean/SRR7629153.final.bam  | wc
  98375 1674485 19435299










========================================
|-- 最终版，及最佳实践
----------------------------------------
2. 最终版
$ cp main6.sf main.sf
(1) 使用配置文件

第一行改为完整版
SI=["SRR7629152","SRR7629153","SRR7629154", "SRR7629161", "SRR7629162", "SRR7629163"]


$ cat config.yaml #格式有严格要求: 逗号后有空格, 冒号后有空格，不需要加引号了。
samples: [SRR7629152, SRR7629153, SRR7629154, SRR7629161, SRR7629162, SRR7629163]
workdir: /home/wangjl/data/ATAC/fq/test3
Snk_RootDir: /home/wangjl/soft/snakemakeWorkflow/ATAC-seq/demo1



snake脚本中引用
$ cat test.sf
configfile: "config.yaml"
workdir: config["workdir"]

SI=config["samples"]







(2) 生成总的流程图
$ mkdir images
$ snakemake -s main.sf --dag | dot -Tsvg > images/ATAC-seq_Sample.svg
$ snakemake -s main.sf --rulegraph 2> /dev/null | dot -Tsvg > images/ATAC-seq_Rule.svg



$ cat rules/getWorkflow.sf
root=config["Snk_RootDir"]

rule cp_config:
	output:temp("config.yaml")
	message: "cp config file from snakeRoot to workdir"
	shell:"cp {root}/config.yaml {output}"

rule get_workflow_dag:
	input:"config.yaml"
	output:
		"images/ATAC-seq_Sample.svg",
		"images/ATAC-seq_Rule.svg"
	shell:
		"snakemake -s {root}/main.sf --dag | dot -Tsvg > {output[0]} && "
		"snakemake -s {root}/main.sf --rulegraph 2> /dev/null | dot -Tsvg > {output[1]}"


# 测试
$ cat test2.sf
configfile:"config.yaml"
include:"rules/getWorkflow.sf"
workdir: config['workdir']

rule all:
	input:"images/ATAC-seq_Sample.svg"


## 必须把 config.yaml 放到工作目录，才能画流程图。原理是啥呢？
$ snakemake -s test2.sf -j 1
Job counts:
	count	jobs
	1	all
	1	cp_config
	1	get_workflow_dag
	3






(3) 把中间特别慢的BAM质控部分单独调用。
(4) 生成报告html文件，可在浏览器中看的。
$ vim getReport.sf 
configfile: "config.yaml"
workdir: config["workdir"]

SI=config["samples"]

#SI=["SRR7629152","SRR7629153"]

rule all:
	input: 
		expand("QC_map/TSS/{sample}.TSS.heatmap.pdf", sample=SI), #BAM QC: TSS (very slow:40min 1e4 reads)
		"report/index.html"

include:"rules/04-2-Bam_QC.sf"
include:"rules/getWorkflow.sf"
include:"rules/report.sf"




###### 其他文件

$ cat rules/report.sf
# SI=["SRR7629152","SRR7629153"]
rule report:
	input:
		"images/ATAC-seq_Rule.svg"
	output:"report/index.html"
	run: 
		import time
		timsString=time.strftime("%Y/%m/%d %H:%M:%S", time.localtime()) 

		head='''
<meta charset="utf-8" />
<style>
.content{width:800px; margin:10px auto;}
h2{
	font-style: normal;
	padding-left: 20px;
	padding-right: 20px;
	margin: 10px 0;
	border-bottom: 1px solid #d3d3d3;
	font-size: 25px;
	background-image: linear-gradient(to bottom,#f3f3f3 0,#e3e3e3 100%);
	border-radius: 5px;
}
h3{
	padding: 5px 10px;
    font-size: 20px;
    text-shadow: 0 0 1px #999;
    color: #333;
    border-bottom: 1px solid #D9D9D9;
    font-weight: bold;
    margin-top: 10px;
}
.content a {
    color: #0593d3;
    text-decoration: none;
}
.h200{
	height:200px;
}
.footer{color: #aaa; background:black; border-top:20px; padding: 20px; border-top:1px solid black;}
</style>
		<title>ATAC-seq Report</title>
		'''
		
		workflow="<div class='content'><h1>ATAC-seq Report</h1>"+ timsString + "<br>" + \
		"<h2>Workflow</h2> <h3>Rules</h3>  <image class=h200 src='../images/ATAC-seq_Rule.svg'>" +\
		"<h3>Samples</h3>  <image class=h200 src='../images/ATAC-seq_Sample.svg'><br>"
		
		files='<h2>Output</h2><h3>raw/</h3> Raw fastq file' +\
		'<h3>QC_raw/</h3> <a target="_blank" href="../QC_raw/multiqc/multiqc_report.html">report</a>, <a href="../QC_raw/multiqc/multiqc_report.html.log">log</a>' +\
		'<h3>clean/</h3> fastq files after cut adaptor ' +\
		'<h3>QC_clean/</h3> <a target="_blank" href="../QC_clean/multiqc/multiqc_report.html">report</a>, <a target="_blank" href="../QC_clean/multiqc/multiqc_report.html.log">log</a>'+\
		'<h3>map/</h3> bam files after BWA mapping to hg38 '+\
		'<h3>map_clean/</h3> bam files after rm MT, low MAPQ, duplicates.'+\
		'<h3>QC_map/</h3>'+\
		'	<p>QC_map/fragment_length/: 插入片段长度分布图 barplot (pdf files) of fragment length distribution</p>%s'+\
		'	<p>QC_map/TSS/: TSS附近reads 热图。 heatmap 可选 运行巨慢。</p>%s'+\
		'<h3>macs2_result/</h3> .narrowPeak for each file.%s' +\
		'<h3>homer/</h3> motif results. %s</div>'
		
		footer="<div class=footer><div class='content'> Sample number: "+ str(len(SI)) +"<br> The end | "+timsString+" </div></div>"
		
		#################
		# get BAM QC links
		#################
		fragLen="<hr>Click and View <ul>"
		pngs=""
		for i in SI:
			fnames="<li><a href='../QC_map/fragment_length/fragment_length_%s.pdf'>fragment_length_%s.pdf</a>, <a href='../QC_map/fragment_length/%s.fragment.length.txt'>%s.fragment.length.txt</a></li>" % (i,i, i,i)
			fragLen += fnames
			#
			pngs+="<img class=h200 src='../QC_map/fragment_length/fragment_length_%s.png'>" % i;
		fragLen+="</ul>"+pngs
		
		
		TSS="<hr>Click and View <ul>"
		for i in SI:
			fnames="<li><a href='../QC_map/TSS/%s.TSS.heatmap.pdf'>%s.TSS.heatmap.pdf</a></li>" % (i,i)
			TSS += fnames
		TSS+="</ul>"
		
		#################
		# get macs results links
		#################
		macs2="<hr>Download <ul>"
		for i in SI:
			fnames="<li><a href='../macs2_result/%s_peaks.narrowPeak'>%s_peaks.narrowPeak</a>, <a href='../macs2_result/%s_peaks.xls'>%s_peaks.xls</a>, <a href='../macs2_result/%s_summits.bed'>%s_summits.bed</a></li>" % (i,i, i,i, i,i)
			macs2 += fnames
		macs2+="</ul>"
		
		#################
		# get homer result
		#################
		homer="<hr>Click and View<ul>"
		for i in SI:
			fnames="<li><a href='../homer/%s/knownResults.html'>%s knownResults.html</a>, <a href='../homer/%s/homerResults.html'>%s homerResults.html</a>,</li>" % (i,i, i,i)
			homer += fnames
		homer+="</ul>"
		
		
		files=files % (fragLen, TSS, macs2, homer)
		
		html=head+workflow+ files+footer;
		
		# save
		fw=open( output[0],'w')
		fw.write(html)
		fw.close()
#


$ snakemake -s getReport.sf -j 4
Job counts:
	count	jobs
	2	MAP_QC_bamCoverage
	2	MAP_QC_computeMatrix
	2	MAP_QC_plotHeatmap
	1	all
	7
耗时 22min，2个样本。
[Wed Jun 23 13:04:42 2021]
[Wed Jun 23 13:22:41 2021]







3. 其他修改与测试

(1) 测试文件全局运行
$ snakemake -s main.sf -j2
Job counts:    
        count   jobs   
        4       QC_fq
        1       all       
        4       bwa_mapping
        6       call_peak                                          
        4       cut_adapter                                         
        4       del_MT                
        4       draw_plot
        4       get_chrlist     
        4       get_fragment_length
        6       homer_find_motif
        4       index
        4       rm_dup
        4       rm_low_MAPQ
        4       sort_to_bam
        57
[Tue Jun 22 22:52:13 2021] to 
[Wed Jun 23 02:02:52 2021]
6个小样本: 去掉了 BAM heatmap 支线，全程只需要 3 h 多

需要看的结果文件
$ ls QC_map/fragment_length/ 片段长度的pdf
$ head homer/SRR7629152/knownResults.html 富集已知motif的报告




(2) 实验文件修改名字，和正式一致。 准备正式开始
$ cat ../../../raw/SRR_Acc_List.txt | while read id; do echo $id; 
mv s_${id}_1.fastq.gz ${id}_1.fastq.gz;
mv s_${id}_2.fastq.gz ${id}_2.fastq.gz;
done

$ ls -lth
total 36M
-rw-rw-r-- 1 wangjl wangjl 3.1M Jun 22 21:54 SRR7629163_2.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 3.0M Jun 22 21:54 SRR7629163_1.fastq.gz

$ ls -lth ../../../raw/
total 13G
-rw-rw-r-- 1 wangjl wangjl 1.3G Jun 18 00:09 SRR7629163_2.fastq.gz
-rw-rw-r-- 1 wangjl wangjl 1.3G Jun 18 00:09 SRR7629163_1.fastq.gz


删除其他文件夹。
$ ls | grep -v '^raw$' | xargs -i rm -rf {}


(3) 删除代码中的 s_ 前缀
$ find . | xargs grep "s_{" --color=auto
grep: .: Is a directory
grep: ./rules: Is a directory
./rules/01qc_raw.sf:		"raw/s_{sample}_1.fastq.gz",
./rules/01qc_raw.sf:		"raw/s_{sample}_2.fastq.gz",
./rules/01qc_raw.sf:		"QC_raw/s_{sample}_1_fastqc.html",
./rules/01qc_raw.sf:		"QC_raw/s_{sample}_2_fastqc.html"
./rules/01qc_raw.sf:	log: "QC_raw/s_{sample}_fastqc.html.log"
./rules/01qc_raw.sf:	input: expand("QC_raw/s_{sample}_2_fastqc.html", sample=SI)

./rules/02cutAdaptor.sf:		"raw/s_{sample}_1.fastq.gz",
./rules/02cutAdaptor.sf:		"raw/s_{sample}_2.fastq.gz",



(4) images 文件夹放到 report/ 下。
$ find . | grep -v ".snakemake"| xargs grep "images/" --color=auto 2>/dev/null
./rules/report.sf:		"images/ATAC-seq_Rule.svg"
./rules/report.sf:		"<h2>Workflow</h2> <h3>Rules</h3>  <image class=h200 src='../images/ATAC-seq_Rule.svg'>" +\
./rules/report.sf:		"<h3>Samples</h3>  <image class=h200 src='../images/ATAC-seq_Sample.svg'><br>"
./rules/getWorkflow.sf:		"images/ATAC-seq_Sample.svg",
./rules/getWorkflow.sf:		"images/ATAC-seq_Rule.svg"

./test2.sf:	input:"images/ATAC-seq_Sample.svg"


(5) 把 BAM QC 部分移到 main.sf 中。
最后的报告就很快了。报告也可以移动进去。

	"report/index.html"

include:"rules/04-2-Bam_QC.sf"
include:"rules/getWorkflow.sf"
include:"rules/report.sf"

整个流程的报告图如下:
$ snakemake -s getReport.sf -j 1 -F


(6) fastqc -t {threads}
threads: 8

$ find . | grep "sf$" | xargs grep "fastqc " --color=auto
./rules/01qc_raw.sf:		"fastqc -t 10 {input} -o {params.out_dir} >{log} 2>&1"
./rules/02cutAdaptor.sf:		  "fastqc -t 10 {input} -o {params.out_dir} >{log} 2>&1"



(7) 给 samtools 添加多线程
$ find . | grep "sf$" | xargs grep "samtools " --color=auto
./rules/04-2-Bam_QC.sf:	shell:"samtools view {input} | \
./rules/04Bam_filter.sf:	shell:"samtools index {input}"
./rules/04Bam_filter.sf:	shell:"samtools view  {input}| grep -v '^#'| awk '{{print $3}}' \
./rules/04Bam_filter.sf:	shell:"samtools view -b {input[1]} `cat {input[0]}` > {output} 2>{log}"
./rules/04Bam_filter.sf:	shell:"samtools view -bh -q 50 {input} > {output}"
./rules/03BWA_mapping.sf:	shell:"samtools sort -O bam -T {params.tmp} -o {output} {input} >{log} 2>&1"

threads: 4
-@ {threads}



(8) findMotifsGenome.pl -p 20 添加多线程
$ find . | grep "sf$" | xargs grep "findMotifsGenome" --color=auto
./rules/06homer_find_motif.sf:	shell:"findMotifsGenome.pl {input} {GENOME} {params.out_dir} -size given >{log} 2>&1"


Usage: findMotifsGenome.pl <pos file> <genome> <output directory> [additional options]
        Example: findMotifsGenome.pl peaks.txt mm8r peakAnalysis -size 200 -len 8

findMotifsGenome.pl peaks.txt mm8r peakAnalysis -size 200 -len 8

"findMotifsGenome.pl {input} {GENOME} {params.out_dir} -size given -p {threads} >{log} 2>&1"


所有的选项都在最后添加，否则会出错。
-p <#> (Number of processors to use, default: 1)



(9) 怎么解决dag画流程图问题?
嗯，直接在工作目录下建立，就可以直接画图。
配置文件会不会被删掉？大概率不会，需要测试。
还真被删除了。怎么办？只能把temp()去掉了。




(10) cutadapt -j 4 
$ find . | grep "sf$" | xargs grep "cutada" --color=auto
./rules/02cutAdaptor.sf:		"cutadapt -j 4 --time 1 -e 0.1 -O 3 --quality-cutoff 25 \









4. 测试
(1)6个完全样本:
$ snakemake -s main.sf -j 8
Building DAG of jobs...                                        
Using shell: /bin/bash                                              
Provided cores: 8                     
Rules claiming more threads will be scaled down.
Job counts:                     
        count   jobs
        6       MAP_QC_bamCoverage
        6       MAP_QC_computeMatrix
        6       MAP_QC_plotHeatmap
        6       QC_clean_fq                                    
        6       QC_raw_fq                                           
        1       all                   
        6       bwa_mapping
        6       call_peak       
        6       cut_adapter
        6       del_MT
        6       draw_plot
        6       get_chrlist
        6       get_fragment_length
        6       homer_find_motif
        6       index
        1       multi_QC_clean
        1       multi_QC_raw
        6       rm_dup
        6       rm_low_MAPQ
        6       sort_to_bam
        105
#
[Wed Jun 23 20:35:59 2021] 开始
[Wed Jun 23 22:53:40 2021] 晚上走之前，37 of 105 steps (35%) done。map还没结束。

[Thu Jun 24 05:39:03 2021] 早上过来，  78 of 105 steps (74%) done，QC_map/matrix
[Thu Jun 24 09:50:30 2021] 中午吃饭前  94 of 105 steps (90%) done，MAP_QC_plotHeatmap
[Thu Jun 24 13:32:22 2021]  最后一个文件不知道为什么这么慢？     103 of 105 steps (98%) done

[Thu Jun 24 16:43:37 2021]  105 of 105 steps (100%) done
一共运行了 20h 多。
晚8:35-半夜0点 3.5h
0点-16:43      16.7h
Complete log: /data/wangjl/soft/snakemakeWorkflow/ATAC-seq/demo1/.snakemake/log/2021-06-23T203559.284905.snakemake.log






(2) 修订后的测试，2个小样本
直接在工作目录下建立配置文件。
$ cd /home/wangjl/data/ATAC/fq/test4
$ cat config.yaml
samples: [SRR7629152, SRR7629153] #, SRR7629154, SRR7629161, SRR7629162, SRR7629163]
workdir: /home/wangjl/data/ATAC/fq/test4
Snk_RootDir: /home/wangjl/soft/snakemakeWorkflow/ATAC-seq/demo1

$ ls -l
total 8
-rw-rw-r-- 1 wangjl wangjl  191 Jun 24 15:29 config.yaml
drwxrwxr-x 2 wangjl wangjl 4096 Jun 23 19:59 raw


$ snakemake -s /home/wangjl/soft/snakemakeWorkflow/ATAC-seq/demo1/main.sf -np

$ snakemake -s /home/wangjl/soft/snakemakeWorkflow/ATAC-seq/demo1/main.sf -j 8
Job counts:
        count   jobs
        2       MAP_QC_bamCoverage
        2       MAP_QC_computeMatrix
        2       MAP_QC_plotHeatmap
        2       QC_clean_fq
        2       QC_raw_fq
        1       all
        2       bwa_mapping
        2       call_peak
        2       cut_adapter
        2       del_MT
        2       draw_plot
        2       get_chrlist
        2       get_fragment_length
        1       get_workflow_dag
        2       homer_find_motif
        2       index
        1       multi_QC_clean
        1       multi_QC_raw
        1       report
        2       rm_dup
        2       rm_low_MAPQ
        2       sort_to_bam
        39
17:12 --> 17:49, 共37min;
Complete log: /data/wangjl/ATAC/fq/test4/.snakemake/log/2021-06-24T171243.266321.snakemake.log

如果出错，删掉重来。
$ ls | grep -v '^raw$' | xargs -i rm -rf {}




Building DAG of jobs...
Error: Directory cannot be locked. This usually means that another Snakemake instance is running on this directory. Another possibility is that a previous run exited unexpectedly.
[Thu Jun 24 17:12:45 2021]

翻译：无法锁定目录。请确保没有其他Snakemake进程尝试在下面的目录中创建相同的文件
问题所在：之前这个目录下已经执行过其他的 snakemake 命令了。

解决办法也直接给出来了：
If you are sure that no other instances of snakemake are running on this directory, the remaining lock was likely caused by a kill signal or a power loss. It can be removed with the --unlock argument.

在这个目录下执行: snakemake --unlock






此后的修订记录在单独的库中:
https://github.com/DawnEve/snakemakeWorkflow

ref: https://github.com/snakemake-workflows








========================================
Hair project (Run by ATAC-seq workflow version v0.3)
----------------------------------------
1. 共96个文件
$ cd /home/wangjl/data/ATAC/hair
$ ls -lth raw/origin | head
total 3.0G
-r--r--r-- 1 wangjl wangjl  65M Jun 24 19:09 cgm-9_R2.fastq.gz
-r--r--r-- 1 wangjl wangjl  67M Jun 24 19:09 cgm-9_R1.fastq.gz

cgm-1_R2.fastq.gz
cgm-96_R2.fastq.gz


$ seq 1 4
1
2
3
4


(1) 写配置文件
$ path1="/home/wangjl/data/ATAC/hair/raw/origin/"
$ seq 1 96 | while read i; do 
id="cgm-"${i};
echo $id; 
ln -s ${path1}/${id}_R1.fastq.gz raw/${id}_1.fastq.gz;
ln -s ${path1}/${id}_R2.fastq.gz raw/${id}_2.fastq.gz;
echo $id >>raw/cid.txt
done;


$ zcat raw/cgm-2_1.fastq.gz | head
@A00582:646:H7CJTDSX2:4:1101:27534:1141 1:N:0:CTAAACGG+AGAGGATA
CTTATACACATCTCCGAGCCCACGAGACCTAAACGGATCTCGGATGCCGTCTTGGGCGTGGAAAGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
+
FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF,:F,,:,,,F,,,,,,F,,,F,,,,,,:::FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF


$ cp raw/cid.txt config.yaml
$ sed -i "s/^/ - /" config.yaml

$ vim config.yaml ###add three lines on top
workdir: /home/wangjl/data/ATAC/hair
Snk_RootDir: /home/wangjl/soft/snakemakeWorkflow/ATAC-seq/demo1
samples: 

$ vim test.sf 
configfile:"config.yaml"
SI=config["samples"]
print(SI[1:10])

$ snakemake -s test.sf -j 1
['cgm-2', 'cgm-3', 'cgm-4', 'cgm-5', 'cgm-6', 'cgm-7', 'cgm-8', 'cgm-9', 'cgm-10']


## dry run:
$ snakemake -s /home/wangjl/soft/snakemakeWorkflow/ATAC-seq/demo1/main.sf -np

$ snakemake -s /home/wangjl/soft/snakemakeWorkflow/ATAC-seq/demo1/main.sf -j 8
Job counts:
	count	jobs
	96	MAP_QC_bamCoverage
	96	MAP_QC_computeMatrix
	96	MAP_QC_plotHeatmap
	96	QC_clean_fq
	96	QC_raw_fq
	1	all
	96	bwa_mapping
	96	call_peak
	96	cut_adapter
	96	del_MT
	96	draw_plot
	96	get_chrlist
	96	get_fragment_length
	1	get_workflow_dag
	96	homer_find_motif
	96	index
	1	multi_QC_clean
	1	multi_QC_raw
	1	report
	96	rm_dup
	96	rm_low_MAPQ
	96	sort_to_bam
	1637
[Thu Jun 24 19:44:31 2021]



[Thu Jun 24 20:32:12 2021]
rule MAP_QC_computeMatrix:
    input: QC_map/cgm-57.bw
    output: QC_map/matrix/cgm-57.mat.gz
    log: QC_map/matrix/cgm-57.mat.gz.log
    jobid: 1132
    wildcards: sample=cgm-57

Waiting at most 5 seconds for missing files.
MissingOutputException in line 3 of /home/wangjl/soft/snakemakeWorkflow/ATAC-seq/demo1/rules/06homer_find_motif.sf:
Job Missing files after 5 seconds:
homer/cgm-57/knownResults.html
This might be due to filesystem latency. If that is the case, consider to increase the wait time with --latency-wait.
Job id: 1555 completed successfully, but some output files are missing. 1555
  File "/home/wangjl/.local/lib/python3.6/site-packages/snakemake/executors/__init__.py", line 589, in handle_job_success
  File "/home/wangjl/.local/lib/python3.6/site-packages/snakemake/executors/__init__.py", line 259, in handle_job_success


发现macs2峰是0行。
往前找发现bam还是有的。反复尝试macs参数都不行，往前把MAPQ过滤bam的功能去掉-q 0，再跑就正常了。





(2) 看reads/cell 

$ ls -lth raw/|head
total 16K
-rw-rw-r-- 1 wangjl wangjl 663 Jun 24 19:36 cid.txt
lrwxrwxrwx 1 wangjl wangjl  58 Jun 24 19:35 cgm-96_1.fastq.gz -> /home/wangjl/data/ATAC/hair/raw/origin//cgm-96_R1.fastq.gz
lrwxrwxrwx 1 wangjl wangjl  58 Jun 24 19:35 cgm-96_2.fastq.gz -> /home/wangjl/data/ATAC/hair/raw/origin//cgm-96_R2.fastq.gz


$ cat raw/cid.txt | head -n 2 | while read id; do echo $id; done;
cgm-1
cgm-2

$ cat raw/cid.txt | while read id; do 
R1=`zcat raw/${id}_1.fastq.gz | grep "^+" |wc -l`
echo $id $R1 >> readsPerCell.txt; 
done;

使用R画图。
只保留reads数超过 0.02e6=2万 reads的才保留。






========================================
----------------------------------------







========================================
----------------------------------------










