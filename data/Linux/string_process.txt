linux文本处理

linux shell文本处理三大利器：
grep 查找
sed 行编辑器
awk 列文本处理工具
一行指令，轻松搞定。

========================================
概述与资源
----------------------------------------
gerp 查找, awk 根据内容分析并处理, sed 编辑.
(1)grep, egrep, fgrep, rgrep - print lines matching a pattern 打印匹配模式的行。
(2)awk(关键字:分析&处理) 一行一行的分析处理。
mawk - pattern scanning and text processing language模式扫描与文本处理语言。
(3)sed(关键字: 编辑) 以行为单位的文本编辑工具 
sed - stream editor for filtering and transforming text 用于过滤和转换文本的流编辑器。特色是该编辑器能用于pipeline中。

awk和sed简明教程：
	http://agetouch.blog.163.com/blog/static/228535090201732824532207/

AWK 简明教程: http://coolshell.cn/articles/9070.html
sed 简明教程: http://coolshell.cn/articles/9104.html
三十分钟学会AWK: https://segmentfault.com/a/1190000007338373


========================================
grep 查找与正则表达式
----------------------------------------
正则规则：http://blog.csdn.net/newthinker_wei/article/details/8219293

1.grep(关键字: 截取) 文本搜集工具, 结合正则表达式非常强大。
一般格式： grep 正则 fileName
比如： $ grep 'wangjl' /etc/passwd #查找并返回passwd文件中包含wangjl的行。

主要参数 []
	-c : 只输出匹配的行
	-I : 不区分大小写
	-h : 查询多文件时不显示文件名
	-l : 查询多文件时, 只输出包含匹配字符的文件名
	-n : 显示匹配的行号及行
	-v : 显示不包含匹配文本的所有行
	
基本工作方式: grep 要匹配的内容 文件名
例如:
grep 'test' d* 显示所有以d开头的文件中包含test的行
grep 'test' aa bb cc 显示在 aa bb cc 文件中包含test的行
grep '[a-z]\{5}\' aa 显示所有包含字符串至少有5个连续小写字母的串


2.正则表达式分类：
1)基本的正则表达式（Basic Regular Expression 又叫 Basic RegEx  简称 BREs）
2)扩展的正则表达式 -E（Extended Regular Expression 又叫 Extended RegEx 简称 EREs）
3)Perl 的正则表达式 -P（Perl Regular Expression 又叫 Perl RegEx 简称 PREs）
 说明：只有掌握了正则表达式，才能全面地掌握 Linux 下的常用文本工具（例如：grep、egrep、GUN sed、 Awk 等） 的用法
注意：linux的正则支持有三种，其中perl兼容的是功能最强大的。
默认的是基本的正则，不支持数字元字符，但是加上-P指定Perl兼容的正则，就支持数字元字符了。

$ grep -P '\d' /etc/passwd #任何带数字的行
		\d: 任何数字 [0-9] grep默认不支持
		\D: 任何非数字[^0-9] grep默认不支持



3.正则表达式的数量词
正则表达式可能被以下重复修饰符中的一个修饰：
    ?      {0,1}The preceding item is optional and matched at most once.
    *      {0,}The preceding item will be matched zero or more times.
    +      {1,}The preceding item will be matched one or more times.
    {n}    The preceding item is matched exactly n times.
    {n,}   The preceding item is matched n or more times.
    {,m}   The  preceding  item  is matched at most m times.  This is a GNU extension.
    {n,m}  The preceding item is matched at least n  times,  but  not  more than m times.
比如：$ grep 'ro*t' /etc/passwd   # {0,}表示0个或多个o。


$ cd /etc
$ grep 'ro+t' passwd   #啥也没有
$ grep -P 'ro+t' passwd #使用Perl兼容的可以-P
root:x:0:0:root:/root:/bin/bash

$ grep 'ro\+t' passwd #或者使用转义字符\
root:x:0:0:root:/root:/bin/bash


4.正则的分组()
使用小括号()，默认需要加转义字符\(text\)
如果加入-P参数，则可以直接输入(text)

$ grep -P '(34)+' passwd #带有1个及以上34的行



5.范围
[]表示范围，比如
	[0-9]表示任意一位数字，等价于\d
	[a-z]任意一个小写字母，
	[A-Z]任意大写字母，
	[a-zA-Z]任意字母
[]内的^表示否定。
$ grep -P "[0-9]{4,6}" passwd # 含4到6个数字的行
$ grep -P "[^0-9]" passwd #匹配含有非数字的行
$ grep -P "[^0-9a-zA-Z]" passwd #匹配含有非数字、非大小写字母的行





6.位置界定^$
 ^首位
 $结尾
$ grep '^c.*e$' passwd #找c开头，e结尾的行




7.任意字符串 .* # .在[]外表示任意字符，*表示前面字符任意多个，加起来.*就是任意字符串了。
$ grep -P '^r.*' passwd #r开头，后面跟着任意字符
$ grep -P 'm.*c' passwd #m后面有c的行，默认贪婪匹配，匹配尽量后的c

如果想使用非贪婪匹配，找到最近的c就停止匹配，可以首尾加上分隔符\b 
$ grep -P '\bm.*c\b' passwd





8.贪婪匹配
更好的非贪婪匹配是量词后加上?
当"?"字符紧跟在任何一个其他限制符（*,+,?，{n}，{n,}，{n,m}）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少的匹配所搜索的字符串，而默认的贪婪模式则尽可能多的匹配所搜索的字符串。例如，对于字符串“oooo”，“o+?”将匹配单个“o”，而“o?”将匹配所有“o”。

注：非贪婪只对量词有效果，如 * + {1，9} 等。
默认是贪婪模式；在量词后面直接加上一个问号？就是非贪婪模式。

$ grep -P 'm.*?c' passwd #从每行的m开始，找到第一个c停止
$ echo 12,23,24|grep -P '([0-9]\d{1,})' 
$ echo 12,23,24|grep -P '([0-9]\d{1,}?)' 




9.其他细节
\s	匹配任何空白字符，包括空格、制表符、换页符等等。等价于[ \f\n\r\t\v]。
\S	匹配任何非空白字符。等价于[^ \f\n\r\t\v]。










========================================
awk(关键字:分析&处理) 一行一行的分析处理
----------------------------------------
gawk是awk的增强版，如果有些教程中的awk命令不能运行，请考虑安装gawk。
$ sudo apt install gawk


1.定义与作用
mawk - pattern scanning and text processing language模式扫描与文本处理语言。
An AWK program is a sequence of pattern {action} pairs and user function definitions.

典型用途：使用AWK可以做很多任务，下面是其中一些
	文本处理
	输出格式化的文本报表
	执行算数运算
	执行字符串操作等等







2.工作流
要成为AWK编程专家，你需要先知道它的内部实现机制，AWK遵循了非常简单的工作流 - 读取，执行和重复，下图描述了AWK的工作流。
(1)BEGIN block: BEGIN {awk-commands} #可选
(2)Read a line from input stream
(3)Execute AWK commands on a line: /pattern/ {awk-commands}
(4)Repeat if it is not End of file,GOTO(2)
(5)END block: END {awk-commands} #可选

awk的处理流程是:
1) 读第一行, 将第一行资料填入变量 $0, $1... 等变量中
2) 依据条件限制, 执行动作
3) 接下来执行下一行









3.一般格式：$ awk 'pattern1{动作1}pattern2{动作2}' filename
	awk 也可以读取来自前一个指令的 standard input。
	相对于sed常常用于一整行处理, awk则比较倾向于一行当中分成数个"字段"(区域)来处理, 默认的分隔符是空格键或tab键

示例文件marks.txt
$ cat marks.txt
1)  Amit    Physics  80
2)  Rahul   Maths    90
3)  Shyam   Biology  87
4)  Kedar   English  85
5)  Hari    History  89


示例文件netstat.txt。
$ netstat -na |head -n 16 > netstat.txt
$ ls #用vim删掉第一行
netstat.txt
$ cat netstat.txt
Proto Recv-Q Send-Q Local Address           Foreign Address         State
tcp        0      0 127.0.1.1:53            0.0.0.0:*               LISTEN
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN
tcp        0     36 172.16.112.86:22        172.16.113.174:55033    ESTABLISHED
tcp        0      0 172.16.112.86:22        172.16.113.174:56000    ESTABLISHED
tcp6       0      0 :::22                   :::*                    LISTEN
tcp6       0      0 :::3306                 :::*                    LISTEN
udp        0      0 127.0.1.1:53            0.0.0.0:*
udp        0      0 0.0.0.0:68              0.0.0.0:*
udp        0      0 0.0.0.0:631             0.0.0.0:*
udp        0      0 0.0.0.0:55418           0.0.0.0:*
udp        0      0 0.0.0.0:5353            0.0.0.0:*
udp6       0      0 :::58832                :::*
udp6       0      0 :::5353                 :::*
raw6       0      0 :::58                   :::*                    7



(1)可以用 $ awk '{print}' marks.txt 来代替cat命令，查看文件内容。

awk可以接受标准输入的数据，例如:$ last -n 5 | awk '{print $1 "\t" $3}'  #输入最后5次登陆，只显示用户名和ip。
这里大括号内$1"\t"$3 之间不加空格也可以, 不过最好还是加上个空格, 另外注意"\t"是有双引号的, 因为本身这些内容都在单引号内
$0 代表整行 $1代表第一个区域, 依此类推

#打印第3和4列，用制表符隔开:
$ awk '{print $3 "\t" $4}' marks.txt
Physics 80
Maths   90
Biology 87
English 85
History 89

所以, AWK一次处理是一行, 而一次中处理的最小单位是一个区域。

$ awk '/a/{print $0}' marks.txt 可以简化为
$ awk '/a/{print}' marks.txt 可以进一步简化为
$ awk '/a/' marks.txt 没有制定操作，就是默认打印匹配到的整行。
2)  Rahul   Maths    90
3)  Shyam   Biology  87
4)  Kedar   English  85
5)  Hari    History  89



(2)逻辑判断 > < >= <= == !== , 赋值直接使用=

另外还有3个变量, 
	NF: 当前行的第几个字段(number of fields in the current record). 每个字段保存在$1, $2, ..., $NF中.  The built-in variable NF is set to the number of fields.
	NR 目前处理到第几行(current record number in the total input stream).
	FS 目前的分隔符(input record separator, initially = "\n").

	
例1 $ cat /etc/passwd | awk '{FS=":"} $3<10 {print $1 "\t" $3}'
首先定义分隔符为:, 
然后判断, 注意看, 判断没有写在{}中, 
然后执行动作, 
FS=":"这是一个动作, 赋值动作, 不是一个判断, 所以写在{}中

$  awk  'BEGIN{FS=":"} {print $1,$3,$6}' /etc/passwd
也等价于：（-F的意思就是指定分隔符）
$ awk  -F: '{print $1,$3,$6}' /etc/passwd

注：如果你要指定多个分隔符，你可以这样来：
awk -F '[;:]'




例2 $ awk '/linux/ {print NR}' out.txt #将带有linux的行的行号打印出来, 注意//之间可以使用正则表达式
$ cat out.txt
this is a linux system.
line2
Ubuntu is a release of linux.
$ awk '/linux/ {print NR}' out.txt
1
3


例3：&&并的使用。显示第3列是0且第6列是LISTEN的行。
$ awk '$3==0 && $6=="LISTEN"' netstat.txt
tcp        0      0 127.0.1.1:53            0.0.0.0:*               LISTEN
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN
tcp6       0      0 :::22                   :::*                    LISTEN
tcp6       0      0 :::3306                 :::*                    LISTEN

如果需要保留表头，可以引入内建变量NR：
$ awk '$3==0 && $6=="LISTEN" || NR==1' netstat.txt
Active Internet connections (servers and established)
tcp        0      0 127.0.1.1:53            0.0.0.0:*               LISTEN
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN
tcp6       0      0 :::22                   :::*                    LISTEN
tcp6       0      0 :::3306                 :::*                    LISTEN




(3) BEGIN END , 给程序员一个初始化和收尾的工作

BEGIN之后列出的操作在{}内将在awk开始扫描输入之前执行, 而END{}内的操作, 将在扫描完输入文件后执行.

例1：通过BEGIN给文本marks.txt添加表头
$ awk 'BEGIN{printf "Sr No\tName\tSub\tMarks\n"}{print}' marks.txt
Sr No   Name    Sub     Marks
1)  Amit    Physics  80
2)  Rahul   Maths    90
3)  Shyam   Biology  87
4)  Kedar   English  85
5)  Hari    History  89

例2： prints all lines that start with an AWK identifier.打印开头符合identifier的行。
$ head /etc/passwd | awk 'BEGIN { identifier = "ro*t" } $0 ~ "^" identifier' /etc/passwd 
（r开头，后面若干个0，接着是t的）


-v 变量赋值选项：该选项将一个值赋予一个变量，它会在程序开始之前进行赋值。
例3：$ awk -v name=Jimmy 'BEGIN{printf "Name = %s\n", name}'
Name=Jimmy




(4)条件、循环控制语句，及从文件输入pattern。

awk {}内, 可以使用 if else ,for(i=0;i<10;i++), i=1 while(i<NF)
可见, awk的很多用法都等同于C语言, 比如"\t" 分隔符, print的格式, if, while, for 等等。

例：计数文件中独特单词的个数。count the number of unique "real words".

1)把模式写入文件$ cat cmd.awk
    BEGIN { FS = "[^A-Za-z]+" }
    { for(i = 1 ; i <= NF ; i++)  word[$i] = "" }
    END { delete word[""]
          for ( i in word )  cnt++
          print cnt
    }

$ cat out.txt
this is a linux system.
line2
Ubuntu is a release of linux.

2)对文件out.txt使用以上规则计数
$ awk -f cmd.awk out.txt #-f表示从文件中读取pattern。
9


(5)运算符

算术运算符：+-*/%
# awk 'BEGIN {a=50;b=20;print "(a+b)=",(a+b)}'
(a+b)= 70
# awk 'BEGIN {a=50;b=20;print "(a%b)=",(a%b)}'
(a%b)= 10 #取余数

自增自减与C语言一致。
# awk 'BEGIN { a = 10; b = a--; printf "a = %d, b = %d\n", a, b }'
# 猜一下a和b分别是多少？

赋值操作符有+=, -=, *=, /=, %=,乘方符^=,**=(这个不支持)
# awk 'BEGIN{a=2;a^=10;printf "a=%d\n",a}'
a=1024

关系操作符>,<,>=,<=,==,!=
# awk 'BEGIN{a=10; b=10; if(a==b)print"a==b"}'
a==b



逻辑操作符 或(||),且(&&)非,(!)
打印第2到4行
# awk '{if (NR >= 2 && NR <= 4) printf "line%d:%s\n", NR,$0}' marks.txt
line2:2)  Rahul   Maths    90
line3:3)  Shyam   Biology  87
line4:4)  Kedar   English  85

三元操作符
# awk 'BEGIN{a=10;b=2;max=(a>b)?a:b;print "max=",max;}'
max= 10

字符串连接，就是用空格连接字符串变量。
# awk 'BEGIN{a="Hello,"; b="world";c=a b;print c;}'
Hello,world

数组成员操作符
# awk 'BEGIN{arr[0]=10;arr[1]=11;arr[2]=12; for(i in arr) printf "arr[%d]=%d\n",i,arr[i]}'
arr[0]=10
arr[1]=11
arr[2]=12







4.awk正则表达式
正则表达式操作符使用 ~ 和 !~ 分别代表匹配和不匹配。
也可以按字段匹配。~ 表示模式开始。/ /中是模式，表达式前后添加反斜线，与js类似吧
# tail -n 40 /var/log/nginx/access.log | awk '$0 ~ /ip\[127\.0\.0\.1\]/'
# tail -n 40 /var/log/auth.log | awk '/wangjl/'

awk可以像grep一样的去匹配每一行，就像这样：
例1：awk '/LISTEN/' netstat.txt
tcp        0      0 127.0.1.1:53            0.0.0.0:*               LISTEN
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN
tcp6       0      0 :::22                   :::*                    LISTEN
tcp6       0      0 :::3306                 :::*                    LISTEN



例2： 第六个字段符合正则的行
$ awk '$6 ~ /ESTA/ || NR==1 {print NR,$4,$5,$6}' OFS=";" netstat.txt
1;Local;Address;Foreign
4;172.16.112.86:22;172.16.113.174:55033;ESTABLISHED
5;172.16.112.86:22;172.16.113.174:56000;ESTABLISHED

例3： LISTEN 状态的行
$ netstat -an| awk '$6 ~ /LISTEN/ ||NR==2 {print NR,$4,$5,$6}' OFS="\t"
2       Local   Address Foreign
3       127.0.1.1:53    0.0.0.0:*       LISTEN
4       0.0.0.0:22      0.0.0.0:*       LISTEN
7       :::22   :::*    LISTEN
8       :::3306 :::*    LISTEN

例4：可以使用 “/LISTEN|ESTABLISHED/” 来匹配 LISTEN 或者 ESTABLISHED :
$ netstat -an| awk '$6 ~ /LISTEN|ESTABLISHED/ ||NR==2 {print NR,$4,$5,$6}' OFS="\t"

例5：取反
p$ awk '$6 !~ /LISTEN|ESTABLISHED/ ||NR==1 {print NR,$4,$5,$6}' OFS="\t" netstat.txt
1       Local   Address Foreign
8       127.0.1.1:53    0.0.0.0:*

或者$ awk '!/LISTEN/' netstat.txt








5.内置变量与自定义变量
(1)内置变量参考[$ man awk 的 7. Builtin-variables]

内置变量Builtin-variables
The following variables are built-in and initialized before program execution.程序执行前初始化
	ARGC      number of command line arguments.
	ARGV      array of command line arguments, 0..ARGC-1.
	CONVFMT   format for internal conversion of numbers to string, initially = "%.6g".
	ENVIRON   array  indexed  by  environment  variables.  An environment string, var=value is stored as
			ENVIRON[var] = value.
	FILENAME  当前文件名 name of the current input file.
	FNR       文件内自己的行号 current record number in FILENAME.
	FS        字段分隔符 splits records into fields as a regular expression.
	NF        当前行字段数 number of fields in the current record.
	NR        当前记录数 current record number in the total input stream.
	OFMT      format for printing numbers; initially = "%.6g".
	OFS       显示时字段分割符 inserted between fields on output, initially = " ".
	ORS       terminates each record on output, initially = "\n".
	RLENGTH   length set by the last call to the built-in function, match().
	RS        记录分隔符，默认是换行符 input record separator, initially = "\n".
	RSTART    index set by the last call to match().
	SUBSEP    used to build multiple array subscripts, initially = "\034".


例1: 内置变量 FILENAME 表示当前文件名：
$ awk 'END {print FILENAME}' marks.txt
marks.txt

例2: OFS指定显示分隔符
$ awk  -F: '{print $1,$3,$6}' OFS=";" /etc/passwd | head
root;0;/root
daemon;1;/usr/sbin
bin;2;/bin
sys;3;/dev
sync;4;/bin



(2)
自定义变量统计含a的行数：
$ awk '/a/{++cnt} END {print "Count=", cnt}' marks.txt
Count= 4

使用语句打印出来哪些行含有r：
$ awk '/r/{++cnt; print} END {print "Count=", cnt}' marks.txt
4)  Kedar   English  85
5)  Hari    History  89
Count= 2








6.内置函数、自定义函数与系统命令
AWK提供了很多方便的内建函数供编程人员使用。最好先知道大概，使用的时候再查手册。
https://www.gnu.org/software/gawk/manual/gawk.html#Built_002din
内置函数： http://www.cnblogs.com/chengmo/archive/2010/10/08/1845913.html

数学函数
	atan2(y, x)
	cos(expr)
	exp(expr)
	int(expr)
	log(expr)
	rand
	sin(expr)
	sqrt(expr)
	srand([expr])

字符串函数
	asort(arr [, d [, how] ])
	asorti(arr [, d [, how] ])
	gsub(regex, sub, string)
	index(str, sub)
	length(str)
	match(str, regex)
	split(str, arr, regex)
	sprintf(format, expr-list)
	strtonum(str)
	sub(regex, sub, string)
	substr(str, start, l)
	tolower(str)
	toupper(str)

时间函数
	systime
	mktime(datespec)
	strftime([format [, timestamp[, utc-flag]]])

字节操作函数
	and
	compl
	lshift
	rshift
	or
	xor

其它
	close(expr) 关闭管道文件


例1: 使用command | getline var可以实现将命令的输出写入到变量var。
$ awk 'BEGIN {
     "date" | getline current_time
     close("date")
     print "Report printed on " current_time
}'

只能读取一行，其中command是linux命令。
$ awk 'BEGIN{"ls"|getline txts; close("ls"); print txts}'
Desktop


函数是程序基本的组成部分，AWK允许我们自己创建自定义的函数。一个大型的程序可以被划分为多个函数，每个函数之间可以独立的开发和测试，提供可重用的代码。

下面是用户自定义函数的基本语法
function function_name(argument1, argument2, ...) { 
   function body
}
return 用于用户自定义函数的返回值。


例2:自定义加法
首先，创建一个functions.awk文件，包含下面的awk命令
$ cat awk_2.cmd
function addition(num1, num2) {
   result = num1 + num2
   return result
}
BEGIN {
   res = addition(10, 20)
   print "10 + 20 = " res
}

$ awk -f awk_2.cmd
10 + 20 = 30


例3:执行系统命令
system函数用于执行操作系统命令并且返回命令的退出码到awk。
END {
     system("date | mail -s 'awk run done' root")
}

$ awk 'BEGIN{system("date")}'
2017年 08月 12日 星期六 06:37:36 CST
$ awk 'BEGIN{system("date | tr [A-Z] [a-z]")}'
2017年 08月 12日 星期六 06:37:50 cst







7.文件操作：拆分文件、重定向与管道

awk拆分文件很简单，使用重定向就好了。
重定向操作符跟在print和printf函数的后面，与shell中的用法基本一致。
	print DATA > output-file #覆盖式写入
	print DATA >> output-file #追加到文件结尾

例如，下面两条命令输出是一致的
$ echo "Hello, World !!!" > /tmp/message.txt
$ awk 'BEGIN { print "Hello, World !!!" > "/tmp/message.txt" }'

例1：按第6例分隔文件，相当的简单（其中的NR!=1表示不处理表头,$6!=""表示如果第六行是空则忽略掉）。
$ awk 'NR!=1 && $6!="" {print>$6}' netstat.txt
$ ls
7  ESTABLISHED  LISTEN  marks.txt  netstat.txt


例2：也可以把指定的列输出到文件：
$ ls
marks.txt  netstat.txt
$ awk 'NR!=1 && $6!="" {print $4,$5 > $6}' netstat.txt
$ ls
7  ESTABLISHED  LISTEN  marks.txt  netstat.txt
$ cat LISTEN
127.0.1.1:53 0.0.0.0:*
0.0.0.0:22 0.0.0.0:*
:::22 :::*
:::3306 :::*



例3:再复杂一点：（注意其中的if-else-if语句，可见awk其实是个脚本解释器）
$ ls
marks.txt  netstat.txt
$ awk 'NR!=1{
	if($6 ~ /TIME|ESTABLISHED/) print > "1.txt";
	else if($6 ~ /LISTEN/) print > "2.txt";
	else print > "3.txt" 
}' netstat.txt
$ ls
1.txt  2.txt  3.txt  marks.txt  netstat.txt
$ cat 3.txt
udp        0      0 127.0.1.1:53            0.0.0.0:*
udp        0      0 0.0.0.0:68              0.0.0.0:*
udp        0      0 0.0.0.0:631             0.0.0.0:*
udp        0      0 0.0.0.0:55418           0.0.0.0:*
udp        0      0 0.0.0.0:5353            0.0.0.0:*
udp6       0      0 :::58832                :::*
udp6       0      0 :::5353                 :::*
raw6       0      0 :::58                   :::*   



例4:管道
除了将输出重定向到文件之外，我们还可以将输出重定向到其它程序，与shell中一样，我们可以使用管道操作符|。
r$ echo "hello"|tr [a-z] [A-Z]
HELLO
$ awk 'BEGIN { print "hello, world !!!" | "tr [a-z] [A-Z]" }'
HELLO, WORLD !!!


例5:双向连接
AWK中可以使用|&进行双向连接，那么什么是双向连接呢？一种常见的场景是我们发送数据到另一个程序处理，然后读取处理结果，这种场景下就需要打开一个到另外一个进程的双向管道了。第二个进程会与gawk程序并行执行，这里称其为 协作进程。与单向连接使用|操作符不同的是，双向连接使用|&操作符。

do {
    print data |& "subprogram"
    "subprogram" |& getline results
} while (data left to process)
close("subprogram")

第一次I/O操作使用了|&操作符，gawk会创建一个到运行其它程序的子进程的双向管道，print的输出被写入到了subprogram的标准输入，而这个subprogram的标准输出在gawk中使用getline函数进行读取。





8.统计
例1：下面的命令计算所有的C文件，CPP文件和H文件的文件大小总和。
$ ls -l  *.cpp *.c *.h | awk '{sum+=$5} END {print sum}'

# ls -l *.zip
-rw-rw-r-- 1 wangjl wangjl 25072402 8月   4 10:49 mapdata_2.2-6.zip
-rw-rw-r-- 1 wangjl wangjl  3631621 8月   4 10:37 maps_3.2.0.zip
-rw-rw-r-- 1 wangjl wangjl  1823908 8月   4 08:10 maptools_0.9-2.zip
-rw-rw-r-- 1 wangjl wangjl  1219777 8月   4 10:47 plyr_1.8.4.zip
-rw-rw-r-- 1 wangjl wangjl  1538955 8月   4 08:09 sp_1.2-5.zip
# ls -l *.zip | awk '{sum+=$5} END{print sum}'
33286663



例2：（利用数组）统计每种状态（第六列）的数量

# awk 'BEGIN{print "State,count"}NR!=1 {a[$6]++} END{for(i in a) print i "," a[i]}' netstat.txt
State,count
,7
LISTEN,4
ESTABLISHED,2
7,1



例3: （利用关联数组）统计每个用户(第一列)的进程的占了多少内存（注：sum的RSS那一列）
# ps aux | head
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.3 185340  3444 ?        Ss   7月31   0:04 /sbin/init splash
root         2  0.0  0.0      0     0 ?        S    7月31   0:00 [kthreadd]
root         4  0.0  0.0      0     0 ?        S<   7月31   0:00 [kworker/0:0H]
root         6  0.0  0.0      0     0 ?        S    7月31   0:19 [ksoftirqd/0]
root         7  0.0  0.0      0     0 ?        S    7月31   1:06 [rcu_sched]
root         8  0.0  0.0      0     0 ?        S    7月31   0:00 [rcu_bh]
root         9  0.0  0.0      0     0 ?        S    7月31   0:00 [migration/0]
root        10  0.0  0.0      0     0 ?        S<   7月31   0:00 [lru-add-drain]
root        11  0.0  0.0      0     0 ?        S    7月31   0:04 [watchdog/0]

# ps aux | awk 'NR!=1 {a[$1]+=$6;} END{ for(i in a) print i "," a[i] "KB"}'
vboxadd,177912KB
syslog,644KB
colord,528KB
nobody,816KB
avahi,2324KB
wangjl,259812KB
whoopsie,3292KB
rtkit,292KB
root,115712KB
message+,3088KB




例4:综合统计
利用GEGIN,END语句求学生成绩表的行列小计。

$ cat score.txt
Marry   2143 78 84 77
Jack    2321 66 78 45
Tom     2122 48 77 71
Mike    2537 87 97 95
Bob     2415 40 57 62


$ cat cal.awk
#!/bin/awk -f
#运行前
BEGIN {
    math = 0
    english = 0
    computer = 0
 
    printf "NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL\n"
    printf "---------------------------------------------\n"
}
#运行中
{
    math+=$3
    english+=$4
    computer+=$5
    printf "%-6s %-6s %4d %8d %8d %8d\n", $1, $2, $3,$4,$5, $3+$4+$5
}
#运行后
END {
    printf "---------------------------------------------\n"
    printf "  TOTAL:%10d %8d %8d \n", math, english, computer
    printf "AVERAGE:%10.2f %8.2f %8.2f\n", math/NR, english/NR, computer/NR
}


我们来看一下执行结果：（也可以这样运行 ./cal.awk score.txt）
$ awk -f cal.awk score.txt #-f表示从文件读取awk命令
NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL
---------------------------------------------
Marry  2143     78       84       77      239
Jack   2321     66       78       45      189
Tom    2122     48       77       71      196
Mike   2537     87       97       95      279
Bob    2415     40       57       62      159
---------------------------------------------
  TOTAL:       319      393      350
AVERAGE:     63.80    78.60    70.00





9.环境变量
即然说到了脚本，我们来看看怎么和环境变量交互：
（使用-v参数和ENVIRON，使用ENVIRON的环境变量需要export）
# x=5
# y=10
# export y
# echo $x $y

# cat score.txt
Marry   2143 78 84 77
Jack    2321 66 78 45
Tom     2122 48 77 71
Mike    2537 87 97 95
Bob     2415 40 57 62

# awk -v val=$x '{print $1,$2,$3,$4+val, $5+ENVIRON["y"]}' OFS="\t" score.txt
Marry   2143    78      89      87
Jack    2321    66      83      55
Tom     2122    48      82      81
Mike    2537    87      102     105
Bob     2415    40      62      72





10.杂项
# 从file文件中找出长度大于80的行
$ awk 'length>80' file

#按连接数查看客户端IP
netstat -ntu | awk '{print $5}' | cut -d: -f1 | sort | uniq -c | sort -nr

#打印99乘法表
seq 9 | sed 'H;g' | awk -v RS='' '{for(i=1;i<=NF;i++)printf("%dx%d=%d%s", i, NR, i*NR, i==NR?"\n":"\t")}'



结束语： awk 是相当复杂的工具, 真正使用时, 再细看man awk吧. 
内建变量，参看：http://www.gnu.org/software/gawk/manual/gawk.html#Built_002din-Variables
流控方面，参看：http://www.gnu.org/software/gawk/manual/gawk.html#Statements
内建函数，参看：http://www.gnu.org/software/gawk/manual/gawk.html#Built_002din
正则表达式，参看：http://www.gnu.org/software/gawk/manual/gawk.html#Regexp

https://segmentfault.com/a/1190000007338373
http://www.gnu.org/software/gawk/manual/gawk.html
https://www.gnu.org/software/gawk/manual/gawk.html





========================================
sed(关键字: 编辑) 以行为单位的文本编辑工具 
----------------------------------------
1.定义与作用
sed - stream editor for filtering and transforming text 
用于过滤和转换文本的流编辑器。特色是该编辑器能用于pipeline中。

sed全名叫stream editor，流编辑器，用程序的方式来编辑文本（非交互式的），相当的hacker啊。
sed基本上就是玩正则模式匹配，所以，玩sed的人，正则表达式一般都比较强。

sed可以直接修改档案, 不过一般不推荐这么做, 可以分析 standard input

文档： 
	man: http://www.gnu.org/software/sed/manual/sed.html
	https://www.gnu.org/software/sed/
	list: http://sed.sourceforge.net/
	detail: http://www.grymoire.com/Unix/Sed.html




2.基本工作方式: sed [-nef] '[动作]' [输入文本]
	-n : 安静模式, 一般sed用法中, 来自stdin的数据一般会被列出到屏幕上, 如果使用-n参数后, 只有经过sed处理的那一行被列出来.
	-e : 多重编辑, 比如你同时又想删除某行, 又想改变其他行, 那么可以用 sed -e '1,5d' -e 's/abc/xxx/g' filename
	-f : 首先将 sed的动作写在一个档案内, 然后通过 sed -f scriptfile 就可以直接执行 scriptfile 内的sed动作。
	-i : 直接编辑, 这回就是真的改变文件中的内容了, 别的都只是改变显示. (不推荐使用)
	
动作:
	a 新增, a 后面可以接字符串, 而这个字符串会在新的一行出现. (下一行)
	c 取代, c 后面的字符串, 这些字符串可以取代 n1,n2之间的行
	d 删除, 后面不接任何东西
	i 插入, 后面的字符串, 会在上一行出现
	p 打印, 将选择的资料列出, 通常和 sed -n 一起运作 sed -n '3p' 只打印第3行
	s 取代, 类似vi中的取代, 1,20s/old/new/g

例： $ echo "this is a book" | sed 's/is/was/g'
thwas was a book

	[line-address]q 退出, 匹配到某行退出, 提高效率
	[line-address]r 匹配到的行读取某文件(注意是文件名) 例如: sed '1r qqq.txt' abc , 注意, 写入的文本是写在了第1行的后边, 也就是第2行
	[line-address]w file, 匹配到的行写入某文件  例如: sed -n '/m/w qqq' abc , 从abc中读取带m的行写到qqq文件中, 注意, 这个写入带有覆盖性.


常用例子:
sed '1d' abc 删除 abc 档案里的第一行, 注意, 这时会显示除了第一行之外的所有行, 因为第一行已经被删除了(实际文件并没有被删除,而只是显示的时候被删除了)

sed -n '1d' abc 什么内容也不显示, 因为经过sed处理的行, 是个删除操作, 所以不显示.

sed '2,$d' abc 删除abc中从第二行到最后一行所有的内容, 注意, $符号正则表达式中表示行末尾, 但是这里并没有说那行末尾, 就会指最后一行末尾, ^开头, 如果没有指定哪行开头, 那么就是第一行开头

sed '$d' abc 只删除了最后一行, 因为并没有指定是那行末尾, 就认为是最后一行末尾

sed '/test/d' abc 删除文件中所有带 test 的行

sed '/test/a RRRRRRR' abc 将 RRRRRRR 追加到所有的带 test 行的下一行 

sed '1,5c RRRRRRR' abc 从1到5行被 RRRRRRR 替换

sed '/test/c RRRRRRR' abc 将 RRRRRRR 替换所有带 test 的行, 当然, 这里也可以是通过行来进行替换, 比如 sed '1,5c RRRRRRR' abc





3.用s命令替换
(1)一般替换
$ cat out.txt #原文
this is a linux system.
line2
Ubuntu is a release of linux.

$ sed 's/is/are/' out.txt #把is用are替换
thare is a linux system.
line2
Ubuntu are a release of linux.

$ sed 's/is/are/g' out.txt #/g 表示一行上的替换所有的匹配
thare are a linux system.
line2
Ubuntu are a release of linux.

$ sed '1s/linux/Unix/g' out.txt #1s表示只替换第一行。
this is a Unix system.
line2
Ubuntu is a release of linux.


上面的sed并没有对文件的内容改变，只是把处理过后的内容输出，如果你要写回文件，你可以使用重定向。
$ sed '1s/linux/Unix/g' out.txt >out2.txt
或者使用-i参数（不推荐）直接修改原文件
$ sed -i 's/linux/Windows/g' out2.txt
wangjl@ubt16:~/str$ cat out2.txt
this is a Unix system.
line2
Ubuntu is a release of Windows.


在每一行最前面加注释符#：
$ sed 's/^/#/g' out.txt
#this is a linux system.
#line2
#Ubuntu is a release of linux.

在每一行最后面加上英文分号;
$ sed 's/$/;/g' out.txt
this is a linux system.;
line2;
Ubuntu is a release of linux.;

(2)每一行多个替换(-e参数)
同时在行首加上#，行尾加上;
$ sed -e 's/^/#/g' -e 's/$/;/g' out.txt
#this is a linux system.;
#line2;
#Ubuntu is a release of linux.;

(3)正则表达式的一些最基本的东西：
	^ 表示一行的开头。如：/^#/ 以#开头的匹配。
	$ 表示一行的结尾。如：/}$/ 以}结尾的匹配。
	\< 表示词首。 如：\<abc 表示以 abc 为首的詞。
	\> 表示词尾。 如：abc\> 表示以 abc 結尾的詞。
	. 表示任何单个字符。
	* 表示某个字符出现了0次或多次。
	[ ] 字符集合。 如：[abc] 表示匹配a或b或c，还有 [a-zA-Z] 表示匹配所有的26个字符。如果其中有^表示反，如 [^a] 表示非a的字符
	
注意： sed的正则用的是BREs/EREs，不支持非贪婪模式。
https://segmentfault.com/q/1010000002416121

例:去掉某html中的tags：
index.html
<b>This</b> is what <span style="text-decoration: underline;">the Boss</span> meant. Understand?

# 如果你这样搞的话，就会有问题
$ sed 's/<.*>//g' index.html
 meant. Understand?

# 要解决上面的那个问题，就得像下面这样。
# 其中的'[^>]' 指定了非>的字符重复0次或多次。
$ sed 's/<[^>]*>//g' index.html
This is what the Boss meant. Understand?


(4)替换每一行的第2个匹配项
$ sed 's/i/I/2' out.txt
this Is a linux system.
line2
Ubuntu is a release of lInux.

$ sed 's/i/I/1' out.txt
thIs is a linux system.
lIne2
Ubuntu Is a release of linux.

$ sed 's/i/I/' out.txt #默认就是只替换每行的第一个
thIs is a linux system.
lIne2
Ubuntu Is a release of linux. 

$ sed 's/i/I/2g' out.txt #替换每行第三个及以后的
this Is a lInux system.
line2
Ubuntu is a release of lInux.


(5)引用匹配项
我们可以使用&来当做被匹配的变量，然后可以在其左右加点东西。
$ sed 's/i/[&]/g' out.txt
th[i]s [i]s a l[i]nux system.
l[i]ne2
Ubuntu [i]s a release of l[i]nux.

或者使用圆括号匹配，用\1,\2等表示对匹配的引用。
$ sed 's/\(\w*\) is a \([^.]*\)/\1-\2/g' out.txt
this-linux system.
line2
Ubuntu-release of linux.
为什么[^.]没起到过滤.号的作用？
注意： 因为sed只替换了匹配的，没有匹配的保持不变。

比如 echo 'aaaaaaactttt'|sed 's/\(.*\)a/\1b/'
输出为 aaaaaabctttt

想达到去除.号的目的，需要把.移到正则()外面：
$ sed 's/\(\w*\) is a \(.*\)\./\1-\2/g' out.txt
this-linux system
line2
Ubuntu-release of linux

正则为：(\w*) is a (). 
匹配为：(this) is a (linux system).
然后：\1就是this，\2就是linux system







4.更多命令

(1)N命令: 把下一行的内容纳入当成缓冲区做匹配。
n N    Read/append the next line of input into the pattern space.

$ sed 's/i/I/' out2.txt 
thIs is a linux system.
lIne2
Ubuntu Is a release of linux.
It Is a wonderfull release.

加了N命令后，偶数行合并到奇数行结尾，原文大概成了这样
this is a linux system.\nline2
Ubuntu is a release of linux.\nIt is a wonderfull release.

$ sed 'N;s/i/I/' out2.txt #偶数行没做替换
thIs is a linux system.
line2
Ubuntu Is a release of linux.
It is a wonderfull release.

$ sed 'N;s/i/I/' out.txt #最后一个没有偶数行的也没有处理(?bug)
thIs is a linux system.
line2
Ubuntu is a release of linux.

我们甚至可以替换掉这个换行符/n 
$ sed 'N;s/\n//' out2.txt
this is a linux system.line2
Ubuntu is a release of linux.It is a wonderfull release.


$ sed -e 'N;s/i/I/' -e 'N;s/\n//' out2.txt #又出现bug第二个没有替换
thIs is a linux system.line2
Ubuntu is a release of linux.
It is a wonderfull release.


(2)a命令和i命令
a命令就是append， i命令就是insert，它们是用来添加行的。

1)
# 其中的1i表明，其要在第1行前插入一行（insert）
$ sed '1i desc\n------------' out.txt
desc
------------
this is a linux system.
line2
Ubuntu is a release of linux.

# 其中的1a表明，其要在第一行后追加一行（append）
$ sed '1a ------------' out.txt
this is a linux system.
------------
line2
Ubuntu is a release of linux.


# 其中的$a表明，其要在最后一行后追加一行（append）
$ sed '$a ------------' out.txt
this is a linux system.
line2
Ubuntu is a release of linux.
------------

2)我们可以运用匹配来添加文本：
注意其中的/is/a，这意思是匹配到/fish/后就追加一行
$ sed '/is/a ---' out.txt
this is a linux system.
---
line2
Ubuntu is a release of linux.
---


(3)c命令-替换匹配行
$ sed '2c this is another line' out.txt
this is a linux system.
this is another line
Ubuntu is a release of linux.

$ sed '/linux/c replace the line with linux' out.txt
replace the line with linux
line2
replace the line with linux



(4)d命令-删除匹配行
$ sed '2d' out.txt
this is a linux system.
Ubuntu is a release of linux.

$ sed '2,$d' out.txt
this is a linux system.

$ sed '/is/d' out.txt
line2



(5)p命令-打印命令
你可以把这个命令当成grep式的命令

$ sed '/is/p' out.txt
this is a linux system.
this is a linux system.
line2
Ubuntu is a release of linux.
Ubuntu is a release of linux.

发现有些输出两遍，这是因为sed处理时会把处理的信息输出。
添加-n参数后就可以了。
$ sed -n '/is/p' out.txt
this is a linux system.
Ubuntu is a release of linux.


#从一个模式到另一个模式（跨行了）
$ sed -n '/ine/,/nux/p' out.txt
line2
Ubuntu is a release of linux.


#从第1行到匹配到的行
$ sed -n '1,/line/p' out.txt
this is a linux system.
line2







5.四个sed的基本知识点

(0)Pattern Space
我们来看一下sed处理文本的伪代码，并了解一下Pattern Space的概念：
foreach line in file {
    //把行放入Pattern_Space
    Pattern_Space <= line;
 
    // 对每个pattern space执行sed命令
    Pattern_Space <= EXEC(sed_cmd, Pattern_Space);
 
    // 如果没有指定 -n 则输出处理后的Pattern_Space
    if (sed option hasn't "-n")  {
       print Pattern_Space
    }
}

(1)Address
第一个是关于address，几乎上述所有的命令都是这样的（注：其中的!表示匹配成功后是否执行命令）
[address[,address]][!]{cmd}

address可以是一个数字，也可以是一个模式，
你可以通过逗号要分隔两个address 表示两个address的区间，参执行命令cmd，伪代码如下：
bool bexec = false
foreach line in file {
    if ( match(address1) ){
        bexec = true;
    }
 
    if ( bexec == true) {
        EXEC(sed_cmd);
    }
 
    if ( match (address2) ) {
        bexec = false;
    }
}

关于address可以使用相对位置，如：
r$ sed '/sys/,+1s/^/#/g' out.txt
#this is a linux system.
#line2
Ubuntu is a release of linux.

$ sed '/sys/,+2s/^/#/g' out.txt
#this is a linux system.
#line2
#Ubuntu is a release of linux.


(2)命令打包
第二个是cmd可以是多个，它们可以用分号分开，可以用大括号括起来作为嵌套命令。下面是几个例子：

对1行到第2行，执行命令/ine/d
$ sed '1,2 {/ine/d}' out.txt
this is a linux system.
Ubuntu is a release of linux.

# 对1行到第3行，匹配/is/成功后，再匹配/linux/，成功后执行d命令
$ sed '1,3{/is/{/linux/d}}' out2.txt
line2
It is a wonderfull release.

# 从第一行到最后一行，如果匹配到is，则删除之；如果有line，则替换为anotherLine
$ sed '1,${/is/d;s/line/anotherLine/g}' out2.txt
anotherLine2



(3)Hold Space[比较难，慢慢看，多看几遍]
第三个我们再来看一下 Hold Space

接下来，我们需要了解一下Hold Space的概念，我们先来看四个命令：
	g： 将hold space中的内容拷贝到pattern space中，原来pattern space里的内容清除
	G： 将hold space中的内容append到pattern space\n后
	h： 将pattern space中的内容拷贝到hold space中，原来的hold space里的内容被清除
	H： 将pattern space中的内容append到hold space\n后
	x： 交换pattern space和hold space的内容

这些命令有什么用？我们来看两个示例吧，用到的示例文件是：
$ cat >t.txt
one
two
three


第一个示例：
$ sed 'H;g' t.txt


第二个示例，反序了一个文件的行：
$ sed '1!G;h;$!d' t.txt

其中的 '1!G;h;$!d' 可拆解为三个命令
	1!G —— 只有第一行不执行G命令，将hold space中的内容append回到pattern space
	h —— 第一行都执行h命令，将pattern space中的内容拷贝到hold space中
	$!d —— 除了最后一行不执行d命令，其它行都执行d命令，删除当前行










6.杂七杂八
(1)sed '/^$/d' my.txt 为什么起到过滤空行的效果呢？
sed是按行进行处理的。
^$ 是正则表达式，其中^表示以什么开头，$表示以什么结尾，两个连载一起就是空行的意思，
d指令是sed里面的删除，
整个语句的意思就是从my.txt文件中删除空行空行

(2)# 在每一行后面增加一空行 
$ sed G my.txt

(3)可以修改定界符，用#代替/
$ a='are'
$ echo $a
are

$ sed 's/is/$a/g' out.txt #单引号内就是字符替换
th$a $a a linux system.
line2
Ubuntu $a a release of linux.

$ sed "s#is#$a#g" out.txt #双引号内才可以变量替换
thare are a linux system.
line2
Ubuntu are a release of linux.

$ sed "s/is/$a/g" out.txt
thare are a linux system.
line2
Ubuntu are a release of linux.





========================================
shell脚本入门
----------------------------------------
1.
(1)概述
shell提供了对UNIX系统的接口。收集输入，并根据输入执行程序。当一个程序执行完毕后，它会显示该程序的输出。
 
shell是一个环境，我们可以运行我们的命令，程序和shell脚本。shell有不同的风格，就像有不同风格的操作系统。每个的shell的风格，有它自己的一套识别的命令和功能。

shell它交互式解释和执行用户输入的命令或者自动地解释和执行预先设定好的一连串的命令；
作为程序设计语言，它定义了各种变量和参数，并提供了许多在高级语言中才具有的控制结构，包括循环和分支。

(2)资源：
	http://www.yiibai.com/shell/
	http://www.itshouce.com.cn/linux/linux-shell.html
	编写Shell脚本的最佳实践 http://kb.cnblogs.com/page/574767/
	菜鸟教程 http://www.runoob.com/linux/linux-shell.html

(3)分类
Shell 编程跟 java、php 编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。
Linux 的 Shell 种类众多，常见的有：
	Bourne Shell（/usr/bin/sh或/bin/sh）
	Bourne Again Shell（/bin/bash）
	C Shell（/usr/bin/csh）
	K Shell（/usr/bin/ksh）
	Shell for Root（/sbin/sh）
	……
	
本教程关注的是 Bash，也就是 Bourne Again Shell，由于易用和免费，Bash 在日常工作中被广泛使用。同时，Bash 也是大多数Linux 系统默认的 Shell。

在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 #!/bin/sh，它同样也可以改为 #!/bin/bash。
#! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 程序。


2. hello world 
(1)编写
第一个shell脚本
打开文本编辑器(可以使用 vi/vim 命令来创建文件)，新建一个文件 test.sh，扩展名为 sh（sh代表shell），扩展名并不影响脚本执行，见名知意就好，如果你用 php 写 shell 脚本，扩展名就用 php 好了。
输入一些代码，第一行一般是这样：

#!/bin/bash
echo "Hello World !"

(1)运行 
运行方法1：添加可执行权限
$ chmod +x ./test.sh  #使脚本具有执行权限
$ ./test.sh  #执行脚本

注意，一定要写成 ./test.sh，而不是 test.sh

运行方式2：作为解释器参数
$/bin/sh test.sh
或简写 $sh test.sh

这种方式运行的脚本，不需要在第一行指定解释器信息，写了也没用。


========================================
----------------------------------------



========================================
----------------------------------------



========================================
----------------------------------------


